{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StickMonkey615/JHCSMod4/blob/main/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRn73TIW7gn9"
      },
      "source": [
        "# Module 4 Guidance\n",
        "\n",
        "This notebook is a template for module 4b and 4c, which will be tested in Google Colab, your code needs to run there.\n",
        "The structure has been provided to improve consistency and make it easier for markers to understand your code but still give students the flexibility to be creative.  You need to populate the required functions to solve this problem.  All dependencies should be documented in the next cell.\n",
        "\n",
        "You can:\n",
        "    add further cells or text blocks to extend or further explain your solution\n",
        "    add further functions\n",
        "\n",
        "Dont:\n",
        "    rename functions\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxOsuHxz7goC",
        "outputId": "aa590fd6-db7d-4148-bf88-f4527b3a987c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Collecting xlrd\n",
            "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 3.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: xlrd\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "Successfully installed xlrd-2.0.1\n"
          ]
        }
      ],
      "source": [
        "# Fixed dependencies - do not remove or change.\n",
        "import pytest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "'''from google.colab import drive'''\n",
        "# drive.mount('/content/gdrive/')\n",
        "# Import your dependencies\n",
        "#!pip install xlrd>=1.2.0\n",
        "!pip install --upgrade xlrd\n",
        "#!apt-get -qq install -y graphviz && pip install xlrd\n",
        "import xlrd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1m_gmKQP7goE"
      },
      "outputs": [],
      "source": [
        "# Import data\n",
        "\n",
        "def import_local_data(file_path):\n",
        "    \"\"\"This function needs to import the data file into collab and return a pandas dataframe\n",
        "    \"\"\"\n",
        "    raw_df = pd.read_excel(file_path)\n",
        "    return raw_df "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cIljHljB7goF"
      },
      "outputs": [],
      "source": [
        "#local_file_path = \"C:/Users/shaun/Python_work/jHub Coding Scheme/Module 4 - ML/breast-cancer.xls\"\n",
        "local_file_path = \"breast-cancer.xls\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LCu51H5Z7goF"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "raw_data = import_local_data(local_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9WDYKUP7goG"
      },
      "source": [
        "### Conduct exploratory data analysis and explain your key findings - Examine the data, explain its key features and what they look like.  Highlight any fields that are anomalous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KMB3eKfC7goU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f02MTYgB7goW"
      },
      "outputs": [],
      "source": [
        "# Explain your key findings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jgbyjpS37goW"
      },
      "outputs": [],
      "source": [
        "def process_data(unproc_data):\n",
        "    \n",
        "    # Taking care of missing data\n",
        "    # from sklearn.impute import SimpleImputer\n",
        "    # imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "    # imputer.fit(raw_data[:, 5])\n",
        "    # X[:, 5] = imputer.transform(X[:, 5])\n",
        "    # print(X)\n",
        "\n",
        "    # Remove non-categorical data\n",
        "    dm = unproc_data.pop('deg-malig')\n",
        "\n",
        "    # Correct date types in tumor-size abd inv-nodes variables\n",
        "    for i in range(0, len(unproc_data)):\n",
        "        if type(unproc_data['tumor-size'][i]) is not str:\n",
        "            if unproc_data['tumor-size'][i].day == 1:\n",
        "                unproc_data['tumor-size'][i] = str(unproc_data['tumor-size'][i].month) + '-' + str(unproc_data['tumor-size'][i].year-2000)\n",
        "            else:\n",
        "                unproc_data['tumor-size'][i] = str(unproc_data['tumor-size'][i].day) + '-' + str(unproc_data['tumor-size'][i].month)\n",
        "        if type(unproc_data['inv-nodes'][i]) is not str:\n",
        "            if unproc_data['inv-nodes'][i].day == 1:\n",
        "                unproc_data['inv-nodes'][i] = str(unproc_data['inv-nodes'][i].month) + '-' + str(unproc_data['inv-nodes'][i].year-2000)\n",
        "            else:\n",
        "                unproc_data['inv-nodes'][i] = str(unproc_data['inv-nodes'][i].day) + '-' + str(unproc_data['inv-nodes'][i].month)\n",
        "\n",
        "    # Convert node-caps and irradiat variables into booleans\n",
        "    for i in range(0, len(unproc_data)):\n",
        "        if unproc_data['node-caps'][i] == 'yes':\n",
        "            unproc_data['node-caps'][i] = True\n",
        "        elif unproc_data['node-caps'][i] == 'no':\n",
        "            unproc_data['node-caps'][i] = False\n",
        "        else:\n",
        "            unproc_data['node-caps'][i] = False\n",
        "        if unproc_data['irradiat'][i] == 'yes':\n",
        "            unproc_data['irradiat'][i] = True\n",
        "        elif unproc_data['irradiat'][i] == 'no':\n",
        "            unproc_data['irradiat'][i] = False\n",
        "        else:\n",
        "            unproc_data['irradiat'][i] = False\n",
        "\n",
        "\n",
        "    # Encode the catagorical data (dummy variables)\n",
        "    proc_data = pd.get_dummies(data=unproc_data, prefix_sep='_', drop_first=True)\n",
        "    \n",
        "    # Add back in non-categorical data\n",
        "    proc_data.insert(0, 'deg-malig', dm)\n",
        "    \n",
        "    return proc_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yi4pFb5iD-zT"
      },
      "outputs": [],
      "source": [
        "clean_data = process_data(raw_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzZj8I8G7goX"
      },
      "source": [
        "Create any data pre-processing that you will conduct on seen and unseen data.  Regardless of the model you use, this dataframe must contain only numeric features and have a strategy for any expected missing values. Any objects can that are needed to handle the test data that are dependent on the training data can be stored in the model class.  You are recommended to use sklearn Pipelines or similar functionality to ensure reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mcmJMdW9D9Rm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WIh9_0pp7goY"
      },
      "outputs": [],
      "source": [
        "# Split your data so that you can test the effectiveness of your model\n",
        "# Split the data into a Training set and a Test set\n",
        "dfs = np.split(clean_data, [len(clean_data.columns)-1], axis=1)\n",
        "X = dfs[0]\n",
        "y = dfs[1]\n",
        "#X = raw_data.iloc[:, :-1].values\n",
        "#y = raw_data.iloc[:, -1].values\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AbOQACY77goY"
      },
      "outputs": [],
      "source": [
        "# Populate preprocess_training_data and preprocess_test_data to preprocess data.\n",
        "# You must process test and train separately so your model does not accidently gain information that a model wouldnt have in reality and therefore get better predictions\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Xsq2f8747goZ"
      },
      "outputs": [],
      "source": [
        "class Module4_Model:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        \n",
        "    def preprocess_training_data(self, training_df):\n",
        "        \"\"\"\n",
        "        This function should process the training data and store any features required in the class\n",
        "        \"\"\"\n",
        "        processed_df = training_df\n",
        "        return processed_df\n",
        "\n",
        "    def preprocess_test_data(self, test_df):\n",
        "\n",
        "        processed_df= test_df\n",
        "        return processed_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "F3LiNNCb7goa"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "my_model = Module4_Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZQD7WPdN7god"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "x_train_processed = my_model.preprocess_training_data(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XnLHgaXS7goe"
      },
      "outputs": [],
      "source": [
        "# Create a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Qr5QOWyc7goe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rQwUj4lk7goe"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "x_test_processed = my_model.preprocess_test_data(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqEGqaAA7goi",
        "outputId": "b3ae2ffa-4a43-424e-a3b4-ab7d2dad458c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Train your model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8YP4YbN7goi",
        "outputId": "38df896a-8ccf-4b79-d108-825140dabd66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 76.15 %\n",
            "Best Parameters: {'algorithm': 'auto', 'metric': 'chebyshev', 'n_neighbors': 10, 'weights': 'uniform'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "1800 fits failed out of a total of 8400.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "300 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
            "    return self._fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\", line 553, in _fit\n",
            "    **self.effective_metric_params_,\n",
            "  File \"sklearn/neighbors/_binary_tree.pxi\", line 966, in sklearn.neighbors._ball_tree.BinaryTree.__init__\n",
            "  File \"sklearn/metrics/_dist_metrics.pyx\", line 280, in sklearn.metrics._dist_metrics.DistanceMetric.get_metric\n",
            "  File \"sklearn/metrics/_dist_metrics.pyx\", line 615, in sklearn.metrics._dist_metrics.WMinkowskiDistance.__init__\n",
            "TypeError: __init__() takes exactly 2 positional arguments (1 given)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "300 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
            "    return self._fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\", line 553, in _fit\n",
            "    **self.effective_metric_params_,\n",
            "  File \"sklearn/neighbors/_binary_tree.pxi\", line 966, in sklearn.neighbors._ball_tree.BinaryTree.__init__\n",
            "  File \"sklearn/metrics/_dist_metrics.pyx\", line 280, in sklearn.metrics._dist_metrics.DistanceMetric.get_metric\n",
            "  File \"sklearn/metrics/_dist_metrics.pyx\", line 462, in sklearn.metrics._dist_metrics.SEuclideanDistance.__init__\n",
            "TypeError: __init__() takes exactly 1 positional argument (0 given)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "300 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
            "    return self._fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\", line 553, in _fit\n",
            "    **self.effective_metric_params_,\n",
            "  File \"sklearn/neighbors/_binary_tree.pxi\", line 966, in sklearn.neighbors._ball_tree.BinaryTree.__init__\n",
            "  File \"sklearn/metrics/_dist_metrics.pyx\", line 280, in sklearn.metrics._dist_metrics.DistanceMetric.get_metric\n",
            "  File \"sklearn/metrics/_dist_metrics.pyx\", line 676, in sklearn.metrics._dist_metrics.MahalanobisDistance.__init__\n",
            "ValueError: Must provide either V or VI for Mahalanobis distance\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "300 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
            "    return self._fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\", line 437, in _fit\n",
            "    self._check_algorithm_metric()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\", line 378, in _check_algorithm_metric\n",
            "    \"Metric can also be a callable function.\" % (self.metric, alg_check)\n",
            "ValueError: Metric 'wminkowski' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "300 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
            "    return self._fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\", line 437, in _fit\n",
            "    self._check_algorithm_metric()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\", line 378, in _check_algorithm_metric\n",
            "    \"Metric can also be a callable function.\" % (self.metric, alg_check)\n",
            "ValueError: Metric 'seuclidean' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "300 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
            "    return self._fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\", line 437, in _fit\n",
            "    self._check_algorithm_metric()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\", line 378, in _check_algorithm_metric\n",
            "    \"Metric can also be a callable function.\" % (self.metric, alg_check)\n",
            "ValueError: Metric 'mahalanobis' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.66839827 0.66839827 0.70519481 0.67294372 0.69134199 0.68203463\n",
            " 0.72424242 0.69588745 0.72402597 0.71471861 0.72922078 0.72857143\n",
            " 0.72445887 0.71969697 0.72900433 0.73831169 0.72878788 0.72857143\n",
            " 0.71991342 0.72424242 0.71969697 0.72424242 0.72922078 0.73354978\n",
            " 0.72424242 0.72402597 0.72402597 0.73809524 0.71948052 0.72402597\n",
            " 0.66428571 0.66428571 0.71038961 0.66904762 0.69199134 0.69177489\n",
            " 0.71017316 0.69199134 0.71926407 0.71471861 0.74264069 0.71969697\n",
            " 0.71471861 0.71948052 0.73333333 0.71038961 0.73311688 0.72380952\n",
            " 0.72424242 0.71471861 0.70995671 0.70974026 0.72445887 0.71450216\n",
            " 0.71948052 0.71450216 0.71969697 0.72900433 0.71969697 0.72900433\n",
            " 0.67813853 0.67813853 0.72922078 0.68766234 0.70151515 0.69220779\n",
            " 0.71558442 0.68744589 0.72489177 0.71580087 0.72467532 0.6969697\n",
            " 0.71017316 0.71493506 0.73398268 0.73376623 0.73809524 0.73831169\n",
            " 0.76147186 0.73852814 0.75670996 0.7521645  0.7521645  0.73376623\n",
            " 0.75670996 0.7521645  0.7521645  0.74761905 0.7521645  0.74761905\n",
            " 0.66839827 0.66839827 0.70519481 0.67294372 0.69134199 0.68203463\n",
            " 0.72424242 0.69588745 0.72402597 0.71471861 0.72922078 0.72857143\n",
            " 0.72445887 0.71969697 0.72900433 0.73831169 0.72878788 0.72857143\n",
            " 0.71991342 0.72424242 0.71969697 0.72424242 0.72922078 0.73354978\n",
            " 0.72424242 0.72402597 0.72402597 0.73809524 0.71948052 0.72402597\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.66839827 0.66839827 0.70519481 0.67294372 0.69134199 0.68203463\n",
            " 0.71948052 0.69588745 0.71948052 0.71017316 0.72922078 0.72857143\n",
            " 0.72445887 0.71969697 0.72424242 0.73354978 0.72878788 0.72857143\n",
            " 0.71991342 0.72900433 0.71969697 0.72424242 0.72922078 0.73354978\n",
            " 0.72424242 0.72402597 0.72402597 0.73809524 0.71948052 0.72402597\n",
            " 0.66428571 0.66428571 0.71038961 0.66904762 0.69199134 0.69177489\n",
            " 0.71017316 0.69199134 0.72380952 0.71926407 0.74264069 0.71969697\n",
            " 0.71471861 0.71948052 0.73333333 0.71038961 0.72857143 0.71926407\n",
            " 0.72424242 0.71471861 0.70995671 0.70974026 0.72445887 0.71450216\n",
            " 0.71948052 0.71450216 0.71969697 0.72900433 0.71969697 0.73376623\n",
            " 0.67813853 0.67813853 0.72467532 0.68766234 0.70151515 0.69220779\n",
            " 0.71082251 0.66926407 0.68722944 0.69220779 0.73852814 0.70151515\n",
            " 0.72900433 0.73376623 0.75238095 0.74329004 0.74761905 0.7478355\n",
            " 0.75692641 0.74329004 0.74307359 0.74329004 0.7478355  0.73874459\n",
            " 0.7478355  0.74329004 0.75692641 0.74805195 0.75692641 0.75238095\n",
            " 0.66839827 0.66839827 0.70519481 0.67294372 0.69134199 0.68203463\n",
            " 0.71948052 0.69588745 0.71948052 0.71017316 0.72922078 0.72857143\n",
            " 0.72445887 0.71969697 0.72424242 0.73354978 0.72878788 0.72857143\n",
            " 0.71991342 0.72900433 0.71969697 0.72424242 0.72922078 0.73354978\n",
            " 0.72424242 0.72402597 0.72402597 0.73809524 0.71948052 0.72402597\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.66839827 0.66839827 0.70519481 0.67294372 0.69134199 0.68203463\n",
            " 0.72424242 0.69588745 0.71948052 0.71017316 0.72922078 0.72857143\n",
            " 0.72445887 0.71969697 0.72424242 0.73354978 0.72878788 0.72857143\n",
            " 0.71991342 0.72900433 0.71969697 0.72424242 0.72922078 0.73354978\n",
            " 0.72424242 0.72402597 0.72402597 0.73809524 0.71948052 0.72402597\n",
            " 0.66428571 0.66428571 0.71038961 0.66904762 0.69199134 0.69177489\n",
            " 0.71017316 0.69199134 0.72380952 0.71926407 0.74264069 0.71969697\n",
            " 0.71471861 0.71948052 0.73333333 0.71038961 0.72857143 0.71926407\n",
            " 0.72424242 0.71471861 0.70995671 0.70974026 0.72445887 0.71450216\n",
            " 0.71948052 0.71450216 0.71969697 0.72900433 0.71969697 0.73376623\n",
            " 0.67813853 0.67813853 0.72467532 0.68766234 0.70151515 0.69220779\n",
            " 0.71082251 0.66926407 0.66904762 0.69220779 0.72034632 0.68333333\n",
            " 0.71082251 0.73376623 0.73419913 0.72510823 0.71991342 0.7478355\n",
            " 0.73874459 0.72510823 0.72489177 0.74329004 0.72965368 0.71580087\n",
            " 0.72965368 0.74329004 0.75692641 0.74329004 0.75692641 0.75238095\n",
            " 0.66839827 0.66839827 0.70519481 0.67294372 0.69134199 0.68203463\n",
            " 0.72424242 0.69588745 0.71948052 0.71017316 0.72922078 0.72857143\n",
            " 0.72445887 0.71969697 0.72424242 0.73354978 0.72878788 0.72857143\n",
            " 0.71991342 0.72900433 0.71969697 0.72424242 0.72922078 0.73354978\n",
            " 0.72424242 0.72402597 0.72402597 0.73809524 0.71948052 0.72402597\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.66839827 0.66839827 0.70519481 0.67294372 0.69134199 0.68203463\n",
            " 0.72424242 0.69588745 0.72402597 0.71471861 0.72922078 0.72857143\n",
            " 0.72445887 0.71969697 0.72900433 0.73831169 0.72878788 0.72857143\n",
            " 0.71991342 0.72424242 0.71969697 0.72424242 0.72922078 0.73354978\n",
            " 0.72424242 0.72402597 0.72402597 0.73809524 0.71948052 0.72402597\n",
            " 0.66428571 0.66428571 0.71038961 0.66904762 0.69199134 0.69177489\n",
            " 0.71017316 0.69199134 0.71926407 0.71471861 0.74264069 0.71969697\n",
            " 0.71471861 0.71948052 0.73333333 0.71038961 0.73311688 0.72380952\n",
            " 0.72424242 0.71471861 0.70995671 0.70974026 0.72445887 0.71450216\n",
            " 0.71948052 0.71450216 0.71969697 0.72900433 0.71969697 0.72900433\n",
            " 0.67813853 0.67813853 0.72922078 0.68766234 0.70151515 0.69220779\n",
            " 0.71558442 0.68744589 0.72489177 0.71580087 0.72467532 0.6969697\n",
            " 0.71017316 0.71493506 0.73398268 0.73376623 0.73809524 0.73831169\n",
            " 0.76147186 0.73852814 0.75670996 0.7521645  0.7521645  0.73376623\n",
            " 0.75670996 0.7521645  0.7521645  0.74761905 0.7521645  0.74761905\n",
            " 0.66839827 0.66839827 0.70519481 0.67294372 0.69134199 0.68203463\n",
            " 0.72424242 0.69588745 0.72402597 0.71471861 0.72922078 0.72857143\n",
            " 0.72445887 0.71969697 0.72900433 0.73831169 0.72878788 0.72857143\n",
            " 0.71991342 0.72424242 0.71969697 0.72424242 0.72922078 0.73354978\n",
            " 0.72424242 0.72402597 0.72402597 0.73809524 0.71948052 0.72402597\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ],
      "source": [
        "# Apply Grid Search to find best model and parameters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = [{'n_neighbors': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n",
        "               'weights':['uniform', 'distance'],\n",
        "               'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "               'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'wminkowski', 'seuclidean', 'mahalanobis']}]\n",
        "grid_search = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 10,\n",
        "                           n_jobs = -1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_accuracy = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
        "print(\"Best Parameters:\", best_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fti8z8kPFrtl",
        "outputId": "c4128f13-a5bc-42ea-d04a-1ec7c3dbeb41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(metric='chebyshev', n_neighbors=10)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Update model\n",
        "classifier = KNeighborsClassifier(n_neighbors = best_parameters['n_neighbors'], \n",
        "                                  weights = best_parameters['weights'],\n",
        "                                  algorithm = best_parameters['algorithm'],\n",
        "                                  metric = best_parameters['metric'],)\n",
        "classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "z2jfiiAD7goj",
        "outputId": "1eb9f26e-36fb-4563-c49c-d6f8d6029dce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 76.15 %\n",
            "Best Parameters: {'algorithm': 'auto', 'metric': 'chebyshev', 'n_neighbors': 10, 'weights': 'uniform'}\n"
          ]
        }
      ],
      "source": [
        "# use your model to make a prediction on unseen data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kwOiqNee7goj"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGgleoej7gok",
        "outputId": "24bedaee-f735-4a8e-d4d8-4e21813567e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[42  3]\n",
            " [25  2]]\n",
            "Accuracy: 76.15 %\n",
            "Standard Deviation: 4.39 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ],
      "source": [
        "# Asssess the accuracy of your model and explain your key findings\n",
        "# Generate confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Apply k-fold Cross Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDU85k7J7gok"
      },
      "source": [
        "### Unit tests:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq2QRpri7gol"
      },
      "source": [
        "#### Checking training and test data for null values. This will work for both pd dataframes and np arrays, and ensures no null values exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUeh38w_7gol"
      },
      "outputs": [],
      "source": [
        "def test_no_nulls(data):\n",
        "    \"\"\" Assert no null values within pd dataframe or np array \"\"\"\n",
        "    \n",
        "    # if data is numpy array, handle accordingly\n",
        "    if isinstance(data, (np.ndarray)):\n",
        "        assert not np.isnan(np.min(data))\n",
        "    \n",
        "    # if not np array, assume data is pandas dataframe\n",
        "    else:\n",
        "        assert data.isna().sum().sum() == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BV9Z1F3i7gom"
      },
      "outputs": [],
      "source": [
        "# run null data unit test on both training and test data\n",
        "test_no_nulls(x_train_processed)\n",
        "test_no_nulls(x_test_processed)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of KSVC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}