{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StickMonkey615/JHCSMod4/blob/main/ANN%20v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRn73TIW7gn9"
      },
      "source": [
        "# Module 4 Guidance\n",
        "\n",
        "This notebook is a template for module 4b and 4c, which will be tested in Google Colab, your code needs to run there.\n",
        "The structure has been provided to improve consistency and make it easier for markers to understand your code but still give students the flexibility to be creative.  You need to populate the required functions to solve this problem.  All dependencies should be documented in the next cell.\n",
        "\n",
        "You can:\n",
        "    add further cells or text blocks to extend or further explain your solution\n",
        "    add further functions\n",
        "\n",
        "Dont:\n",
        "    rename functions\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "I5Pj_LPoJcrT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZxOsuHxz7goC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a96c3b2-6dd7-4500-97b1-96c5e9da7803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (7.9.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.9.24)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.2.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.49.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.1)\n",
            "Installing collected packages: jedi, kt-legacy, keras-tuner\n",
            "Successfully installed jedi-0.18.1 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "# Fixed dependencies - do not remove or change.\n",
        "import pytest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/gdrive/')\n",
        "# Import your dependencies\n",
        "!pip install --upgrade xlrd > 1.2.0\n",
        "import xlrd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "!pip install keras-tuner --upgrade\n",
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1m_gmKQP7goE"
      },
      "outputs": [],
      "source": [
        "# Import data\n",
        "\n",
        "def import_local_data(file_path):\n",
        "    \"\"\"This function needs to import the data file into collab and return a pandas dataframe\n",
        "    \"\"\"\n",
        "    raw_df = pd.read_excel(file_path)\n",
        "    return raw_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cIljHljB7goF"
      },
      "outputs": [],
      "source": [
        "local_file_path = \"breast-cancer.xls\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LCu51H5Z7goF"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "raw_data = import_local_data(local_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9WDYKUP7goG"
      },
      "source": [
        "### Conduct exploratory data analysis and explain your key findings - Examine the data, explain its key features and what they look like.  Highlight any fields that are anomalous."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the different dataframe column headings\n",
        "print(raw_data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkjdfYHGiz7a",
        "outputId": "f894b574-c3a1-4226-cd11-b02041f3d378"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig',\n",
            "       'breast', 'breast-quad', 'irradiat', 'Class'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine data types for each column\n",
        "for i in range(0, len(raw_data.columns)):\n",
        "    print(type(raw_data.values[1][i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKqjAI-XigbI",
        "outputId": "cdcd10cb-74b0-4a9a-a924-973eaea91736"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'int'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Look at the range of values for each field\n",
        "from collections import Counter\n",
        "rng_vals=[]\n",
        "for i in range(0,len(raw_data.columns)):\n",
        "    rng_vals.append(Counter(raw_data.iloc[:,i].values))\n",
        "    print(f\"{raw_data.columns[i]}: {rng_vals[i]}\")\n",
        "del rng_vals, i"
      ],
      "metadata": {
        "id": "-lQUCdTe36Dp",
        "outputId": "92a0c1d4-026f-4c1a-b4f1-9ec4fa5b6392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age: Counter({'50-59': 96, '40-49': 90, '60-69': 57, '30-39': 36, '70-79': 6, '20-29': 1})\n",
            "menopause: Counter({'premeno': 150, 'ge40': 129, 'lt40': 7})\n",
            "tumor-size: Counter({'30-34': 60, '25-29': 54, '20-24': 50, '15-19': 30, datetime.datetime(2014, 10, 1, 0, 0): 28, '40-44': 22, '35-39': 19, '0-4': 8, '50-54': 8, datetime.datetime(2019, 9, 5, 0, 0): 4, '45-49': 3})\n",
            "inv-nodes: Counter({'0-2': 213, datetime.datetime(2019, 5, 3, 0, 0): 36, datetime.datetime(2019, 8, 6, 0, 0): 17, datetime.datetime(2019, 11, 9, 0, 0): 10, '15-17': 6, datetime.datetime(2014, 12, 1, 0, 0): 3, '24-26': 1})\n",
            "node-caps: Counter({'no': 222, 'yes': 56, '?': 8})\n",
            "deg-malig: Counter({2: 130, 3: 85, 1: 71})\n",
            "breast: Counter({'left': 152, 'right': 134})\n",
            "breast-quad: Counter({'left_low': 110, 'left_up': 97, 'right_up': 33, 'right_low': 24, 'central': 21, '?': 1})\n",
            "irradiat: Counter({'no': 218, 'yes': 68})\n",
            "Class: Counter({'no-recurrence-events': 201, 'recurrence-events': 85})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All fields look to contain data that is catagorical in nature.**\n",
        "\n",
        "**Some contain data that appears erroneous:**\n",
        " \n",
        "*   **'tumor-size' and 'inv-nodes' appear to contain some data in a datetime format and some in string.**\n",
        "*   **'node-caps' and 'breast-quad' contain Question Marks.**\n",
        "\n",
        "**Need a way to address these erroneous data inputs.**\n",
        "\n"
      ],
      "metadata": {
        "id": "lALFUx2EEQF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look in more detail at the columns with datetime data.\n",
        "print(raw_data.iloc[:, 2].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IetVwnCr3XI",
        "outputId": "735a5d9e-237d-450a-80df-cf422e14b0ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['15-19' '15-19' '35-39' '35-39' '30-34' '25-29' '40-44'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '0-4' '40-44' '25-29' '15-19'\n",
            " '30-34' '25-29' '25-29' '20-24' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '15-19' '40-44' '20-24' '20-24' '40-44' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '15-19' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '30-34' '15-19' '30-34' '25-29' '25-29' '20-24' '30-34' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '45-49' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '35-39' '25-29' '20-24'\n",
            " '15-19' '30-34' datetime.datetime(2014, 10, 1, 0, 0) '35-39' '50-54'\n",
            " '40-44' '15-19' '30-34' '0-4' '40-44' '25-29' '25-29' '20-24' '35-39'\n",
            " '50-54' '0-4' '40-44' '30-34' '20-24' '30-34' '20-24' '15-19' '25-29'\n",
            " '15-19' '50-54' datetime.datetime(2014, 10, 1, 0, 0) '25-29' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '15-19' '25-29' '25-29' '30-34'\n",
            " '15-19' '25-29' '30-34' '15-19' '0-4' '35-39' '40-44' '25-29' '20-24'\n",
            " '30-34' '20-24' '30-34' '20-24' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '20-24' '45-49' '40-44' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " '35-39' '20-24' '15-19' '30-34' '20-24' '20-24' '30-34' '20-24' '25-29'\n",
            " '30-34' '20-24' '15-19' '30-34' '30-34' '40-44'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '30-34' datetime.datetime(2014, 10, 1, 0, 0) '35-39' '20-24' '30-34'\n",
            " '25-29' '15-19' '35-39' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " '30-34' '25-29' '15-19' '15-19' '30-34' '35-39' '30-34' '25-29' '30-34'\n",
            " '15-19' '0-4' '0-4' '50-54' '30-34' '20-24' '25-29' '30-34' '20-24'\n",
            " '15-19' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '40-44' '30-34' '50-54' '15-19'\n",
            " '40-44' '25-29' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '25-29' '25-29' '30-34' '50-54'\n",
            " '30-34' '20-24' '30-34' '25-29' '20-24' '20-24' '50-54' '20-24' '30-34'\n",
            " '25-29' '25-29' '40-44' '20-24' '20-24' '25-29' '25-29' '20-24' '40-44'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '30-34'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) '15-19' '30-34' '25-29'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) '25-29' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '50-54' '25-29' '20-24'\n",
            " '30-34' '30-34' '15-19' '20-24' datetime.datetime(2019, 9, 5, 0, 0)\n",
            " '30-34' '30-34' '25-29' '25-29' '40-44' '25-29' '30-34' '30-34' '25-29'\n",
            " '25-29' '40-44' '20-24' '25-29' '20-24' '40-44' '25-29' '25-29' '45-49'\n",
            " '20-24' '25-29' '20-24' '20-24' '35-39' '20-24' '30-34' '25-29' '30-34'\n",
            " '25-29' '20-24' '20-24' datetime.datetime(2014, 10, 1, 0, 0) '15-19'\n",
            " '25-29' '20-24' '40-44' '15-19' '30-34' '30-34' '40-44' '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '40-44' '30-34' '30-34' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '25-29' '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '0-4' '25-29' '25-29'\n",
            " '40-44' '25-29' '30-34' '20-24' '20-24' '25-29' '30-34' '20-24' '30-34'\n",
            " '0-4' '20-24' '35-39' '30-34' '20-24' '25-29' '35-39' '20-24' '20-24'\n",
            " '35-39' '35-39' '25-29' '35-39' '30-34' '20-24' '15-19' '30-34' '25-29'\n",
            " '30-34' '15-19' '40-44']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at output data\n",
        "raw_data['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HePUlhNvfWF",
        "outputId": "585c888b-f91a-42a3-9ac5-824cb03d2906"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no-recurrence-events    201\n",
              "recurrence-events        85\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only 2 possible outputs, thus needs converting to binary format for use in classifier models."
      ],
      "metadata": {
        "id": "bkV5bQKKwYHj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KMB3eKfC7goU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f312434-bf18-44b4-b379-c96f30ead2d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True outputs: 29.72 %\n"
          ]
        }
      ],
      "source": [
        "# Check output balance\n",
        "out = raw_data.iloc[:, -1].values\n",
        "no_rows = len(raw_data)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "code_rows = le.fit_transform(out)\n",
        "print(\"True outputs: {:.2f} %\".format(sum(code_rows)/len(raw_data)*100))\n",
        "pos = sum(code_rows)\n",
        "neg = len(raw_data)-sum(code_rows)\n",
        "del out, no_rows, le, code_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clear imbalance between output data. Some degree of bias/weighting/sampling will be required to ensure that results accurately predict outcomes for both True and False outcomes."
      ],
      "metadata": {
        "id": "mMo9-0hTwirc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f02MTYgB7goW"
      },
      "outputs": [],
      "source": [
        "# Explain your key findings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data set is made up of 9 independent variables all of which appear catagorical in nature. Although stored as an integer, 'deg-malig' can be viewed as  catagorical data as it can only contain 3 discrete values.**\n",
        "\n",
        "**The inclusion of datetime data entries in both the 'tumor-size' and 'inv-nodes' fields appears to be caused by a formatting entry within Excel. For example, '10-14' being input erroneously as 10/14 thus Excel has interpreted (and converted) it to the datetime field 01/10/2014. A function will need to be written within the model to convert these back to correct format.**\n",
        "\n",
        "**How to deal with '?' entries in fields that are otherwise boolean poses an interesting dilemma. If these are infact meant to signify that the presence is unknown because no diagnostic work has been conducted, then this woiuld signify a valid dat entry. If it is however just an incomplete data entry then there is a risk its inclusion could skew the model results. Without knowing which it seems wisest to remove this data from the dataset. Removal of the entire field could well deprive the model of important information, thus just removing these specific entries (rows) appears the most sensible option, particularly noting that there are relatively few occurences.**\n",
        "\n",
        "**Data set is imbalanced, with dependent variable outputs only True in 30% of instances. The model applied will require this imbalance to be taken into account so as not to sacrifice results predicting this smaller class (surely the aim of cancer diagnosis) so as to achieve a high accuracy figure.**\n",
        "\n",
        "**Output variable will need converting into binary output for use with a binary classification model.**"
      ],
      "metadata": {
        "id": "V7OWyLcOrgWJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzZj8I8G7goX"
      },
      "source": [
        "###Create any data pre-processing that you will conduct on seen and unseen data.  Regardless of the model you use, this dataframe must contain only numeric features and have a strategy for any expected missing values. Any objects can that are needed to handle the test data that are dependent on the training data can be stored in the model class.  You are recommended to use sklearn Pipelines or similar functionality to ensure reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct date types in 'tumor-size' and 'inv-nodes' variables\n",
        "for i in range(0, len(raw_data)):\n",
        "    if type(raw_data['tumor-size'][i]) is not str:\n",
        "        if raw_data['tumor-size'][i].day == 1:\n",
        "            raw_data['tumor-size'][i] = str(raw_data['tumor-size'][i].month) +'-' + str(raw_data['tumor-size'][i].year-2000)\n",
        "        else:\n",
        "            raw_data['tumor-size'][i] = str(raw_data['tumor-size'][i].day) + '-' + str(raw_data['tumor-size'][i].month)\n",
        "    if type(raw_data['inv-nodes'][i]) is not str:\n",
        "        if raw_data['inv-nodes'][i].day == 1:\n",
        "            raw_data['inv-nodes'][i] = str(raw_data['inv-nodes'][i].month) + '-' + str(raw_data['inv-nodes'][i].year-2000)\n",
        "        else:\n",
        "            raw_data['inv-nodes'][i] = str(raw_data['inv-nodes'][i].day) + '-' + str(raw_data['inv-nodes'][i].month)        "
      ],
      "metadata": {
        "id": "GlZwiMllRpUB",
        "outputId": "33849546-0cc4-49a6-cfcc-2930777bd00c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all rows containing ? data\n",
        "indx = raw_data[raw_data.isin(['?'])].stack(dropna=True).unstack().index\n",
        "print(f\"indx: {indx}\")\n",
        "raw_data = raw_data.drop(index=indx)"
      ],
      "metadata": {
        "id": "ThhbSU5gPBYA",
        "outputId": "a454b0b9-0cf8-417e-e062-3bde7d28c445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indx: Int64Index([20, 31, 50, 54, 71, 92, 149, 240, 264], dtype='int64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WIh9_0pp7goY"
      },
      "outputs": [],
      "source": [
        "# Split your data so that you can test the effectiveness of your model\n",
        "# Split the data into a Training set and a Test set\n",
        "dfs = np.split(raw_data, [len(raw_data.columns)-1], axis=1)\n",
        "X = dfs[0]\n",
        "y = dfs[1]\n",
        "\n",
        "# Handle categorical values and drop dummy variable\n",
        "# Remove non-categorical data\n",
        "dm = X.pop('deg-malig')\n",
        "# Encode the catagorical data (dummy variables)\n",
        "proc_X = pd.get_dummies(data=X, prefix_sep='_', drop_first=True)\n",
        "# Add back in non-categorical data\n",
        "proc_X.insert(0, 'deg-malig', dm)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(proc_X, y, test_size = 0.25, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate class weights\n",
        "weight_0 = (1 / neg) * ((pos + neg) / 2)\n",
        "weight_1 = (1 / pos) * ((pos + neg) / 2)\n",
        "class_weight = np.log([pos/neg])\n",
        "class_weight_dict = {0: weight_0, 1: weight_1}\n",
        "print(f\"Weight for 0: {weight_0}\")\n",
        "print(f\"Weight for 1: {weight_1}\")"
      ],
      "metadata": {
        "id": "CtCPaYUj8dcn",
        "outputId": "f0436d75-368b-4c92-d632-3b19195f854f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight for 0: 0.7114427860696517\n",
            "Weight for 1: 1.6823529411764706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AbOQACY77goY"
      },
      "outputs": [],
      "source": [
        "# Populate preprocess_training_data and preprocess_test_data to preprocess data.\n",
        "# You must process test and train separately so your model does not accidently gain information that a model wouldnt have in reality and therefore get better predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Xsq2f8747goZ"
      },
      "outputs": [],
      "source": [
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "class Module4_Model:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.metrics = [\n",
        "            keras.metrics.TruePositives(name='tp'),\n",
        "            keras.metrics.FalsePositives(name='fp'),\n",
        "            keras.metrics.TrueNegatives(name='tn'),\n",
        "            keras.metrics.FalseNegatives(name='fn'),\n",
        "            keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "            keras.metrics.Recall(name='recall'),\n",
        "            keras.metrics.Precision(name='precision'),\n",
        "            keras.metrics.AUC(name='prc', curve='PR'),\n",
        "            keras.metrics.SensitivityAtSpecificity(name='sen',specificity=0.8)\n",
        "        ]\n",
        "        self.EPOCHS = 500\n",
        "        self.BATCH = 100\n",
        "        self.THR = 0.3\n",
        "        self.stop_crit = keras.callbacks.EarlyStopping(\n",
        "            monitor='val_prc',\n",
        "            verbose=1,\n",
        "            patience=100,\n",
        "            mode='max',\n",
        "            restore_best_weights=True)\n",
        "\n",
        "    def preprocess_training_data(self, training_df):\n",
        "        \"\"\"\n",
        "        This function should process the training data and store any features\n",
        "        required in the class\n",
        "        \"\"\"         \n",
        "        # Apply feature scaling\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "        sc = StandardScaler()\n",
        "        processed_df = sc.fit_transform(training_df)\n",
        "        return processed_df, sc\n",
        "\n",
        "    def preprocess_test_data(self, test_df):\n",
        "        \"\"\"\n",
        "        This function should process the test data and store any features\n",
        "        required in the class\n",
        "        \"\"\"\n",
        "        # Apply feature scaling\n",
        "        processed_df = self.scalar.transform(test_df)\n",
        "        return processed_df\n",
        "\n",
        "    def make_model(self,hp):\n",
        "        model = keras.Sequential()\n",
        "        output_bias = keras.initializers.Constant(class_weight)\n",
        "        # Tune the number of units in each layer\n",
        "        hp_units1 = hp.Int('units1',min_value=16,max_value=128,step=2)\n",
        "        hp_units2 = hp.Int('units2',min_value=16,max_value=64,step=2)\n",
        "        hp_units3 = hp.Int('units3',min_value=16,max_value=32,step=2)\n",
        "\n",
        "        model.add(Dense(hp_units1,\n",
        "                        activation=hp.Choice(\n",
        "                            name='dense_activation1',\n",
        "                            values=['tanh','relu','selu','leaky-relu'],\n",
        "                            default='selu'),\n",
        "                        input_shape=(x_train_processed.shape[-1],),\n",
        "                        kernel_initializer='lecun_normal'\n",
        "                        ))\n",
        "        #model.add(Dropout(0.5))\n",
        "        model.add(Dense(hp_units2,\n",
        "                        activation=hp.Choice(\n",
        "                            name='dense_activation2',\n",
        "                            values=['tanh','relu','selu','leaky-relu'],\n",
        "                            default='leaky-relu'),\n",
        "                        kernel_initializer='lecun_normal'\n",
        "                        ))\n",
        "        model.add(Dense(hp_units3,\n",
        "                        activation=hp.Choice(\n",
        "                            name='dense_activation3',\n",
        "                            values=['tanh','relu','selu','leaky-relu'],\n",
        "                            default='leaky-relu'),\n",
        "                        kernel_initializer='lecun_normal'\n",
        "                        ))\n",
        "        model.add(Dense(1,kernel_initializer='normal',activation='sigmoid',bias_initializer=output_bias))\n",
        "        hp_learning_rate = hp.Choice('learning_rate',values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adamax(learning_rate=hp_learning_rate),\n",
        "            loss=keras.losses.BinaryCrossentropy(),\n",
        "            metrics=self.metrics)\n",
        "        \n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "F3LiNNCb7goa"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "my_model = Module4_Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZQD7WPdN7god"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "x_train_processed, my_model.scalar = my_model.preprocess_training_data(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the output data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb = LabelEncoder()\n",
        "y_train = pd.DataFrame(lb.fit_transform(y_train))\n",
        "y_test = pd.DataFrame(lb.transform(y_test))"
      ],
      "metadata": {
        "id": "xZNGF1UxWGU5",
        "outputId": "0949a52f-2332-4880-f3b4-d64850a5bd85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create model and train"
      ],
      "metadata": {
        "id": "deUEPqVyJUpX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XnLHgaXS7goe"
      },
      "outputs": [],
      "source": [
        "# Create a model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "from keras.layers import LeakyReLU,ELU,PReLU,Dropout\n",
        "from keras.losses import MeanSquaredLogarithmicError\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "msle = MeanSquaredLogarithmicError()\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.3))})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilise HyperBand algorithm from keras tuner to construct model\n",
        "tuner = kt.Hyperband(\n",
        "    my_model.make_model,\n",
        "    objective=kt.Objective('sen', direction='max'),\n",
        "    max_epochs=50,\n",
        "    directory='keras_tuner_dir',\n",
        "    project_name='keras_tuner',\n",
        ")\n",
        "tuner.search(x_train_processed,y_train,epochs=50,validation_split=0.2)"
      ],
      "metadata": {
        "id": "p1Ph9bZMV5G6",
        "outputId": "ef7f9a51-fb70-40bc-a04a-3dfbcd940e22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 06s]\n",
            "sen: 0.6851851940155029\n",
            "\n",
            "Best sen So Far: 1.0\n",
            "Total elapsed time: 00h 06m 11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rQwUj4lk7goe"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "x_test_processed = my_model.preprocess_test_data(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for h_param in [f\"units{i}\" for i in range(1,4)] + ['learning_rate'] + [f\"dense_activation{i}\" for i in range(1,4)]:\n",
        "    print(h_param, tuner.get_best_hyperparameters()[0].get(h_param))\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "HuWZxfcvYOI4",
        "outputId": "36bfa556-42e3-426f-a970-fef93a701683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "units1 76\n",
            "units2 50\n",
            "units3 28\n",
            "learning_rate 0.01\n",
            "dense_activation1 relu\n",
            "dense_activation2 selu\n",
            "dense_activation3 selu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.best_model = tuner.get_best_models()[0]\n",
        "my_model.best_model.build(x_train_processed.shape)\n",
        "my_model.best_model.summary()"
      ],
      "metadata": {
        "id": "Lku4uguEY1ar",
        "outputId": "b19f8306-8d6c-476d-b667-52cfbef20936",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 76)                2432      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 50)                3850      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 28)                1428      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 29        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,739\n",
            "Trainable params: 7,739\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the best model (with class weights)\n",
        "my_model.best_model.fit(x_train_processed,\n",
        "                   y_train,\n",
        "                   batch_size=my_model.BATCH,\n",
        "                   epochs=my_model.EPOCHS,\n",
        "                   callbacks=[my_model.stop_crit],\n",
        "                   validation_split=0.2,\n",
        "                   class_weight=class_weight_dict)"
      ],
      "metadata": {
        "id": "DFAWtazI9LH4",
        "outputId": "f3b0f782-6cd1-49f7-c574-6b0f2470d89a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.1796 - tp: 50.0000 - fp: 7.0000 - tn: 138.0000 - fn: 12.0000 - accuracy: 0.9082 - recall: 0.8065 - precision: 0.8772 - prc: 0.9407 - sen: 0.9355 - val_loss: 1.1542 - val_tp: 3.0000 - val_fp: 9.0000 - val_tn: 25.0000 - val_fn: 5.0000 - val_accuracy: 0.6667 - val_recall: 0.3750 - val_precision: 0.2500 - val_prc: 0.1972 - val_sen: 0.1250\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.1638 - tp: 50.0000 - fp: 4.0000 - tn: 107.0000 - fn: 4.0000 - accuracy: 0.9515 - recall: 0.9259 - precision: 0.9259 - prc: 0.9807 - sen: 1.0000 - val_loss: 1.2606 - val_tp: 3.0000 - val_fp: 10.0000 - val_tn: 24.0000 - val_fn: 5.0000 - val_accuracy: 0.6429 - val_recall: 0.3750 - val_precision: 0.2308 - val_prc: 0.1926 - val_sen: 0.1250\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1374 - tp: 51.0000 - fp: 7.0000 - tn: 104.0000 - fn: 3.0000 - accuracy: 0.9394 - recall: 0.9444 - precision: 0.8793 - prc: 0.9850 - sen: 1.0000 - val_loss: 1.3731 - val_tp: 4.0000 - val_fp: 13.0000 - val_tn: 21.0000 - val_fn: 4.0000 - val_accuracy: 0.5952 - val_recall: 0.5000 - val_precision: 0.2353 - val_prc: 0.1940 - val_sen: 0.2500\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.1350 - tp: 53.0000 - fp: 10.0000 - tn: 101.0000 - fn: 1.0000 - accuracy: 0.9333 - recall: 0.9815 - precision: 0.8413 - prc: 0.9846 - sen: 1.0000 - val_loss: 1.4516 - val_tp: 4.0000 - val_fp: 15.0000 - val_tn: 19.0000 - val_fn: 4.0000 - val_accuracy: 0.5476 - val_recall: 0.5000 - val_precision: 0.2105 - val_prc: 0.1972 - val_sen: 0.2500\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1328 - tp: 54.0000 - fp: 10.0000 - tn: 101.0000 - fn: 0.0000e+00 - accuracy: 0.9394 - recall: 1.0000 - precision: 0.8438 - prc: 0.9868 - sen: 1.0000 - val_loss: 1.4530 - val_tp: 4.0000 - val_fp: 15.0000 - val_tn: 19.0000 - val_fn: 4.0000 - val_accuracy: 0.5476 - val_recall: 0.5000 - val_precision: 0.2105 - val_prc: 0.2004 - val_sen: 0.2500\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1229 - tp: 53.0000 - fp: 9.0000 - tn: 102.0000 - fn: 1.0000 - accuracy: 0.9394 - recall: 0.9815 - precision: 0.8548 - prc: 0.9874 - sen: 1.0000 - val_loss: 1.4173 - val_tp: 4.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 4.0000 - val_accuracy: 0.6190 - val_recall: 0.5000 - val_precision: 0.2500 - val_prc: 0.1999 - val_sen: 0.2500\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1106 - tp: 53.0000 - fp: 5.0000 - tn: 106.0000 - fn: 1.0000 - accuracy: 0.9636 - recall: 0.9815 - precision: 0.9138 - prc: 0.9902 - sen: 1.0000 - val_loss: 1.3837 - val_tp: 3.0000 - val_fp: 10.0000 - val_tn: 24.0000 - val_fn: 5.0000 - val_accuracy: 0.6429 - val_recall: 0.3750 - val_precision: 0.2308 - val_prc: 0.2025 - val_sen: 0.2500\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1121 - tp: 50.0000 - fp: 4.0000 - tn: 107.0000 - fn: 4.0000 - accuracy: 0.9515 - recall: 0.9259 - precision: 0.9259 - prc: 0.9896 - sen: 1.0000 - val_loss: 1.3720 - val_tp: 2.0000 - val_fp: 10.0000 - val_tn: 24.0000 - val_fn: 6.0000 - val_accuracy: 0.6190 - val_recall: 0.2500 - val_precision: 0.1667 - val_prc: 0.2041 - val_sen: 0.2500\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1089 - tp: 50.0000 - fp: 2.0000 - tn: 109.0000 - fn: 4.0000 - accuracy: 0.9636 - recall: 0.9259 - precision: 0.9615 - prc: 0.9900 - sen: 1.0000 - val_loss: 1.4156 - val_tp: 3.0000 - val_fp: 10.0000 - val_tn: 24.0000 - val_fn: 5.0000 - val_accuracy: 0.6429 - val_recall: 0.3750 - val_precision: 0.2308 - val_prc: 0.2040 - val_sen: 0.2500\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1007 - tp: 52.0000 - fp: 2.0000 - tn: 109.0000 - fn: 2.0000 - accuracy: 0.9758 - recall: 0.9630 - precision: 0.9630 - prc: 0.9916 - sen: 1.0000 - val_loss: 1.4863 - val_tp: 3.0000 - val_fp: 13.0000 - val_tn: 21.0000 - val_fn: 5.0000 - val_accuracy: 0.5714 - val_recall: 0.3750 - val_precision: 0.1875 - val_prc: 0.2048 - val_sen: 0.2500\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0935 - tp: 54.0000 - fp: 7.0000 - tn: 104.0000 - fn: 0.0000e+00 - accuracy: 0.9576 - recall: 1.0000 - precision: 0.8852 - prc: 0.9939 - sen: 1.0000 - val_loss: 1.5495 - val_tp: 3.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 5.0000 - val_accuracy: 0.5476 - val_recall: 0.3750 - val_precision: 0.1765 - val_prc: 0.2026 - val_sen: 0.2500\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0904 - tp: 54.0000 - fp: 7.0000 - tn: 104.0000 - fn: 0.0000e+00 - accuracy: 0.9576 - recall: 1.0000 - precision: 0.8852 - prc: 0.9946 - sen: 1.0000 - val_loss: 1.5828 - val_tp: 3.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 5.0000 - val_accuracy: 0.5476 - val_recall: 0.3750 - val_precision: 0.1765 - val_prc: 0.2125 - val_sen: 0.2500\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0861 - tp: 54.0000 - fp: 6.0000 - tn: 105.0000 - fn: 0.0000e+00 - accuracy: 0.9636 - recall: 1.0000 - precision: 0.9000 - prc: 0.9950 - sen: 1.0000 - val_loss: 1.5933 - val_tp: 3.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 5.0000 - val_accuracy: 0.5476 - val_recall: 0.3750 - val_precision: 0.1765 - val_prc: 0.1993 - val_sen: 0.2500\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 0.0826 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9951 - sen: 1.0000 - val_loss: 1.5991 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1959 - val_sen: 0.2500\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0796 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9943 - sen: 1.0000 - val_loss: 1.6215 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1945 - val_sen: 0.2500\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 0.0755 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9957 - sen: 1.0000 - val_loss: 1.6707 - val_tp: 2.0000 - val_fp: 13.0000 - val_tn: 21.0000 - val_fn: 6.0000 - val_accuracy: 0.5476 - val_recall: 0.2500 - val_precision: 0.1333 - val_prc: 0.2077 - val_sen: 0.2500\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0731 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9965 - sen: 1.0000 - val_loss: 1.7070 - val_tp: 3.0000 - val_fp: 13.0000 - val_tn: 21.0000 - val_fn: 5.0000 - val_accuracy: 0.5714 - val_recall: 0.3750 - val_precision: 0.1875 - val_prc: 0.2021 - val_sen: 0.2500\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0705 - tp: 54.0000 - fp: 5.0000 - tn: 106.0000 - fn: 0.0000e+00 - accuracy: 0.9697 - recall: 1.0000 - precision: 0.9153 - prc: 0.9968 - sen: 1.0000 - val_loss: 1.7206 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2032 - val_sen: 0.2500\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0656 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9978 - sen: 1.0000 - val_loss: 1.7189 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.1949 - val_sen: 0.2500\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0694 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9968 - sen: 1.0000 - val_loss: 1.7303 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.1974 - val_sen: 0.2500\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0644 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9975 - sen: 1.0000 - val_loss: 1.7968 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.1949 - val_sen: 0.2500\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0588 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9979 - sen: 1.0000 - val_loss: 1.8523 - val_tp: 3.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 5.0000 - val_accuracy: 0.5952 - val_recall: 0.3750 - val_precision: 0.2000 - val_prc: 0.2043 - val_sen: 0.2500\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0591 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9974 - sen: 1.0000 - val_loss: 1.8853 - val_tp: 3.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 5.0000 - val_accuracy: 0.5952 - val_recall: 0.3750 - val_precision: 0.2000 - val_prc: 0.2027 - val_sen: 0.2500\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0566 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 1.8972 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1924 - val_sen: 0.2500\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.0536 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9979 - sen: 1.0000 - val_loss: 1.9079 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1920 - val_sen: 0.2500\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0519 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9974 - sen: 1.0000 - val_loss: 1.9327 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1896 - val_sen: 0.2500\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0512 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 1.9557 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2014 - val_sen: 0.2500\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0504 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 1.9772 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1916 - val_sen: 0.2500\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0484 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.0123 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1902 - val_sen: 0.2500\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0467 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.0378 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1909 - val_sen: 0.2500\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 0.0457 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9979 - sen: 1.0000 - val_loss: 2.0472 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2035 - val_sen: 0.2500\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0459 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.0559 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2031 - val_sen: 0.2500\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.0446 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.0755 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.1988 - val_sen: 0.2500\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0440 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.0958 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.1974 - val_sen: 0.2500\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0433 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9975 - sen: 1.0000 - val_loss: 2.1258 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.1960 - val_sen: 0.2500\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.0420 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.1479 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.1942 - val_sen: 0.2500\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0429 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.1636 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.1950 - val_sen: 0.2500\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0405 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.2010 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1957 - val_sen: 0.2500\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0410 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.2194 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1963 - val_sen: 0.2500\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0400 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9985 - sen: 1.0000 - val_loss: 2.2204 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1963 - val_sen: 0.2500\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.0398 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9974 - sen: 1.0000 - val_loss: 2.2093 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.1969 - val_sen: 0.2500\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0401 - tp: 53.0000 - fp: 2.0000 - tn: 109.0000 - fn: 1.0000 - accuracy: 0.9818 - recall: 0.9815 - precision: 0.9636 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.2062 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.1968 - val_sen: 0.2500\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0418 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - sen: 1.0000 - val_loss: 2.2373 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1956 - val_sen: 0.2500\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0380 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.2676 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1950 - val_sen: 0.2500\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0414 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - sen: 1.0000 - val_loss: 2.3047 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2159 - val_sen: 0.2500\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.0379 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.3138 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2159 - val_sen: 0.2500\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0381 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.3160 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1957 - val_sen: 0.2500\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 0.0393 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.3183 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.1968 - val_sen: 0.2500\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0373 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.3301 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.1963 - val_sen: 0.2500\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.0375 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.3448 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.1957 - val_sen: 0.2500\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0377 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9975 - sen: 1.0000 - val_loss: 2.3637 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2177 - val_sen: 0.2500\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0362 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9979 - sen: 1.0000 - val_loss: 2.3712 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2182 - val_sen: 0.2500\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0380 - tp: 53.0000 - fp: 3.0000 - tn: 108.0000 - fn: 1.0000 - accuracy: 0.9758 - recall: 0.9815 - precision: 0.9464 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.3862 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2167 - val_sen: 0.2500\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0376 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.3941 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2179 - val_sen: 0.2500\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0365 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.4037 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2179 - val_sen: 0.2500\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0356 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.4128 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2179 - val_sen: 0.2500\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0362 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.4331 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2189 - val_sen: 0.2500\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0358 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.4482 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2184 - val_sen: 0.2500\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0366 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.4541 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2184 - val_sen: 0.2500\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0351 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.4690 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2174 - val_sen: 0.2500\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0338 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.4904 - val_tp: 2.0000 - val_fp: 13.0000 - val_tn: 21.0000 - val_fn: 6.0000 - val_accuracy: 0.5476 - val_recall: 0.2500 - val_precision: 0.1333 - val_prc: 0.2174 - val_sen: 0.2500\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0360 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.4973 - val_tp: 2.0000 - val_fp: 13.0000 - val_tn: 21.0000 - val_fn: 6.0000 - val_accuracy: 0.5476 - val_recall: 0.2500 - val_precision: 0.1333 - val_prc: 0.2204 - val_sen: 0.2500\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0387 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9975 - sen: 1.0000 - val_loss: 2.4982 - val_tp: 2.0000 - val_fp: 13.0000 - val_tn: 21.0000 - val_fn: 6.0000 - val_accuracy: 0.5476 - val_recall: 0.2500 - val_precision: 0.1333 - val_prc: 0.2189 - val_sen: 0.2500\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0360 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9974 - sen: 1.0000 - val_loss: 2.5056 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2189 - val_sen: 0.2500\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.0371 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - sen: 1.0000 - val_loss: 2.5042 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2172 - val_sen: 0.2500\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0388 - tp: 53.0000 - fp: 3.0000 - tn: 108.0000 - fn: 1.0000 - accuracy: 0.9758 - recall: 0.9815 - precision: 0.9464 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.4846 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2126 - val_sen: 0.2500\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.0354 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.4966 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2139 - val_sen: 0.2500\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 0.0333 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.5087 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2164 - val_sen: 0.2500\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.0344 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.5107 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2128 - val_sen: 0.2500\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0353 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9975 - sen: 1.0000 - val_loss: 2.5196 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2128 - val_sen: 0.2500\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0341 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - sen: 1.0000 - val_loss: 2.5226 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2124 - val_sen: 0.2500\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0363 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9975 - sen: 1.0000 - val_loss: 2.5245 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2112 - val_sen: 0.2500\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0348 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.5548 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2174 - val_sen: 0.2500\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0333 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.5553 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2139 - val_sen: 0.2500\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0353 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - sen: 1.0000 - val_loss: 2.5496 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2139 - val_sen: 0.2500\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0324 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9985 - sen: 1.0000 - val_loss: 2.5397 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2133 - val_sen: 0.2500\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0353 - tp: 53.0000 - fp: 3.0000 - tn: 108.0000 - fn: 1.0000 - accuracy: 0.9758 - recall: 0.9815 - precision: 0.9464 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.5360 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2166 - val_sen: 0.2500\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0351 - tp: 53.0000 - fp: 3.0000 - tn: 108.0000 - fn: 1.0000 - accuracy: 0.9758 - recall: 0.9815 - precision: 0.9464 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.5621 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2133 - val_sen: 0.2500\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0357 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9969 - sen: 1.0000 - val_loss: 2.5847 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2128 - val_sen: 0.2500\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0323 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.5775 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2128 - val_sen: 0.2500\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0337 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.5832 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2128 - val_sen: 0.2500\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0337 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.5916 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2128 - val_sen: 0.2500\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0322 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.6158 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2133 - val_sen: 0.2500\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.0333 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.6450 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2194 - val_sen: 0.2500\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0369 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.6499 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2194 - val_sen: 0.2500\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0375 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.6149 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2141 - val_sen: 0.2500\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0334 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.6061 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2133 - val_sen: 0.2500\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0325 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.5875 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0363 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.5937 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.0337 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.6275 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2133 - val_sen: 0.2500\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0354 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.6682 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2169 - val_sen: 0.2500\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.0362 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.6704 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2162 - val_sen: 0.2500\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.0353 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.6378 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2156 - val_sen: 0.2500\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0335 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.6137 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2139 - val_sen: 0.2500\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0346 - tp: 53.0000 - fp: 2.0000 - tn: 109.0000 - fn: 1.0000 - accuracy: 0.9818 - recall: 0.9815 - precision: 0.9636 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.6051 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2162 - val_sen: 0.2500\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0332 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.6384 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2133 - val_sen: 0.2500\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0313 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9985 - sen: 1.0000 - val_loss: 2.6765 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2128 - val_sen: 0.2500\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0333 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.7019 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2124 - val_sen: 0.2500\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0338 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - sen: 1.0000 - val_loss: 2.6857 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2124 - val_sen: 0.2500\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0327 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.6602 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2116 - val_sen: 0.2500\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0331 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.6454 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.0336 - tp: 53.0000 - fp: 2.0000 - tn: 109.0000 - fn: 1.0000 - accuracy: 0.9818 - recall: 0.9815 - precision: 0.9636 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.6472 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2139 - val_sen: 0.2500\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0336 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9982 - sen: 1.0000 - val_loss: 2.6732 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2149 - val_sen: 0.2500\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0324 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9985 - sen: 1.0000 - val_loss: 2.6824 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2149 - val_sen: 0.2500\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0345 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.6766 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2166 - val_sen: 0.2500\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0335 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.6685 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2149 - val_sen: 0.2500\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0334 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.6662 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2139 - val_sen: 0.2500\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0360 - tp: 53.0000 - fp: 3.0000 - tn: 108.0000 - fn: 1.0000 - accuracy: 0.9758 - recall: 0.9815 - precision: 0.9464 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.6961 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2128 - val_sen: 0.2500\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0313 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9986 - sen: 1.0000 - val_loss: 2.7407 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2124 - val_sen: 0.2500\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0327 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.7600 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2139 - val_sen: 0.2500\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0376 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - sen: 1.0000 - val_loss: 2.7551 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2139 - val_sen: 0.2500\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0350 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.7137 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2076 - val_sen: 0.2500\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0320 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9985 - sen: 1.0000 - val_loss: 2.6761 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 0.0339 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.6723 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0328 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.6973 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.0308 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9985 - sen: 1.0000 - val_loss: 2.7256 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2128 - val_sen: 0.2500\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0360 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9973 - sen: 1.0000 - val_loss: 2.7373 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2149 - val_sen: 0.2500\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.0361 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9973 - sen: 1.0000 - val_loss: 2.7166 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2133 - val_sen: 0.2500\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0331 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9975 - sen: 1.0000 - val_loss: 2.7154 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2133 - val_sen: 0.2500\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0313 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9985 - sen: 1.0000 - val_loss: 2.6952 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0358 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9973 - sen: 1.0000 - val_loss: 2.6956 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2101 - val_sen: 0.2500\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0330 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - sen: 1.0000 - val_loss: 2.7236 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2133 - val_sen: 0.2500\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.0316 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.7588 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2124 - val_sen: 0.2500\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0326 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.7736 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2124 - val_sen: 0.2500\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0322 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9985 - sen: 1.0000 - val_loss: 2.7539 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0346 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9970 - sen: 1.0000 - val_loss: 2.7302 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0329 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - sen: 1.0000 - val_loss: 2.7259 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0317 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.7306 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2133 - val_sen: 0.2500\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0324 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.7375 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2133 - val_sen: 0.2500\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0314 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.7295 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2133 - val_sen: 0.2500\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0318 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.7246 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2146 - val_sen: 0.2500\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0315 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.7170 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2116 - val_sen: 0.2500\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0336 - tp: 53.0000 - fp: 3.0000 - tn: 108.0000 - fn: 1.0000 - accuracy: 0.9758 - recall: 0.9815 - precision: 0.9464 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.7267 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2116 - val_sen: 0.2500\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0350 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9975 - sen: 1.0000 - val_loss: 2.7634 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.0309 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.7646 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0328 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - sen: 1.0000 - val_loss: 2.7685 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0319 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.7663 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0331 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9977 - sen: 1.0000 - val_loss: 2.7653 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2076 - val_sen: 0.2500\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0309 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9982 - sen: 1.0000 - val_loss: 2.7628 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2141 - val_sen: 0.2500\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0325 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.7505 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2172 - val_sen: 0.2500\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.0325 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.7589 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2141 - val_sen: 0.2500\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0328 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9975 - sen: 1.0000 - val_loss: 2.7598 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2146 - val_sen: 0.2500\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0320 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.7574 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0311 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.7557 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2084 - val_sen: 0.2500\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0312 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.7668 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2092 - val_sen: 0.2500\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0321 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.7863 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2076 - val_sen: 0.2500\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0311 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - sen: 1.0000 - val_loss: 2.7904 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2076 - val_sen: 0.2500\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 0.0312 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9979 - sen: 1.0000 - val_loss: 2.7786 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0318 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.7717 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0348 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - sen: 1.0000 - val_loss: 2.7775 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2084 - val_sen: 0.2500\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 0.0307 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.7906 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0318 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - sen: 1.0000 - val_loss: 2.8073 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0316 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - sen: 1.0000 - val_loss: 2.8074 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2076 - val_sen: 0.2500\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0320 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - sen: 1.0000 - val_loss: 2.7975 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2092 - val_sen: 0.2500\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0315 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - sen: 1.0000 - val_loss: 2.8071 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2100 - val_sen: 0.2500\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0317 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.8304 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2084 - val_sen: 0.2500\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0335 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.8532 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2084 - val_sen: 0.2500\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0321 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - sen: 1.0000 - val_loss: 2.8321 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2084 - val_sen: 0.2500\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0310 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - sen: 1.0000 - val_loss: 2.8023 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2084 - val_sen: 0.2500\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0360 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9970 - sen: 1.0000 - val_loss: 2.7839 - val_tp: 2.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 6.0000 - val_accuracy: 0.5952 - val_recall: 0.2500 - val_precision: 0.1538 - val_prc: 0.2101 - val_sen: 0.2500\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0371 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9971 - sen: 1.0000 - val_loss: 2.8280 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2076 - val_sen: 0.2500\n",
            "Epoch 162/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0243 - tp: 33.0000 - fp: 1.0000 - tn: 66.0000 - fn: 0.0000e+00 - accuracy: 0.9900 - recall: 1.0000 - precision: 0.9706 - prc: 0.9991 - sen: 1.0000Restoring model weights from the end of the best epoch: 62.\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.0345 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9966 - sen: 1.0000 - val_loss: 2.8403 - val_tp: 2.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 6.0000 - val_accuracy: 0.5714 - val_recall: 0.2500 - val_precision: 0.1429 - val_prc: 0.2069 - val_sen: 0.2500\n",
            "Epoch 162: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6f31922550>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualise the loss and accuracy for each epoch"
      ],
      "metadata": {
        "id": "G9DPmZDDXEnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(my_model.best_model.history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "84wnXBf0XDyz",
        "outputId": "5861fbd0-4d93-4380-8ca3-907eb95ddbaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(my_model.best_model.history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c_bC8ZieW5fQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "54af7fe2-61fd-431a-fd04-7f64ba420d82"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "kwOiqNee7goj"
      },
      "outputs": [],
      "source": [
        "# use your model to make a prediction on unseen data\n",
        "y_pred = my_model.best_model.predict(x_test_processed,batch_size=my_model.BATCH)\n",
        "#convert values\n",
        "y_pred = (y_pred>my_model.THR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "VGgleoej7gok",
        "outputId": "82ccfa43-6af2-4591-e6cc-273f07f64035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 68.57 %\n",
            "Weighted ROC AUC accuracy: 66.87 %\n",
            "Confusion matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Asssess the accuracy of your model and explain your key findings\n",
        "# Generate confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "score = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {:.2f} %\".format(score*100))\n",
        "print(\"Weighted ROC AUC accuracy: {:.2f} %\".format(roc_auc_score(y_test, y_pred, average='weighted')*100))\n",
        "print(\"Confusion matrix:\")\n",
        "disp = ConfusionMatrixDisplay(cm)\n",
        "disp.plot()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model is approx 65-70% accurate at predicting whether cancer recurrence will occur.**\n",
        "\n",
        "**Crucially, the proportion of False Negatives is low (<15%). In cancer diagnosis these are the outcomes that we want to minimise. False Positives, whilst undesirable, will likely lead to further diagnostic testing before it is realised that cancer is not present.**"
      ],
      "metadata": {
        "id": "UMNN4P_E07L6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDU85k7J7gok"
      },
      "source": [
        "### Unit tests:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq2QRpri7gol"
      },
      "source": [
        "###Checking training and test data for null values. This will work for both pd dataframes and np arrays, and ensures no null values exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "oUeh38w_7gol"
      },
      "outputs": [],
      "source": [
        "def test_no_nulls(data):\n",
        "    \"\"\" Assert no null values within pd dataframe or np array \"\"\"\n",
        "    \n",
        "    # if data is numpy array, handle accordingly\n",
        "    if isinstance(data, (np.ndarray)):\n",
        "        assert not np.isnan(np.min(data))\n",
        "    \n",
        "    # if not np array, assume data is pandas dataframe\n",
        "    else:\n",
        "        assert data.isna().sum().sum() == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BV9Z1F3i7gom"
      },
      "outputs": [],
      "source": [
        "# run null data unit test on both training and test data\n",
        "test_no_nulls(x_train_processed)\n",
        "test_no_nulls(x_test_processed)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of KSVC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}