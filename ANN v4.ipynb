{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StickMonkey615/JHCSMod4/blob/main/ANN%20v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRn73TIW7gn9"
      },
      "source": [
        "# Module 4 Guidance\n",
        "\n",
        "This notebook is a template for module 4b and 4c, which will be tested in Google Colab, your code needs to run there.\n",
        "The structure has been provided to improve consistency and make it easier for markers to understand your code but still give students the flexibility to be creative.  You need to populate the required functions to solve this problem.  All dependencies should be documented in the next cell.\n",
        "\n",
        "You can:\n",
        "    add further cells or text blocks to extend or further explain your solution\n",
        "    add further functions\n",
        "\n",
        "Dont:\n",
        "    rename functions\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "I5Pj_LPoJcrT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZxOsuHxz7goC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eee1243-a5df-4435-ec4a-17b9419b9e74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (7.9.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.9.24)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.49.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.1)\n",
            "Installing collected packages: jedi, kt-legacy, keras-tuner\n",
            "Successfully installed jedi-0.18.1 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "# Fixed dependencies - do not remove or change.\n",
        "import pytest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/gdrive/')\n",
        "# Import your dependencies\n",
        "!pip install --upgrade xlrd > 1.2.0\n",
        "import xlrd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "!pip install keras-tuner --upgrade\n",
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1m_gmKQP7goE"
      },
      "outputs": [],
      "source": [
        "# Import data\n",
        "\n",
        "def import_local_data(file_path):\n",
        "    \"\"\"This function needs to import the data file into collab and return a pandas dataframe\n",
        "    \"\"\"\n",
        "    raw_df = pd.read_excel(file_path)\n",
        "    return raw_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cIljHljB7goF"
      },
      "outputs": [],
      "source": [
        "local_file_path = \"breast-cancer.xls\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LCu51H5Z7goF"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "raw_data = import_local_data(local_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9WDYKUP7goG"
      },
      "source": [
        "### Conduct exploratory data analysis and explain your key findings - Examine the data, explain its key features and what they look like.  Highlight any fields that are anomalous."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the different dataframe column headings\n",
        "print(raw_data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkjdfYHGiz7a",
        "outputId": "5680f916-93a1-48e0-ab32-4a95cd4bd3af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig',\n",
            "       'breast', 'breast-quad', 'irradiat', 'Class'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine data types for each column\n",
        "for i in range(0, len(raw_data.columns)):\n",
        "    print(type(raw_data.values[1][i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKqjAI-XigbI",
        "outputId": "3e7e7b82-f4b8-4a75-c6b1-b5fa920c84b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'int'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Look at the range of values for each field\n",
        "from collections import Counter\n",
        "rng_vals=[]\n",
        "for i in range(0,len(raw_data.columns)):\n",
        "    rng_vals.append(Counter(raw_data.iloc[:,i].values))\n",
        "    print(f\"{raw_data.columns[i]}: {rng_vals[i]}\")\n",
        "del rng_vals, i"
      ],
      "metadata": {
        "id": "-lQUCdTe36Dp",
        "outputId": "6245b150-06c5-45ec-bc20-162d29e54b21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age: Counter({'50-59': 96, '40-49': 90, '60-69': 57, '30-39': 36, '70-79': 6, '20-29': 1})\n",
            "menopause: Counter({'premeno': 150, 'ge40': 129, 'lt40': 7})\n",
            "tumor-size: Counter({'30-34': 60, '25-29': 54, '20-24': 50, '15-19': 30, datetime.datetime(2014, 10, 1, 0, 0): 28, '40-44': 22, '35-39': 19, '0-4': 8, '50-54': 8, datetime.datetime(2019, 9, 5, 0, 0): 4, '45-49': 3})\n",
            "inv-nodes: Counter({'0-2': 213, datetime.datetime(2019, 5, 3, 0, 0): 36, datetime.datetime(2019, 8, 6, 0, 0): 17, datetime.datetime(2019, 11, 9, 0, 0): 10, '15-17': 6, datetime.datetime(2014, 12, 1, 0, 0): 3, '24-26': 1})\n",
            "node-caps: Counter({'no': 222, 'yes': 56, '?': 8})\n",
            "deg-malig: Counter({2: 130, 3: 85, 1: 71})\n",
            "breast: Counter({'left': 152, 'right': 134})\n",
            "breast-quad: Counter({'left_low': 110, 'left_up': 97, 'right_up': 33, 'right_low': 24, 'central': 21, '?': 1})\n",
            "irradiat: Counter({'no': 218, 'yes': 68})\n",
            "Class: Counter({'no-recurrence-events': 201, 'recurrence-events': 85})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All fields look to contain data that is catagorical in nature.**\n",
        "\n",
        "**Some contain data that appears erroneous:**\n",
        " \n",
        "*   **'tumor-size' and 'inv-nodes' appear to contain some data in a datetime format and some in string.**\n",
        "*   **'node-caps' and 'breast-quad' contain Question Marks.**\n",
        "\n",
        "**Need a way to address these erroneous data inputs.**\n",
        "\n"
      ],
      "metadata": {
        "id": "lALFUx2EEQF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look in more detail at the columns with datetime data.\n",
        "print(raw_data.iloc[:, 2].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IetVwnCr3XI",
        "outputId": "c64a3f57-12b2-4a6e-964b-3bda5183d5a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['15-19' '15-19' '35-39' '35-39' '30-34' '25-29' '40-44'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '0-4' '40-44' '25-29' '15-19'\n",
            " '30-34' '25-29' '25-29' '20-24' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '15-19' '40-44' '20-24' '20-24' '40-44' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '15-19' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '30-34' '15-19' '30-34' '25-29' '25-29' '20-24' '30-34' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '45-49' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '35-39' '25-29' '20-24'\n",
            " '15-19' '30-34' datetime.datetime(2014, 10, 1, 0, 0) '35-39' '50-54'\n",
            " '40-44' '15-19' '30-34' '0-4' '40-44' '25-29' '25-29' '20-24' '35-39'\n",
            " '50-54' '0-4' '40-44' '30-34' '20-24' '30-34' '20-24' '15-19' '25-29'\n",
            " '15-19' '50-54' datetime.datetime(2014, 10, 1, 0, 0) '25-29' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '15-19' '25-29' '25-29' '30-34'\n",
            " '15-19' '25-29' '30-34' '15-19' '0-4' '35-39' '40-44' '25-29' '20-24'\n",
            " '30-34' '20-24' '30-34' '20-24' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '20-24' '45-49' '40-44' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " '35-39' '20-24' '15-19' '30-34' '20-24' '20-24' '30-34' '20-24' '25-29'\n",
            " '30-34' '20-24' '15-19' '30-34' '30-34' '40-44'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '30-34' datetime.datetime(2014, 10, 1, 0, 0) '35-39' '20-24' '30-34'\n",
            " '25-29' '15-19' '35-39' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " '30-34' '25-29' '15-19' '15-19' '30-34' '35-39' '30-34' '25-29' '30-34'\n",
            " '15-19' '0-4' '0-4' '50-54' '30-34' '20-24' '25-29' '30-34' '20-24'\n",
            " '15-19' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '40-44' '30-34' '50-54' '15-19'\n",
            " '40-44' '25-29' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '25-29' '25-29' '30-34' '50-54'\n",
            " '30-34' '20-24' '30-34' '25-29' '20-24' '20-24' '50-54' '20-24' '30-34'\n",
            " '25-29' '25-29' '40-44' '20-24' '20-24' '25-29' '25-29' '20-24' '40-44'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '30-34'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) '15-19' '30-34' '25-29'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) '25-29' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '50-54' '25-29' '20-24'\n",
            " '30-34' '30-34' '15-19' '20-24' datetime.datetime(2019, 9, 5, 0, 0)\n",
            " '30-34' '30-34' '25-29' '25-29' '40-44' '25-29' '30-34' '30-34' '25-29'\n",
            " '25-29' '40-44' '20-24' '25-29' '20-24' '40-44' '25-29' '25-29' '45-49'\n",
            " '20-24' '25-29' '20-24' '20-24' '35-39' '20-24' '30-34' '25-29' '30-34'\n",
            " '25-29' '20-24' '20-24' datetime.datetime(2014, 10, 1, 0, 0) '15-19'\n",
            " '25-29' '20-24' '40-44' '15-19' '30-34' '30-34' '40-44' '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '40-44' '30-34' '30-34' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '25-29' '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '0-4' '25-29' '25-29'\n",
            " '40-44' '25-29' '30-34' '20-24' '20-24' '25-29' '30-34' '20-24' '30-34'\n",
            " '0-4' '20-24' '35-39' '30-34' '20-24' '25-29' '35-39' '20-24' '20-24'\n",
            " '35-39' '35-39' '25-29' '35-39' '30-34' '20-24' '15-19' '30-34' '25-29'\n",
            " '30-34' '15-19' '40-44']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at output data\n",
        "raw_data['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HePUlhNvfWF",
        "outputId": "1c1598a0-f776-45b7-ec1b-373020e7a2e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no-recurrence-events    201\n",
              "recurrence-events        85\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only 2 possible outputs, thus needs converting to binary format for use in classifier models."
      ],
      "metadata": {
        "id": "bkV5bQKKwYHj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KMB3eKfC7goU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a07207a-50bc-46b4-b96f-72f8e511f63e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True outputs: 29.72 %\n"
          ]
        }
      ],
      "source": [
        "# Check output balance\n",
        "out = raw_data.iloc[:, -1].values\n",
        "no_rows = len(raw_data)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "code_rows = le.fit_transform(out)\n",
        "print(\"True outputs: {:.2f} %\".format(sum(code_rows)/len(raw_data)*100))\n",
        "pos = sum(code_rows)\n",
        "neg = len(raw_data)-sum(code_rows)\n",
        "del out, no_rows, le, code_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clear imbalance between output data. Some degree of bias/weighting/sampling will be required to ensure that results accurately predict outcomes for both True and False outcomes."
      ],
      "metadata": {
        "id": "mMo9-0hTwirc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f02MTYgB7goW"
      },
      "outputs": [],
      "source": [
        "# Explain your key findings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data set is made up of 9 independent variables all of which appear catagorical in nature. Although stored as an integer, 'deg-malig' can be viewed as  catagorical data as it can only contain 3 discrete values.**\n",
        "\n",
        "**The inclusion of datetime data entries in both the 'tumor-size' and 'inv-nodes' fields appears to be caused by a formatting entry within Excel. For example, '10-14' being input erroneously as 10/14 thus Excel has interpreted (and converted) it to the datetime field 01/10/2014. A function will need to be written within the model to convert these back to correct format.**\n",
        "\n",
        "**How to deal with '?' entries in fields that are otherwise boolean poses an interesting dilemma. If these are infact meant to signify that the presence is unknown because no diagnostic work has been conducted, then this woiuld signify a valid dat entry. If it is however just an incomplete data entry then there is a risk its inclusion could skew the model results. Without knowing which it seems wisest to remove this data from the dataset. Removal of the entire field could well deprive the model of important information, thus just removing these specific entries (rows) appears the most sensible option, particularly noting that there are relatively few occurences.**\n",
        "\n",
        "**Data set is imbalanced, with dependent variable outputs only True in 30% of instances. The model applied will require this imbalance to be taken into account so as not to sacrifice results predicting this smaller class (surely the aim of cancer diagnosis) so as to achieve a high accuracy figure.**\n",
        "\n",
        "**Output variable will need converting into binary output for use with a binary classification model.**"
      ],
      "metadata": {
        "id": "V7OWyLcOrgWJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzZj8I8G7goX"
      },
      "source": [
        "###Create any data pre-processing that you will conduct on seen and unseen data.  Regardless of the model you use, this dataframe must contain only numeric features and have a strategy for any expected missing values. Any objects can that are needed to handle the test data that are dependent on the training data can be stored in the model class.  You are recommended to use sklearn Pipelines or similar functionality to ensure reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct date types in 'tumor-size' and 'inv-nodes' variables\n",
        "for i in range(0, len(raw_data)):\n",
        "    if type(raw_data['tumor-size'][i]) is not str:\n",
        "        if raw_data['tumor-size'][i].day == 1:\n",
        "            raw_data['tumor-size'][i] = str(raw_data['tumor-size'][i].month) +'-' + str(raw_data['tumor-size'][i].year-2000)\n",
        "        else:\n",
        "            raw_data['tumor-size'][i] = str(raw_data['tumor-size'][i].day) + '-' + str(raw_data['tumor-size'][i].month)\n",
        "    if type(raw_data['inv-nodes'][i]) is not str:\n",
        "        if raw_data['inv-nodes'][i].day == 1:\n",
        "            raw_data['inv-nodes'][i] = str(raw_data['inv-nodes'][i].month) + '-' + str(raw_data['inv-nodes'][i].year-2000)\n",
        "        else:\n",
        "            raw_data['inv-nodes'][i] = str(raw_data['inv-nodes'][i].day) + '-' + str(raw_data['inv-nodes'][i].month)        "
      ],
      "metadata": {
        "id": "GlZwiMllRpUB",
        "outputId": "c9dcb113-16dd-4e7b-eba0-f96157414c28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all rows containing ? data\n",
        "indx = raw_data[raw_data.isin(['?'])].stack(dropna=True).unstack().index\n",
        "print(f\"indx: {indx}\")\n",
        "raw_data = raw_data.drop(index=indx)"
      ],
      "metadata": {
        "id": "ThhbSU5gPBYA",
        "outputId": "68b65fe3-f458-4f2b-d1c8-aceab60a206f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indx: Int64Index([20, 31, 50, 54, 71, 92, 149, 240, 264], dtype='int64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WIh9_0pp7goY"
      },
      "outputs": [],
      "source": [
        "# Split your data so that you can test the effectiveness of your model\n",
        "# Split the data into a Training set and a Test set\n",
        "dfs = np.split(raw_data, [len(raw_data.columns)-1], axis=1)\n",
        "X = dfs[0]\n",
        "y = dfs[1]\n",
        "\n",
        "# Handle categorical values and drop dummy variable\n",
        "# Remove non-categorical data\n",
        "dm = X.pop('deg-malig')\n",
        "# Encode the catagorical data (dummy variables)\n",
        "proc_X = pd.get_dummies(data=X, prefix_sep='_', drop_first=True)\n",
        "# Add back in non-categorical data\n",
        "proc_X.insert(0, 'deg-malig', dm)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(proc_X, y, test_size = 0.25, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate class weights\n",
        "weight_0 = (1 / neg) * ((pos + neg) / 2)\n",
        "weight_1 = (1 / pos) * ((pos + neg) / 2)\n",
        "class_weight = np.log([pos/neg])\n",
        "class_weight_dict = {0: weight_0, 1: weight_1}\n",
        "print(f\"Weight for 0: {weight_0}\")\n",
        "print(f\"Weight for 1: {weight_1}\")"
      ],
      "metadata": {
        "id": "CtCPaYUj8dcn",
        "outputId": "8335ffc1-284b-46e8-826b-43e3b5d99a7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight for 0: 0.7114427860696517\n",
            "Weight for 1: 1.6823529411764706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AbOQACY77goY"
      },
      "outputs": [],
      "source": [
        "# Populate preprocess_training_data and preprocess_test_data to preprocess data.\n",
        "# You must process test and train separately so your model does not accidently gain information that a model wouldnt have in reality and therefore get better predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Xsq2f8747goZ"
      },
      "outputs": [],
      "source": [
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "class Module4_Model:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.metrics = [\n",
        "            keras.metrics.TruePositives(name='tp'),\n",
        "            keras.metrics.FalsePositives(name='fp'),\n",
        "            keras.metrics.TrueNegatives(name='tn'),\n",
        "            keras.metrics.FalseNegatives(name='fn'),\n",
        "            keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "            keras.metrics.Recall(name='recall'),\n",
        "            keras.metrics.Precision(name='precision'),\n",
        "            keras.metrics.AUC(name='prc', curve='PR'),\n",
        "        ]\n",
        "        self.EPOCHS = 500\n",
        "        self.BATCH = 100\n",
        "        self.THR = 0.3\n",
        "        self.stop_crit = keras.callbacks.EarlyStopping(\n",
        "            monitor='val_prc',\n",
        "            verbose=1,\n",
        "            patience=100,\n",
        "            mode='max',\n",
        "            restore_best_weights=True)\n",
        "\n",
        "    def preprocess_training_data(self, training_df):\n",
        "        \"\"\"\n",
        "        This function should process the training data and store any features\n",
        "        required in the class\n",
        "        \"\"\"         \n",
        "        # Apply feature scaling\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "        sc = StandardScaler()\n",
        "        processed_df = sc.fit_transform(training_df)\n",
        "        return processed_df, sc\n",
        "\n",
        "    def preprocess_test_data(self, test_df):\n",
        "        \"\"\"\n",
        "        This function should process the test data and store any features\n",
        "        required in the class\n",
        "        \"\"\"\n",
        "        # Apply feature scaling\n",
        "        processed_df = self.scalar.transform(test_df)\n",
        "        return processed_df\n",
        "\n",
        "    def make_model(self,hp):\n",
        "        model = keras.Sequential()\n",
        "        output_bias = keras.initializers.Constant(class_weight)\n",
        "        # Tune the number of units in each layer\n",
        "        hp_units1 = hp.Int('units1',min_value=16,max_value=128,step=2)\n",
        "        hp_units2 = hp.Int('units2',min_value=16,max_value=64,step=2)\n",
        "        hp_units3 = hp.Int('units3',min_value=16,max_value=32,step=2)\n",
        "\n",
        "        model.add(Dense(hp_units1,\n",
        "                        activation=hp.Choice(\n",
        "                            name='dense_activation1',\n",
        "                            values=['tanh','relu','selu','leaky-relu'],\n",
        "                            default='selu'),\n",
        "                        input_shape=(x_train_processed.shape[-1],),\n",
        "                        kernel_initializer='lecun_normal'\n",
        "                        ))\n",
        "        #model.add(Dropout(0.5))\n",
        "        model.add(Dense(hp_units2,\n",
        "                        activation=hp.Choice(\n",
        "                            name='dense_activation2',\n",
        "                            values=['tanh','relu','selu','leaky-relu'],\n",
        "                            default='leaky-relu'),\n",
        "                        kernel_initializer='lecun_normal'\n",
        "                        ))\n",
        "        model.add(Dense(hp_units3,\n",
        "                        activation=hp.Choice(\n",
        "                            name='dense_activation3',\n",
        "                            values=['tanh','relu','selu','leaky-relu'],\n",
        "                            default='leaky-relu'),\n",
        "                        kernel_initializer='lecun_normal'\n",
        "                        ))\n",
        "        model.add(Dense(1,kernel_initializer='normal',activation='sigmoid',bias_initializer=output_bias))\n",
        "        hp_learning_rate = hp.Choice('learning_rate',values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adamax(learning_rate=hp_learning_rate),\n",
        "            loss=keras.losses.BinaryCrossentropy(),\n",
        "            metrics=self.metrics)\n",
        "        \n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "F3LiNNCb7goa"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "my_model = Module4_Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZQD7WPdN7god"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "x_train_processed, my_model.scalar = my_model.preprocess_training_data(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the output data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb = LabelEncoder()\n",
        "y_train = pd.DataFrame(lb.fit_transform(y_train))\n",
        "y_test = pd.DataFrame(lb.transform(y_test))"
      ],
      "metadata": {
        "id": "xZNGF1UxWGU5",
        "outputId": "80d655b4-c565-45d7-b23d-06af5cf7f73c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create model and train"
      ],
      "metadata": {
        "id": "deUEPqVyJUpX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XnLHgaXS7goe"
      },
      "outputs": [],
      "source": [
        "# Create a model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "from keras.layers import LeakyReLU,ELU,PReLU,Dropout\n",
        "from keras.losses import MeanSquaredLogarithmicError\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "msle = MeanSquaredLogarithmicError()\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.3))})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilise HyperBand algorithm from keras tuner to construct model\n",
        "tuner = kt.Hyperband(\n",
        "    my_model.make_model,\n",
        "    objective=kt.Objective('val_prc', direction='max'),\n",
        "    max_epochs=50,\n",
        "    directory='keras_tuner_dir',\n",
        "    project_name='keras_tuner',\n",
        ")\n",
        "tuner.search(x_train_processed,y_train,epochs=50,validation_split=0.2)"
      ],
      "metadata": {
        "id": "p1Ph9bZMV5G6",
        "outputId": "8bd1a848-ea8e-40f5-c11b-a36032298dbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 06s]\n",
            "val_prc: 0.4440464973449707\n",
            "\n",
            "Best val_prc So Far: 0.5715206265449524\n",
            "Total elapsed time: 00h 06m 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rQwUj4lk7goe"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "x_test_processed = my_model.preprocess_test_data(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for h_param in [f\"units{i}\" for i in range(1,4)] + ['learning_rate'] + [f\"dense_activation{i}\" for i in range(1,4)]:\n",
        "    print(h_param, tuner.get_best_hyperparameters()[0].get(h_param))\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "HuWZxfcvYOI4",
        "outputId": "4b20834e-f675-4c0b-f042-70cf89fc3a36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "units1 54\n",
            "units2 28\n",
            "units3 26\n",
            "learning_rate 0.01\n",
            "dense_activation1 relu\n",
            "dense_activation2 tanh\n",
            "dense_activation3 tanh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.best_model = tuner.get_best_models()[0]\n",
        "my_model.best_model.build(x_train_processed.shape)\n",
        "my_model.best_model.summary()"
      ],
      "metadata": {
        "id": "Lku4uguEY1ar",
        "outputId": "eee548d6-5339-4087-9ef4-5649adad03de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 54)                1728      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 28)                1540      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 26)                754       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,049\n",
            "Trainable params: 4,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the best model (with class weights)\n",
        "my_model.best_model.fit(x_train_processed,\n",
        "                   y_train,\n",
        "                   batch_size=my_model.BATCH,\n",
        "                   epochs=my_model.EPOCHS,\n",
        "                   callbacks=[my_model.stop_crit],\n",
        "                   validation_split=0.2,\n",
        "                   class_weight=class_weight_dict)"
      ],
      "metadata": {
        "id": "DFAWtazI9LH4",
        "outputId": "c4763961-cad5-472a-d55b-64115e570fc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.7257 - tp: 4.0000 - fp: 8.0000 - tn: 137.0000 - fn: 58.0000 - accuracy: 0.6812 - recall: 0.0645 - precision: 0.3333 - prc: 0.4891 - val_loss: 0.4877 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.5190\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.6983 - tp: 1.0000 - fp: 0.0000e+00 - tn: 111.0000 - fn: 53.0000 - accuracy: 0.6788 - recall: 0.0185 - precision: 1.0000 - prc: 0.7003 - val_loss: 0.5031 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33.0000 - val_fn: 7.0000 - val_accuracy: 0.8095 - val_recall: 0.1250 - val_precision: 0.5000 - val_prc: 0.5144\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6559 - tp: 20.0000 - fp: 6.0000 - tn: 105.0000 - fn: 34.0000 - accuracy: 0.7576 - recall: 0.3704 - precision: 0.7692 - prc: 0.6592 - val_loss: 0.5415 - val_tp: 5.0000 - val_fp: 7.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.7619 - val_recall: 0.6250 - val_precision: 0.4167 - val_prc: 0.4993\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6085 - tp: 36.0000 - fp: 23.0000 - tn: 88.0000 - fn: 18.0000 - accuracy: 0.7515 - recall: 0.6667 - precision: 0.6102 - prc: 0.6510 - val_loss: 0.5936 - val_tp: 6.0000 - val_fp: 15.0000 - val_tn: 19.0000 - val_fn: 2.0000 - val_accuracy: 0.5952 - val_recall: 0.7500 - val_precision: 0.2857 - val_prc: 0.4949\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.5708 - tp: 43.0000 - fp: 33.0000 - tn: 78.0000 - fn: 11.0000 - accuracy: 0.7333 - recall: 0.7963 - precision: 0.5658 - prc: 0.6903 - val_loss: 0.6499 - val_tp: 6.0000 - val_fp: 17.0000 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.5476 - val_recall: 0.7500 - val_precision: 0.2609 - val_prc: 0.4747\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.5522 - tp: 47.0000 - fp: 40.0000 - tn: 71.0000 - fn: 7.0000 - accuracy: 0.7152 - recall: 0.8704 - precision: 0.5402 - prc: 0.6383 - val_loss: 0.7005 - val_tp: 7.0000 - val_fp: 19.0000 - val_tn: 15.0000 - val_fn: 1.0000 - val_accuracy: 0.5238 - val_recall: 0.8750 - val_precision: 0.2692 - val_prc: 0.4740\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5357 - tp: 48.0000 - fp: 44.0000 - tn: 67.0000 - fn: 6.0000 - accuracy: 0.6970 - recall: 0.8889 - precision: 0.5217 - prc: 0.6591 - val_loss: 0.7241 - val_tp: 7.0000 - val_fp: 19.0000 - val_tn: 15.0000 - val_fn: 1.0000 - val_accuracy: 0.5238 - val_recall: 0.8750 - val_precision: 0.2692 - val_prc: 0.3913\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5148 - tp: 48.0000 - fp: 44.0000 - tn: 67.0000 - fn: 6.0000 - accuracy: 0.6970 - recall: 0.8889 - precision: 0.5217 - prc: 0.7190 - val_loss: 0.7163 - val_tp: 7.0000 - val_fp: 19.0000 - val_tn: 15.0000 - val_fn: 1.0000 - val_accuracy: 0.5238 - val_recall: 0.8750 - val_precision: 0.2692 - val_prc: 0.4468\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.4929 - tp: 48.0000 - fp: 41.0000 - tn: 70.0000 - fn: 6.0000 - accuracy: 0.7152 - recall: 0.8889 - precision: 0.5393 - prc: 0.7486 - val_loss: 0.6849 - val_tp: 6.0000 - val_fp: 16.0000 - val_tn: 18.0000 - val_fn: 2.0000 - val_accuracy: 0.5714 - val_recall: 0.7500 - val_precision: 0.2727 - val_prc: 0.4451\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.4740 - tp: 48.0000 - fp: 34.0000 - tn: 77.0000 - fn: 6.0000 - accuracy: 0.7576 - recall: 0.8889 - precision: 0.5854 - prc: 0.7575 - val_loss: 0.6529 - val_tp: 6.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.6190 - val_recall: 0.7500 - val_precision: 0.3000 - val_prc: 0.4422\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.4579 - tp: 47.0000 - fp: 29.0000 - tn: 82.0000 - fn: 7.0000 - accuracy: 0.7818 - recall: 0.8704 - precision: 0.6184 - prc: 0.7731 - val_loss: 0.6384 - val_tp: 6.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.6190 - val_recall: 0.7500 - val_precision: 0.3000 - val_prc: 0.4350\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.4448 - tp: 47.0000 - fp: 28.0000 - tn: 83.0000 - fn: 7.0000 - accuracy: 0.7879 - recall: 0.8704 - precision: 0.6267 - prc: 0.7800 - val_loss: 0.6432 - val_tp: 6.0000 - val_fp: 13.0000 - val_tn: 21.0000 - val_fn: 2.0000 - val_accuracy: 0.6429 - val_recall: 0.7500 - val_precision: 0.3158 - val_prc: 0.3502\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.4263 - tp: 47.0000 - fp: 29.0000 - tn: 82.0000 - fn: 7.0000 - accuracy: 0.7818 - recall: 0.8704 - precision: 0.6184 - prc: 0.7983 - val_loss: 0.6480 - val_tp: 6.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.6190 - val_recall: 0.7500 - val_precision: 0.3000 - val_prc: 0.3315\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.4088 - tp: 49.0000 - fp: 30.0000 - tn: 81.0000 - fn: 5.0000 - accuracy: 0.7879 - recall: 0.9074 - precision: 0.6203 - prc: 0.8131 - val_loss: 0.6592 - val_tp: 6.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.6190 - val_recall: 0.7500 - val_precision: 0.3000 - val_prc: 0.3301\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.3884 - tp: 50.0000 - fp: 30.0000 - tn: 81.0000 - fn: 4.0000 - accuracy: 0.7939 - recall: 0.9259 - precision: 0.6250 - prc: 0.8344 - val_loss: 0.6607 - val_tp: 6.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.6190 - val_recall: 0.7500 - val_precision: 0.3000 - val_prc: 0.3206\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 0.3705 - tp: 50.0000 - fp: 30.0000 - tn: 81.0000 - fn: 4.0000 - accuracy: 0.7939 - recall: 0.9259 - precision: 0.6250 - prc: 0.8526 - val_loss: 0.6553 - val_tp: 6.0000 - val_fp: 16.0000 - val_tn: 18.0000 - val_fn: 2.0000 - val_accuracy: 0.5714 - val_recall: 0.7500 - val_precision: 0.2727 - val_prc: 0.3114\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.3535 - tp: 50.0000 - fp: 28.0000 - tn: 83.0000 - fn: 4.0000 - accuracy: 0.8061 - recall: 0.9259 - precision: 0.6410 - prc: 0.8743 - val_loss: 0.6512 - val_tp: 5.0000 - val_fp: 15.0000 - val_tn: 19.0000 - val_fn: 3.0000 - val_accuracy: 0.5714 - val_recall: 0.6250 - val_precision: 0.2500 - val_prc: 0.2974\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3341 - tp: 51.0000 - fp: 26.0000 - tn: 85.0000 - fn: 3.0000 - accuracy: 0.8242 - recall: 0.9444 - precision: 0.6623 - prc: 0.8965 - val_loss: 0.6460 - val_tp: 5.0000 - val_fp: 15.0000 - val_tn: 19.0000 - val_fn: 3.0000 - val_accuracy: 0.5714 - val_recall: 0.6250 - val_precision: 0.2500 - val_prc: 0.2847\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.3114 - tp: 51.0000 - fp: 23.0000 - tn: 88.0000 - fn: 3.0000 - accuracy: 0.8424 - recall: 0.9444 - precision: 0.6892 - prc: 0.9255 - val_loss: 0.6391 - val_tp: 4.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 4.0000 - val_accuracy: 0.5714 - val_recall: 0.5000 - val_precision: 0.2222 - val_prc: 0.2889\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.2907 - tp: 50.0000 - fp: 17.0000 - tn: 94.0000 - fn: 4.0000 - accuracy: 0.8727 - recall: 0.9259 - precision: 0.7463 - prc: 0.9408 - val_loss: 0.6438 - val_tp: 4.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 4.0000 - val_accuracy: 0.5714 - val_recall: 0.5000 - val_precision: 0.2222 - val_prc: 0.2881\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.2720 - tp: 51.0000 - fp: 14.0000 - tn: 97.0000 - fn: 3.0000 - accuracy: 0.8970 - recall: 0.9444 - precision: 0.7846 - prc: 0.9543 - val_loss: 0.6527 - val_tp: 4.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 4.0000 - val_accuracy: 0.5714 - val_recall: 0.5000 - val_precision: 0.2222 - val_prc: 0.2777\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.2490 - tp: 52.0000 - fp: 13.0000 - tn: 98.0000 - fn: 2.0000 - accuracy: 0.9091 - recall: 0.9630 - precision: 0.8000 - prc: 0.9625 - val_loss: 0.6874 - val_tp: 4.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 4.0000 - val_accuracy: 0.5714 - val_recall: 0.5000 - val_precision: 0.2222 - val_prc: 0.2762\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.2264 - tp: 53.0000 - fp: 12.0000 - tn: 99.0000 - fn: 1.0000 - accuracy: 0.9212 - recall: 0.9815 - precision: 0.8154 - prc: 0.9694 - val_loss: 0.7154 - val_tp: 4.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 4.0000 - val_accuracy: 0.5714 - val_recall: 0.5000 - val_precision: 0.2222 - val_prc: 0.2660\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.2069 - tp: 54.0000 - fp: 12.0000 - tn: 99.0000 - fn: 0.0000e+00 - accuracy: 0.9273 - recall: 1.0000 - precision: 0.8182 - prc: 0.9734 - val_loss: 0.7395 - val_tp: 5.0000 - val_fp: 15.0000 - val_tn: 19.0000 - val_fn: 3.0000 - val_accuracy: 0.5714 - val_recall: 0.6250 - val_precision: 0.2500 - val_prc: 0.2659\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1881 - tp: 54.0000 - fp: 12.0000 - tn: 99.0000 - fn: 0.0000e+00 - accuracy: 0.9273 - recall: 1.0000 - precision: 0.8182 - prc: 0.9769 - val_loss: 0.7577 - val_tp: 6.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.6190 - val_recall: 0.7500 - val_precision: 0.3000 - val_prc: 0.2711\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.1710 - tp: 54.0000 - fp: 10.0000 - tn: 101.0000 - fn: 0.0000e+00 - accuracy: 0.9394 - recall: 1.0000 - precision: 0.8438 - prc: 0.9812 - val_loss: 0.7440 - val_tp: 6.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.6190 - val_recall: 0.7500 - val_precision: 0.3000 - val_prc: 0.2697\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1539 - tp: 54.0000 - fp: 9.0000 - tn: 102.0000 - fn: 0.0000e+00 - accuracy: 0.9455 - recall: 1.0000 - precision: 0.8571 - prc: 0.9878 - val_loss: 0.7399 - val_tp: 6.0000 - val_fp: 13.0000 - val_tn: 21.0000 - val_fn: 2.0000 - val_accuracy: 0.6429 - val_recall: 0.7500 - val_precision: 0.3158 - val_prc: 0.2661\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.1432 - tp: 54.0000 - fp: 7.0000 - tn: 104.0000 - fn: 0.0000e+00 - accuracy: 0.9576 - recall: 1.0000 - precision: 0.8852 - prc: 0.9888 - val_loss: 0.7678 - val_tp: 6.0000 - val_fp: 13.0000 - val_tn: 21.0000 - val_fn: 2.0000 - val_accuracy: 0.6429 - val_recall: 0.7500 - val_precision: 0.3158 - val_prc: 0.2809\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.1262 - tp: 54.0000 - fp: 5.0000 - tn: 106.0000 - fn: 0.0000e+00 - accuracy: 0.9697 - recall: 1.0000 - precision: 0.9153 - prc: 0.9897 - val_loss: 0.7903 - val_tp: 6.0000 - val_fp: 13.0000 - val_tn: 21.0000 - val_fn: 2.0000 - val_accuracy: 0.6429 - val_recall: 0.7500 - val_precision: 0.3158 - val_prc: 0.2827\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.1154 - tp: 54.0000 - fp: 5.0000 - tn: 106.0000 - fn: 0.0000e+00 - accuracy: 0.9697 - recall: 1.0000 - precision: 0.9153 - prc: 0.9903 - val_loss: 0.8263 - val_tp: 6.0000 - val_fp: 13.0000 - val_tn: 21.0000 - val_fn: 2.0000 - val_accuracy: 0.6429 - val_recall: 0.7500 - val_precision: 0.3158 - val_prc: 0.2895\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1040 - tp: 54.0000 - fp: 6.0000 - tn: 105.0000 - fn: 0.0000e+00 - accuracy: 0.9636 - recall: 1.0000 - precision: 0.9000 - prc: 0.9928 - val_loss: 0.8811 - val_tp: 6.0000 - val_fp: 14.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.6190 - val_recall: 0.7500 - val_precision: 0.3000 - val_prc: 0.2963\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0952 - tp: 54.0000 - fp: 6.0000 - tn: 105.0000 - fn: 0.0000e+00 - accuracy: 0.9636 - recall: 1.0000 - precision: 0.9000 - prc: 0.9946 - val_loss: 0.8894 - val_tp: 6.0000 - val_fp: 13.0000 - val_tn: 21.0000 - val_fn: 2.0000 - val_accuracy: 0.6429 - val_recall: 0.7500 - val_precision: 0.3158 - val_prc: 0.2985\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0866 - tp: 54.0000 - fp: 6.0000 - tn: 105.0000 - fn: 0.0000e+00 - accuracy: 0.9636 - recall: 1.0000 - precision: 0.9000 - prc: 0.9962 - val_loss: 0.8710 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 2.0000 - val_accuracy: 0.6667 - val_recall: 0.7500 - val_precision: 0.3333 - val_prc: 0.3023\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0808 - tp: 53.0000 - fp: 3.0000 - tn: 108.0000 - fn: 1.0000 - accuracy: 0.9758 - recall: 0.9815 - precision: 0.9464 - prc: 0.9967 - val_loss: 0.8658 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3028\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0744 - tp: 53.0000 - fp: 3.0000 - tn: 108.0000 - fn: 1.0000 - accuracy: 0.9758 - recall: 0.9815 - precision: 0.9464 - prc: 0.9968 - val_loss: 0.9024 - val_tp: 6.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 2.0000 - val_accuracy: 0.6905 - val_recall: 0.7500 - val_precision: 0.3529 - val_prc: 0.3118\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0689 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9964 - val_loss: 0.9389 - val_tp: 6.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 2.0000 - val_accuracy: 0.6905 - val_recall: 0.7500 - val_precision: 0.3529 - val_prc: 0.3107\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0654 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9967 - val_loss: 0.9811 - val_tp: 6.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 2.0000 - val_accuracy: 0.6905 - val_recall: 0.7500 - val_precision: 0.3529 - val_prc: 0.3086\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.0640 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9966 - val_loss: 1.0103 - val_tp: 6.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 2.0000 - val_accuracy: 0.6905 - val_recall: 0.7500 - val_precision: 0.3529 - val_prc: 0.3084\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0621 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9959 - val_loss: 1.0195 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3179\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0570 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9966 - val_loss: 1.0472 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3119\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0584 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9962 - val_loss: 1.0758 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3429\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0532 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9971 - val_loss: 1.0370 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3053\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0534 - tp: 53.0000 - fp: 4.0000 - tn: 107.0000 - fn: 1.0000 - accuracy: 0.9697 - recall: 0.9815 - precision: 0.9298 - prc: 0.9973 - val_loss: 1.0395 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3065\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0505 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9975 - val_loss: 1.0805 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.2905\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0465 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9981 - val_loss: 1.1380 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.2838\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0485 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9979 - val_loss: 1.1338 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.2853\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0470 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9971 - val_loss: 1.1152 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.2850\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0464 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9972 - val_loss: 1.0961 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.2885\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0483 - tp: 53.0000 - fp: 2.0000 - tn: 109.0000 - fn: 1.0000 - accuracy: 0.9818 - recall: 0.9815 - precision: 0.9636 - prc: 0.9972 - val_loss: 1.1121 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3075\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0420 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - val_loss: 1.1214 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3104\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.0443 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9969 - val_loss: 1.1372 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3074\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0477 - tp: 53.0000 - fp: 2.0000 - tn: 109.0000 - fn: 1.0000 - accuracy: 0.9818 - recall: 0.9815 - precision: 0.9636 - prc: 0.9973 - val_loss: 1.1546 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3070\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0476 - tp: 53.0000 - fp: 3.0000 - tn: 108.0000 - fn: 1.0000 - accuracy: 0.9758 - recall: 0.9815 - precision: 0.9464 - prc: 0.9972 - val_loss: 1.1933 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3065\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.0424 - tp: 54.0000 - fp: 4.0000 - tn: 107.0000 - fn: 0.0000e+00 - accuracy: 0.9758 - recall: 1.0000 - precision: 0.9310 - prc: 0.9974 - val_loss: 1.1790 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3052\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0469 - tp: 53.0000 - fp: 2.0000 - tn: 109.0000 - fn: 1.0000 - accuracy: 0.9818 - recall: 0.9815 - precision: 0.9636 - prc: 0.9976 - val_loss: 1.1818 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3124\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 0.0437 - tp: 53.0000 - fp: 2.0000 - tn: 109.0000 - fn: 1.0000 - accuracy: 0.9818 - recall: 0.9815 - precision: 0.9636 - prc: 0.9974 - val_loss: 1.2065 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3123\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0414 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9979 - val_loss: 1.1860 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3130\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.0415 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - val_loss: 1.1660 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3095\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0404 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9973 - val_loss: 1.1761 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3159\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0400 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9975 - val_loss: 1.2030 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3424\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0380 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - val_loss: 1.2358 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3390\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0401 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - val_loss: 1.2332 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3390\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0397 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - val_loss: 1.2045 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3361\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0371 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9985 - val_loss: 1.1800 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3200\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0445 - tp: 52.0000 - fp: 2.0000 - tn: 109.0000 - fn: 2.0000 - accuracy: 0.9758 - recall: 0.9630 - precision: 0.9630 - prc: 0.9978 - val_loss: 1.1948 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3224\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0397 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9977 - val_loss: 1.2868 - val_tp: 5.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.6429 - val_recall: 0.6250 - val_precision: 0.2941 - val_prc: 0.3211\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0466 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9973 - val_loss: 1.3240 - val_tp: 5.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.6429 - val_recall: 0.6250 - val_precision: 0.2941 - val_prc: 0.3238\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0444 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9977 - val_loss: 1.2600 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3214\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0369 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - val_loss: 1.2191 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3243\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0429 - tp: 53.0000 - fp: 3.0000 - tn: 108.0000 - fn: 1.0000 - accuracy: 0.9758 - recall: 0.9815 - precision: 0.9464 - prc: 0.9976 - val_loss: 1.2309 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3244\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0399 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9973 - val_loss: 1.2532 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3213\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.0395 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - val_loss: 1.2474 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3204\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 0.0402 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - val_loss: 1.2117 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3167\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0347 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9987 - val_loss: 1.1991 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3196\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0521 - tp: 53.0000 - fp: 2.0000 - tn: 109.0000 - fn: 1.0000 - accuracy: 0.9818 - recall: 0.9815 - precision: 0.9636 - prc: 0.9971 - val_loss: 1.2167 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3248\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0421 - tp: 53.0000 - fp: 2.0000 - tn: 109.0000 - fn: 1.0000 - accuracy: 0.9818 - recall: 0.9815 - precision: 0.9636 - prc: 0.9980 - val_loss: 1.3082 - val_tp: 5.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.6429 - val_recall: 0.6250 - val_precision: 0.2941 - val_prc: 0.3186\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.0428 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - val_loss: 1.3660 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 2.0000 - val_accuracy: 0.6667 - val_recall: 0.7500 - val_precision: 0.3333 - val_prc: 0.3159\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0455 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - val_loss: 1.3457 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 2.0000 - val_accuracy: 0.6667 - val_recall: 0.7500 - val_precision: 0.3333 - val_prc: 0.3171\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0425 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - val_loss: 1.2771 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3187\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.0386 - tp: 53.0000 - fp: 3.0000 - tn: 108.0000 - fn: 1.0000 - accuracy: 0.9758 - recall: 0.9815 - precision: 0.9464 - prc: 0.9985 - val_loss: 1.2241 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3172\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0382 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - val_loss: 1.2216 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3215\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0393 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - val_loss: 1.2574 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3237\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0354 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - val_loss: 1.2852 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3210\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0354 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9985 - val_loss: 1.3082 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3210\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 0.0375 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - val_loss: 1.3084 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3210\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0375 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - val_loss: 1.2875 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3237\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0355 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - val_loss: 1.2463 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3182\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0363 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9978 - val_loss: 1.2306 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3182\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0370 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9973 - val_loss: 1.2467 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3182\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0365 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - val_loss: 1.2667 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3209\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0389 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - val_loss: 1.3343 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 2.0000 - val_accuracy: 0.6667 - val_recall: 0.7500 - val_precision: 0.3333 - val_prc: 0.3201\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0392 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - val_loss: 1.3314 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 22.0000 - val_fn: 2.0000 - val_accuracy: 0.6667 - val_recall: 0.7500 - val_precision: 0.3333 - val_prc: 0.3213\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0398 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9977 - val_loss: 1.2855 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_recall: 0.6250 - val_precision: 0.3125 - val_prc: 0.3204\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0361 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9980 - val_loss: 1.2687 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3193\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0336 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9985 - val_loss: 1.2588 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3193\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0343 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9983 - val_loss: 1.2626 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3193\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0368 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9976 - val_loss: 1.2799 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3193\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0359 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9973 - val_loss: 1.3005 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3193\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.0342 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9973 - val_loss: 1.3057 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3193\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0335 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9981 - val_loss: 1.3113 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3193\n",
            "Epoch 101/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0251 - tp: 32.0000 - fp: 1.0000 - tn: 67.0000 - fn: 0.0000e+00 - accuracy: 0.9900 - recall: 1.0000 - precision: 0.9697 - prc: 0.9995Restoring model weights from the end of the best epoch: 1.\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0341 - tp: 54.0000 - fp: 3.0000 - tn: 108.0000 - fn: 0.0000e+00 - accuracy: 0.9818 - recall: 1.0000 - precision: 0.9474 - prc: 0.9979 - val_loss: 1.3069 - val_tp: 4.0000 - val_fp: 11.0000 - val_tn: 23.0000 - val_fn: 4.0000 - val_accuracy: 0.6429 - val_recall: 0.5000 - val_precision: 0.2667 - val_prc: 0.3195\n",
            "Epoch 101: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe83108cb50>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualise the loss and accuracy for each epoch"
      ],
      "metadata": {
        "id": "G9DPmZDDXEnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(my_model.best_model.history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "84wnXBf0XDyz",
        "outputId": "e54c25ad-e0d1-40f2-99a0-dbd9630f2555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(my_model.best_model.history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c_bC8ZieW5fQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "99711c05-d561-447b-f3e4-0b7c2e5a6256"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "kwOiqNee7goj"
      },
      "outputs": [],
      "source": [
        "# use your model to make a prediction on unseen data\n",
        "y_pred = my_model.best_model.predict(x_test_processed,batch_size=my_model.BATCH)\n",
        "#convert values\n",
        "y_pred = (y_pred>my_model.THR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "VGgleoej7gok",
        "outputId": "1d67c4b1-3e19-4041-9d4c-0d2baa8a46b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 65.71 %\n",
            "Weighted ROC AUC accuracy: 71.52 %\n",
            "Confusion matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Asssess the accuracy of your model and explain your key findings\n",
        "# Generate confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "score = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {:.2f} %\".format(score*100))\n",
        "print(\"Weighted ROC AUC accuracy: {:.2f} %\".format(roc_auc_score(y_test, y_pred, average='weighted')*100))\n",
        "print(\"Confusion matrix:\")\n",
        "disp = ConfusionMatrixDisplay(cm)\n",
        "disp.plot()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model is approx 65-70% accurate at predicting whether cancer recurrence will occur.**\n",
        "\n",
        "**Crucially, the proportion of False Negatives is low (<15%). In cancer diagnosis these are the outcomes that we want to minimise. False Positives, whilst undesirable, will likely lead to further diagnostic testing before it is realised that cancer is not present.**"
      ],
      "metadata": {
        "id": "UMNN4P_E07L6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDU85k7J7gok"
      },
      "source": [
        "### Unit tests:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq2QRpri7gol"
      },
      "source": [
        "###Checking training and test data for null values. This will work for both pd dataframes and np arrays, and ensures no null values exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "oUeh38w_7gol"
      },
      "outputs": [],
      "source": [
        "def test_no_nulls(data):\n",
        "    \"\"\" Assert no null values within pd dataframe or np array \"\"\"\n",
        "    \n",
        "    # if data is numpy array, handle accordingly\n",
        "    if isinstance(data, (np.ndarray)):\n",
        "        assert not np.isnan(np.min(data))\n",
        "    \n",
        "    # if not np array, assume data is pandas dataframe\n",
        "    else:\n",
        "        assert data.isna().sum().sum() == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BV9Z1F3i7gom"
      },
      "outputs": [],
      "source": [
        "# run null data unit test on both training and test data\n",
        "test_no_nulls(x_train_processed)\n",
        "test_no_nulls(x_test_processed)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of KSVC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}