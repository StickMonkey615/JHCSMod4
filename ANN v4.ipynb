{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StickMonkey615/JHCSMod4/blob/main/ANN%20v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRn73TIW7gn9"
      },
      "source": [
        "# Module 4 Guidance\n",
        "\n",
        "This notebook is a template for module 4b and 4c, which will be tested in Google Colab, your code needs to run there.\n",
        "The structure has been provided to improve consistency and make it easier for markers to understand your code but still give students the flexibility to be creative.  You need to populate the required functions to solve this problem.  All dependencies should be documented in the next cell.\n",
        "\n",
        "You can:\n",
        "    add further cells or text blocks to extend or further explain your solution\n",
        "    add further functions\n",
        "\n",
        "Dont:\n",
        "    rename functions\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxOsuHxz7goC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b714a7d3-97cb-41e7-b3f5-f41710e9c0e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 15.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.48.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.2.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
            "Installing collected packages: jedi, kt-legacy, keras-tuner\n",
            "Successfully installed jedi-0.18.1 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "# Fixed dependencies - do not remove or change.\n",
        "import pytest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/gdrive/')\n",
        "# Import your dependencies\n",
        "!pip install --upgrade xlrd > 1.2.0\n",
        "import xlrd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "!pip install keras-tuner --upgrade\n",
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1m_gmKQP7goE"
      },
      "outputs": [],
      "source": [
        "# Import data\n",
        "\n",
        "def import_local_data(file_path):\n",
        "    \"\"\"This function needs to import the data file into collab and return a pandas dataframe\n",
        "    \"\"\"\n",
        "    raw_df = pd.read_excel(file_path)\n",
        "    return raw_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIljHljB7goF"
      },
      "outputs": [],
      "source": [
        "local_file_path = \"breast-cancer.xls\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCu51H5Z7goF"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "raw_data = import_local_data(local_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9WDYKUP7goG"
      },
      "source": [
        "### Conduct exploratory data analysis and explain your key findings - Examine the data, explain its key features and what they look like.  Highlight any fields that are anomalous."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the different dataframe column headings\n",
        "print(raw_data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkjdfYHGiz7a",
        "outputId": "ae509b3c-7af8-4e98-a7d4-1a9804ea4b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig',\n",
            "       'breast', 'breast-quad', 'irradiat', 'Class'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine data types for each column\n",
        "for i in range(0, len(raw_data.columns)):\n",
        "    print(type(raw_data.values[1][i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKqjAI-XigbI",
        "outputId": "00c767bf-bae4-4c7b-ea38-4d975041ac14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'int'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Look at the range of values for each field\n",
        "from collections import Counter\n",
        "rng_vals=[]\n",
        "for i in range(0,len(raw_data.columns)):\n",
        "    rng_vals.append(Counter(raw_data.iloc[:,i].values))\n",
        "    print(f\"{raw_data.columns[i]}: {rng_vals[i]}\")\n",
        "del rng_vals, i"
      ],
      "metadata": {
        "id": "-lQUCdTe36Dp",
        "outputId": "eb94a259-a232-4d5d-ebac-385fe8dfecff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age: Counter({'50-59': 96, '40-49': 90, '60-69': 57, '30-39': 36, '70-79': 6, '20-29': 1})\n",
            "menopause: Counter({'premeno': 150, 'ge40': 129, 'lt40': 7})\n",
            "tumor-size: Counter({'30-34': 60, '25-29': 54, '20-24': 50, '15-19': 30, datetime.datetime(2014, 10, 1, 0, 0): 28, '40-44': 22, '35-39': 19, '0-4': 8, '50-54': 8, datetime.datetime(2019, 9, 5, 0, 0): 4, '45-49': 3})\n",
            "inv-nodes: Counter({'0-2': 213, datetime.datetime(2019, 5, 3, 0, 0): 36, datetime.datetime(2019, 8, 6, 0, 0): 17, datetime.datetime(2019, 11, 9, 0, 0): 10, '15-17': 6, datetime.datetime(2014, 12, 1, 0, 0): 3, '24-26': 1})\n",
            "node-caps: Counter({'no': 222, 'yes': 56, '?': 8})\n",
            "deg-malig: Counter({2: 130, 3: 85, 1: 71})\n",
            "breast: Counter({'left': 152, 'right': 134})\n",
            "breast-quad: Counter({'left_low': 110, 'left_up': 97, 'right_up': 33, 'right_low': 24, 'central': 21, '?': 1})\n",
            "irradiat: Counter({'no': 218, 'yes': 68})\n",
            "Class: Counter({'no-recurrence-events': 201, 'recurrence-events': 85})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All fields look to contain data that is catagorical in nature.**\n",
        "\n",
        "**Some contain data that appears erroneous:**\n",
        " \n",
        "*   **'tumor-size' and 'inv-nodes' appear to contain some data in a datetime format and some in string.**\n",
        "*   **'node-caps' and 'breast-quad' contain Question Marks.**\n",
        "\n",
        "**Need a way to address these erroneous data inputs.**\n",
        "\n"
      ],
      "metadata": {
        "id": "lALFUx2EEQF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look in more detail at the columns with datetime data.\n",
        "print(raw_data.iloc[:, 2].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IetVwnCr3XI",
        "outputId": "e11a3b05-ca50-4ce7-b25d-34bfc46c3818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['15-19' '15-19' '35-39' '35-39' '30-34' '25-29' '40-44'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '0-4' '40-44' '25-29' '15-19'\n",
            " '30-34' '25-29' '25-29' '20-24' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '15-19' '40-44' '20-24' '20-24' '40-44' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '15-19' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '30-34' '15-19' '30-34' '25-29' '25-29' '20-24' '30-34' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '45-49' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '35-39' '25-29' '20-24'\n",
            " '15-19' '30-34' datetime.datetime(2014, 10, 1, 0, 0) '35-39' '50-54'\n",
            " '40-44' '15-19' '30-34' '0-4' '40-44' '25-29' '25-29' '20-24' '35-39'\n",
            " '50-54' '0-4' '40-44' '30-34' '20-24' '30-34' '20-24' '15-19' '25-29'\n",
            " '15-19' '50-54' datetime.datetime(2014, 10, 1, 0, 0) '25-29' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '15-19' '25-29' '25-29' '30-34'\n",
            " '15-19' '25-29' '30-34' '15-19' '0-4' '35-39' '40-44' '25-29' '20-24'\n",
            " '30-34' '20-24' '30-34' '20-24' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '20-24' '45-49' '40-44' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " '35-39' '20-24' '15-19' '30-34' '20-24' '20-24' '30-34' '20-24' '25-29'\n",
            " '30-34' '20-24' '15-19' '30-34' '30-34' '40-44'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '30-34' datetime.datetime(2014, 10, 1, 0, 0) '35-39' '20-24' '30-34'\n",
            " '25-29' '15-19' '35-39' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " '30-34' '25-29' '15-19' '15-19' '30-34' '35-39' '30-34' '25-29' '30-34'\n",
            " '15-19' '0-4' '0-4' '50-54' '30-34' '20-24' '25-29' '30-34' '20-24'\n",
            " '15-19' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '40-44' '30-34' '50-54' '15-19'\n",
            " '40-44' '25-29' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '25-29' '25-29' '30-34' '50-54'\n",
            " '30-34' '20-24' '30-34' '25-29' '20-24' '20-24' '50-54' '20-24' '30-34'\n",
            " '25-29' '25-29' '40-44' '20-24' '20-24' '25-29' '25-29' '20-24' '40-44'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '30-34'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) '15-19' '30-34' '25-29'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) '25-29' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '50-54' '25-29' '20-24'\n",
            " '30-34' '30-34' '15-19' '20-24' datetime.datetime(2019, 9, 5, 0, 0)\n",
            " '30-34' '30-34' '25-29' '25-29' '40-44' '25-29' '30-34' '30-34' '25-29'\n",
            " '25-29' '40-44' '20-24' '25-29' '20-24' '40-44' '25-29' '25-29' '45-49'\n",
            " '20-24' '25-29' '20-24' '20-24' '35-39' '20-24' '30-34' '25-29' '30-34'\n",
            " '25-29' '20-24' '20-24' datetime.datetime(2014, 10, 1, 0, 0) '15-19'\n",
            " '25-29' '20-24' '40-44' '15-19' '30-34' '30-34' '40-44' '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '40-44' '30-34' '30-34' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '25-29' '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '0-4' '25-29' '25-29'\n",
            " '40-44' '25-29' '30-34' '20-24' '20-24' '25-29' '30-34' '20-24' '30-34'\n",
            " '0-4' '20-24' '35-39' '30-34' '20-24' '25-29' '35-39' '20-24' '20-24'\n",
            " '35-39' '35-39' '25-29' '35-39' '30-34' '20-24' '15-19' '30-34' '25-29'\n",
            " '30-34' '15-19' '40-44']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at output data\n",
        "raw_data['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HePUlhNvfWF",
        "outputId": "2dfd6794-2af3-429c-fc73-aaa8a68f2bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no-recurrence-events    201\n",
              "recurrence-events        85\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only 2 possible outputs, thus needs converting to binary format for use in classifier models."
      ],
      "metadata": {
        "id": "bkV5bQKKwYHj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMB3eKfC7goU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b256fb6-68d4-4389-9b8f-1c284342188e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True outputs: 29.72 %\n"
          ]
        }
      ],
      "source": [
        "# Check output balance\n",
        "out = raw_data.iloc[:, -1].values\n",
        "no_rows = len(raw_data)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "code_rows = le.fit_transform(out)\n",
        "print(\"True outputs: {:.2f} %\".format(sum(code_rows)/len(raw_data)*100))\n",
        "pos = sum(code_rows)\n",
        "neg = len(raw_data)-sum(code_rows)\n",
        "del out, no_rows, le, code_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clear imbalance between output data. Some degree of bias/weighting/sampling will be required to ensure that results accurately predict outcomes for both True and False outcomes."
      ],
      "metadata": {
        "id": "mMo9-0hTwirc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f02MTYgB7goW"
      },
      "outputs": [],
      "source": [
        "# Explain your key findings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data set is made up of 9 independent variables all of which appear catagorical in nature. Although stored as an integer, 'deg-malig' can be viewed as  catagorical data as it can only contain 3 discrete values.**\n",
        "\n",
        "**The inclusion of datetime data entries in both the 'tumor-size' and 'inv-nodes' fields appears to be caused by a formatting entry within Excel. For example, '10-14' being input erroneously as 10/14 thus Excel has interpreted (and converted) it to the datetime field 01/10/2014. A function will need to be written within the model to convert these back to correct format.**\n",
        "\n",
        "**How to deal with '?' entries in fields that are otherwise boolean poses an interesting dilemma. If these are infact meant to signify that the presence is unknown because no diagnostic work has been conducted, then this woiuld signify a valid dat entry. If it is however just an incomplete data entry then there is a risk its inclusion could skew the model results. Without knowing which it seems wisest to remove this data from the dataset. Removal of the entire field could well deprive the model of important information, thus just removing these specific entries (rows) appears the most sensible option, particularly noting that there are relatively few occurences.**\n",
        "\n",
        "**Data set is imbalanced, with dependent variable outputs only True in 30% of instances. The model applied will require this imbalance to be taken into account so as not to sacrifice results predicting this smaller class (surely the aim of cancer diagnosis) so as to achieve a high accuracy figure.**\n",
        "\n",
        "**Output variable will need converting into binary output for use with a binary classification model.**"
      ],
      "metadata": {
        "id": "V7OWyLcOrgWJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzZj8I8G7goX"
      },
      "source": [
        "Create any data pre-processing that you will conduct on seen and unseen data.  Regardless of the model you use, this dataframe must contain only numeric features and have a strategy for any expected missing values. Any objects can that are needed to handle the test data that are dependent on the training data can be stored in the model class.  You are recommended to use sklearn Pipelines or similar functionality to ensure reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct date types in 'tumor-size' and 'inv-nodes' variables\n",
        "for i in range(0, len(raw_data)):\n",
        "    if type(raw_data['tumor-size'][i]) is not str:\n",
        "        if raw_data['tumor-size'][i].day == 1:\n",
        "            raw_data['tumor-size'][i] = str(raw_data['tumor-size'][i].month) +'-' + str(raw_data['tumor-size'][i].year-2000)\n",
        "        else:\n",
        "            raw_data['tumor-size'][i] = str(raw_data['tumor-size'][i].day) + '-' + str(raw_data['tumor-size'][i].month)\n",
        "    if type(raw_data['inv-nodes'][i]) is not str:\n",
        "        if raw_data['inv-nodes'][i].day == 1:\n",
        "            raw_data['inv-nodes'][i] = str(raw_data['inv-nodes'][i].month) + '-' + str(raw_data['inv-nodes'][i].year-2000)\n",
        "        else:\n",
        "            raw_data['inv-nodes'][i] = str(raw_data['inv-nodes'][i].day) + '-' + str(raw_data['inv-nodes'][i].month)        "
      ],
      "metadata": {
        "id": "GlZwiMllRpUB",
        "outputId": "62054574-200d-4fce-fec9-eb6249ae6ddc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all rows containing ? data\n",
        "indx = raw_data[raw_data.isin(['?'])].stack(dropna=True).unstack().index\n",
        "print(f\"indx: {indx}\")\n",
        "raw_data = raw_data.drop(index=indx)"
      ],
      "metadata": {
        "id": "ThhbSU5gPBYA",
        "outputId": "a800a455-db75-454c-a145-92abcbaf4275",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indx: Int64Index([20, 31, 50, 54, 71, 92, 149, 240, 264], dtype='int64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIh9_0pp7goY"
      },
      "outputs": [],
      "source": [
        "# Split your data so that you can test the effectiveness of your model\n",
        "# Split the data into a Training set and a Test set\n",
        "dfs = np.split(raw_data, [len(raw_data.columns)-1], axis=1)\n",
        "X = dfs[0]\n",
        "y = dfs[1]\n",
        "\n",
        "# Handle categorical values and drop dummy variable\n",
        "# Remove non-categorical data\n",
        "dm = X.pop('deg-malig')\n",
        "# Encode the catagorical data (dummy variables)\n",
        "proc_X = pd.get_dummies(data=X, prefix_sep='_', drop_first=True)\n",
        "# Add back in non-categorical data\n",
        "proc_X.insert(0, 'deg-malig', dm)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(proc_X, y, test_size = 0.25, random_state = 42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate class weights\n",
        "weight_0 = (1 / neg) * ((pos + neg) / 2)\n",
        "weight_1 = (1 / pos) * ((pos + neg) / 2)\n",
        "class_weight = np.log([pos/neg])\n",
        "class_weight_dict = {0: weight_0, 1: weight_1}\n",
        "print(f\"Weight for 0: {weight_0}\")\n",
        "print(f\"Weight for 1: {weight_1}\")"
      ],
      "metadata": {
        "id": "CtCPaYUj8dcn",
        "outputId": "37f6b659-cea8-4448-9abd-2f0c461e8eee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight for 0: 0.7114427860696517\n",
            "Weight for 1: 1.6823529411764706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbOQACY77goY"
      },
      "outputs": [],
      "source": [
        "# Populate preprocess_training_data and preprocess_test_data to preprocess data.\n",
        "# You must process test and train separately so your model does not accidently gain information that a model wouldnt have in reality and therefore get better predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xsq2f8747goZ"
      },
      "outputs": [],
      "source": [
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "class Module4_Model:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.metrics = [\n",
        "            keras.metrics.TruePositives(name='tp'),\n",
        "            keras.metrics.FalsePositives(name='fp'),\n",
        "            keras.metrics.TrueNegatives(name='tn'),\n",
        "            keras.metrics.FalseNegatives(name='fn'),\n",
        "            keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "            keras.metrics.Recall(name='recall'),\n",
        "            keras.metrics.Precision(name='precision'),\n",
        "            keras.metrics.AUC(name='prc', curve='PR'),\n",
        "        ]\n",
        "        self.EPOCHS = 500\n",
        "        self.BATCH = 100\n",
        "        self.THR = 0.3\n",
        "        self.stop_crit = keras.callbacks.EarlyStopping(\n",
        "            monitor='val_prc',\n",
        "            verbose=1,\n",
        "            patience=50,\n",
        "            mode='max',\n",
        "            restore_best_weights=True)\n",
        "\n",
        "    def preprocess_training_data(self, training_df):\n",
        "        \"\"\"\n",
        "        This function should process the training data and store any features\n",
        "        required in the class\n",
        "        \"\"\"         \n",
        "        # Apply feature scaling\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "        sc = StandardScaler()\n",
        "        processed_df = sc.fit_transform(training_df)\n",
        "        return processed_df, sc\n",
        "\n",
        "    def preprocess_test_data(self, test_df):\n",
        "        \"\"\"\n",
        "        This function should process the test data and store any features\n",
        "        required in the class\n",
        "        \"\"\"\n",
        "        # Apply feature scaling\n",
        "        processed_df = self.scalar.transform(test_df)\n",
        "        return processed_df\n",
        "\n",
        "    def make_model(self,hp):\n",
        "        model = keras.Sequential()\n",
        "        output_bias = keras.initializers.Constant(class_weight)\n",
        "        # Tune the number of units in each layer\n",
        "        hp_units1 = hp.Int('units1',min_value=16,max_value=128,step=2)\n",
        "        hp_units2 = hp.Int('units2',min_value=16,max_value=64,step=2)\n",
        "        hp_units3 = hp.Int('units3',min_value=16,max_value=32,step=2)\n",
        "\n",
        "        model.add(Dense(hp_units1,\n",
        "                        activation=hp.Choice(\n",
        "                            name='dense_activation1',\n",
        "                            values=['relu','selu','leaky-relu'],\n",
        "                            default='selu'),\n",
        "                        input_shape=(x_train_processed.shape[-1],),\n",
        "                        kernel_initializer='lecun_normal'\n",
        "                        ))\n",
        "        #model.add(Dropout(0.5))\n",
        "        model.add(Dense(hp_units2,\n",
        "                        activation=hp.Choice(\n",
        "                            name='dense_activation2',\n",
        "                            values=['relu','selu','leaky-relu'],\n",
        "                            default='leaky-relu'),\n",
        "                        kernel_initializer='lecun_normal'\n",
        "                        ))\n",
        "        model.add(Dense(hp_units3,\n",
        "                        activation=hp.Choice(\n",
        "                            name='dense_activation3',\n",
        "                            values=['relu','selu','leaky-relu'],\n",
        "                            default='leaky-relu'),\n",
        "                        kernel_initializer='lecun_normal'\n",
        "                        ))\n",
        "        model.add(Dense(1,kernel_initializer='normal',activation='sigmoid',bias_initializer=output_bias))\n",
        "        hp_learning_rate = hp.Choice('learning_rate',values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adamax(learning_rate=hp_learning_rate),\n",
        "            loss=keras.losses.BinaryCrossentropy(),\n",
        "            metrics=self.metrics)\n",
        "        \n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3LiNNCb7goa"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "my_model = Module4_Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQD7WPdN7god"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "x_train_processed, my_model.scalar = my_model.preprocess_training_data(X_train)\n",
        "x_val_processed = my_model.preprocess_test_data(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the output data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb = LabelEncoder()\n",
        "y_train = pd.DataFrame(lb.fit_transform(y_train))\n",
        "y_val = pd.DataFrame(lb.transform(y_val))\n",
        "y_test = pd.DataFrame(lb.transform(y_test))"
      ],
      "metadata": {
        "id": "xZNGF1UxWGU5",
        "outputId": "a9499ecc-3de9-444b-924c-c74e819a8f56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnLHgaXS7goe"
      },
      "outputs": [],
      "source": [
        "# Create a model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "from keras.layers import LeakyReLU,ELU,PReLU,Dropout\n",
        "from keras.losses import MeanSquaredLogarithmicError\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "msle = MeanSquaredLogarithmicError()\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.3))})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilise HyperBand algorithm from keras tuner to construct model\n",
        "tuner = kt.Hyperband(\n",
        "    my_model.make_model,\n",
        "    objective=kt.Objective('val_prc', direction='max'),\n",
        "    max_epochs=50,\n",
        "    directory='keras_tuner_dir',\n",
        "    project_name='keras_tuner',\n",
        ")\n",
        "tuner.search(x_train_processed,y_train,epochs=10,validation_split=0.2)"
      ],
      "metadata": {
        "id": "p1Ph9bZMV5G6",
        "outputId": "0f5050f6-ea73-4ae9-fff4-c703a20d05d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 07s]\n",
            "val_prc: 0.32779064774513245\n",
            "\n",
            "Best val_prc So Far: 0.5932174921035767\n",
            "Total elapsed time: 00h 04m 18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rQwUj4lk7goe"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "x_test_processed = my_model.preprocess_test_data(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for h_param in [f\"units{i}\" for i in range(1,4)] + ['learning_rate'] + [f\"dense_activation{i}\" for i in range(1,4)]:\n",
        "    print(h_param, tuner.get_best_hyperparameters()[0].get(h_param))\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "HuWZxfcvYOI4",
        "outputId": "462ef78d-5863-49f6-e356-233079a883fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "units1 120\n",
            "units2 28\n",
            "units3 18\n",
            "learning_rate 0.001\n",
            "dense_activation1 relu\n",
            "dense_activation2 selu\n",
            "dense_activation3 elu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.best_model = tuner.get_best_models()[0]\n",
        "my_model.best_model.build(x_train_processed.shape)\n",
        "my_model.best_model.summary()"
      ],
      "metadata": {
        "id": "Lku4uguEY1ar",
        "outputId": "8a42dbe7-b58c-4082-bf8c-9100029c76ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 120)               3840      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 28)                3388      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 18)                522       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 19        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,769\n",
            "Trainable params: 7,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the best model (with class weights)\n",
        "my_model.best_model.fit(x_train_processed,\n",
        "                   y_train,\n",
        "                   batch_size=my_model.BATCH,\n",
        "                   epochs=my_model.EPOCHS,\n",
        "                   callbacks=[my_model.stop_crit,\n",
        "                              keras.callbacks.ReduceLROnPlateau(monitor='val_prc',\n",
        "                                                                factor=0.2,\n",
        "                                                                patience=20,\n",
        "                                                                mode='max',\n",
        "                                                                cooldown=10)],\n",
        "                   validation_data=(x_val_processed,y_val),\n",
        "                   class_weight=class_weight_dict)"
      ],
      "metadata": {
        "id": "DFAWtazI9LH4",
        "outputId": "8f25e6b0-55f6-4959-b36a-43dee98162a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 2s 626ms/step - loss: 0.8224 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 145.0000 - fn: 62.0000 - accuracy: 0.7005 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.3321 - val_loss: 0.5053 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.5640 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8221 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4062 - val_loss: 0.5053 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.5605 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.8217 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4126 - val_loss: 0.5054 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.5882 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8213 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4009 - val_loss: 0.5054 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6375 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8209 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4011 - val_loss: 0.5055 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6375 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8205 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4095 - val_loss: 0.5055 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6103 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8201 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4140 - val_loss: 0.5056 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6098 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8197 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4124 - val_loss: 0.5056 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6423 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8193 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4195 - val_loss: 0.5057 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6423 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8189 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4232 - val_loss: 0.5058 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6439 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8185 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4304 - val_loss: 0.5058 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6749 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8182 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4254 - val_loss: 0.5059 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6442 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8178 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4227 - val_loss: 0.5059 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6407 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8174 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4197 - val_loss: 0.5060 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6402 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8170 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4178 - val_loss: 0.5060 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6397 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8166 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4114 - val_loss: 0.5061 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6330 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8162 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4188 - val_loss: 0.5062 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6304 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8158 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4175 - val_loss: 0.5062 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6496 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8154 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4176 - val_loss: 0.5063 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6585 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8150 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4165 - val_loss: 0.5063 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6585 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8146 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4204 - val_loss: 0.5064 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6581 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8143 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4194 - val_loss: 0.5064 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6550 - lr: 2.0000e-04\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8142 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4217 - val_loss: 0.5064 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6904 - lr: 2.0000e-04\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8142 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4219 - val_loss: 0.5064 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6904 - lr: 2.0000e-04\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8141 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4219 - val_loss: 0.5064 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6904 - lr: 2.0000e-04\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8140 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4219 - val_loss: 0.5064 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6904 - lr: 2.0000e-04\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8139 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4212 - val_loss: 0.5065 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6904 - lr: 2.0000e-04\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8138 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4199 - val_loss: 0.5065 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6898 - lr: 2.0000e-04\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8138 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4194 - val_loss: 0.5065 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6574 - lr: 2.0000e-04\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.8137 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4194 - val_loss: 0.5065 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6765 - lr: 2.0000e-04\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.8136 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4199 - val_loss: 0.5065 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6765 - lr: 2.0000e-04\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.8135 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4193 - val_loss: 0.5065 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6765 - lr: 2.0000e-04\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8134 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4183 - val_loss: 0.5065 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6756 - lr: 2.0000e-04\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8134 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4166 - val_loss: 0.5065 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6756 - lr: 2.0000e-04\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8133 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4184 - val_loss: 0.5065 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6756 - lr: 2.0000e-04\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8132 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4181 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6756 - lr: 2.0000e-04\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8131 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4213 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6756 - lr: 2.0000e-04\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8131 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4209 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6756 - lr: 2.0000e-04\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8130 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4209 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6756 - lr: 2.0000e-04\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.8129 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4206 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6756 - lr: 2.0000e-04\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.8129 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4206 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6756 - lr: 4.0000e-05\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8128 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4206 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6756 - lr: 4.0000e-05\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.8128 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4206 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6756 - lr: 4.0000e-05\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8128 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4206 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6756 - lr: 4.0000e-05\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8128 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4206 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6756 - lr: 4.0000e-05\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8128 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4232 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6756 - lr: 4.0000e-05\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8128 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4232 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 4.0000e-05\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8127 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4232 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 4.0000e-05\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8127 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4232 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 4.0000e-05\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8127 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 4.0000e-05\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8127 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 4.0000e-05\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8127 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 4.0000e-05\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8127 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 4.0000e-05\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.8127 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 4.0000e-05\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.8126 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4243 - val_loss: 0.5066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 4.0000e-05\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8126 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4252 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 4.0000e-05\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8126 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4252 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 4.0000e-05\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8126 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 4.0000e-05\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8126 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 4.0000e-05\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8126 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8126 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8126 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8126 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4249 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4240 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4240 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4240 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4240 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4240 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4240 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4240 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4240 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4240 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4240 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4240 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4240 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4239 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4239 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4239 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4239 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8123 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4239 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8123 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4239 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8123 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4239 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8123 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4239 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8123 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4239 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8123 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4239 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8123 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4239 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 123/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.9183 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 61.0000 - fn: 39.0000 - accuracy: 0.6100 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4584Restoring model weights from the end of the best epoch: 23.\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.8123 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 111.0000 - fn: 54.0000 - accuracy: 0.6727 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.4239 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 34.0000 - val_fn: 8.0000 - val_accuracy: 0.8095 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.6751 - lr: 1.0000e-05\n",
            "Epoch 123: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f342835e890>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualise the loss and accuracy for each epoch"
      ],
      "metadata": {
        "id": "G9DPmZDDXEnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(my_model.best_model.history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "84wnXBf0XDyz",
        "outputId": "d72f5226-a24d-46a3-c1f4-31cd1165fd53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "#print(my_model.best_model.history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(my_model.best_model.history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c_bC8ZieW5fQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b4cbf4bd-ce1a-4d06-e829-0daea875aebc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "kwOiqNee7goj"
      },
      "outputs": [],
      "source": [
        "# use your model to make a prediction on unseen data\n",
        "y_pred = my_model.best_model.predict(x_test_processed,batch_size=my_model.BATCH)\n",
        "#convert values\n",
        "y_pred = (y_pred>my_model.THR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "VGgleoej7gok",
        "outputId": "a73014e0-b2e2-41d4-8f19-05bdea2ed758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 44.29 %\n",
            "Weighted ROC AUC accuracy: 48.56 %\n",
            "Confusion matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Asssess the accuracy of your model and explain your key findings\n",
        "# Generate confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "score = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {:.2f} %\".format(score*100))\n",
        "print(\"Weighted ROC AUC accuracy: {:.2f} %\".format(roc_auc_score(y_test, y_pred, average='weighted')*100))\n",
        "print(\"Confusion matrix:\")\n",
        "disp = ConfusionMatrixDisplay(cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Apply k-fold Cross Validation\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# from numpy import ravel\n",
        "# accuracies = cross_val_score(estimator = classifier, X = x_train_processed, y = ravel(y_train.values), scoring = 'roc_auc_ovo', cv = 10)\n",
        "# print(\"K-fold cross validation results\")\n",
        "# print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "# print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model is approx 65-70% accurate at predicting whether cancer recurrence will occur.**\n",
        "\n",
        "**Crucially, the proportion of False Negatives is low (<15%). In cancer diagnosis these are the outcomes that we want to minimise. False Positives, whilst undesirable, will likely lead to further diagnostic testing before it is realised that cancer is not present.**"
      ],
      "metadata": {
        "id": "UMNN4P_E07L6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDU85k7J7gok"
      },
      "source": [
        "### Unit tests:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq2QRpri7gol"
      },
      "source": [
        "###Checking training and test data for null values. This will work for both pd dataframes and np arrays, and ensures no null values exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "oUeh38w_7gol"
      },
      "outputs": [],
      "source": [
        "def test_no_nulls(data):\n",
        "    \"\"\" Assert no null values within pd dataframe or np array \"\"\"\n",
        "    \n",
        "    # if data is numpy array, handle accordingly\n",
        "    if isinstance(data, (np.ndarray)):\n",
        "        assert not np.isnan(np.min(data))\n",
        "    \n",
        "    # if not np array, assume data is pandas dataframe\n",
        "    else:\n",
        "        assert data.isna().sum().sum() == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BV9Z1F3i7gom"
      },
      "outputs": [],
      "source": [
        "# run null data unit test on both training and test data\n",
        "test_no_nulls(x_train_processed)\n",
        "test_no_nulls(x_test_processed)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of KSVC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}