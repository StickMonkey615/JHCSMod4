{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StickMonkey615/JHCSMod4/blob/main/ANN%20v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRn73TIW7gn9"
      },
      "source": [
        "# Module 4 Guidance\n",
        "\n",
        "This notebook is a template for module 4b and 4c, which will be tested in Google Colab, your code needs to run there.\n",
        "The structure has been provided to improve consistency and make it easier for markers to understand your code but still give students the flexibility to be creative.  You need to populate the required functions to solve this problem.  All dependencies should be documented in the next cell.\n",
        "\n",
        "You can:\n",
        "    add further cells or text blocks to extend or further explain your solution\n",
        "    add further functions\n",
        "\n",
        "Dont:\n",
        "    rename functions\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZxOsuHxz7goC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e4214cb-ac1d-4065-ae0f-506491801518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 40.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.48.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
            "Installing collected packages: jedi, kt-legacy, keras-tuner\n",
            "Successfully installed jedi-0.18.1 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "# Fixed dependencies - do not remove or change.\n",
        "import pytest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/gdrive/')\n",
        "# Import your dependencies\n",
        "!pip install --upgrade xlrd > 1.2.0\n",
        "import xlrd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "!pip install keras-tuner --upgrade\n",
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1m_gmKQP7goE"
      },
      "outputs": [],
      "source": [
        "# Import data\n",
        "\n",
        "def import_local_data(file_path):\n",
        "    \"\"\"This function needs to import the data file into collab and return a pandas dataframe\n",
        "    \"\"\"\n",
        "    raw_df = pd.read_excel(file_path)\n",
        "    return raw_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cIljHljB7goF"
      },
      "outputs": [],
      "source": [
        "local_file_path = \"breast-cancer.xls\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LCu51H5Z7goF"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "raw_data = import_local_data(local_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9WDYKUP7goG"
      },
      "source": [
        "### Conduct exploratory data analysis and explain your key findings - Examine the data, explain its key features and what they look like.  Highlight any fields that are anomalous."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the different dataframe column headings\n",
        "print(raw_data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkjdfYHGiz7a",
        "outputId": "a9e96855-c9b6-42f0-c6b9-525e8c436a19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig',\n",
            "       'breast', 'breast-quad', 'irradiat', 'Class'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine data types for each column\n",
        "for i in range(0, len(raw_data.columns)):\n",
        "    print(type(raw_data.values[1][i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKqjAI-XigbI",
        "outputId": "a2fac6a2-135e-4004-a5b2-c37d7dd4e8b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'int'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Look at the range of values for each field\n",
        "from collections import Counter\n",
        "rng_vals=[]\n",
        "for i in range(0,len(raw_data.columns)):\n",
        "    rng_vals.append(Counter(raw_data.iloc[:,i].values))\n",
        "    print(f\"{raw_data.columns[i]}: {rng_vals[i]}\")\n",
        "del rng_vals, i"
      ],
      "metadata": {
        "id": "-lQUCdTe36Dp",
        "outputId": "a5a73b57-5fe1-4678-8918-f727788f9992",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age: Counter({'50-59': 96, '40-49': 90, '60-69': 57, '30-39': 36, '70-79': 6, '20-29': 1})\n",
            "menopause: Counter({'premeno': 150, 'ge40': 129, 'lt40': 7})\n",
            "tumor-size: Counter({'30-34': 60, '25-29': 54, '20-24': 50, '15-19': 30, datetime.datetime(2014, 10, 1, 0, 0): 28, '40-44': 22, '35-39': 19, '0-4': 8, '50-54': 8, datetime.datetime(2019, 9, 5, 0, 0): 4, '45-49': 3})\n",
            "inv-nodes: Counter({'0-2': 213, datetime.datetime(2019, 5, 3, 0, 0): 36, datetime.datetime(2019, 8, 6, 0, 0): 17, datetime.datetime(2019, 11, 9, 0, 0): 10, '15-17': 6, datetime.datetime(2014, 12, 1, 0, 0): 3, '24-26': 1})\n",
            "node-caps: Counter({'no': 222, 'yes': 56, '?': 8})\n",
            "deg-malig: Counter({2: 130, 3: 85, 1: 71})\n",
            "breast: Counter({'left': 152, 'right': 134})\n",
            "breast-quad: Counter({'left_low': 110, 'left_up': 97, 'right_up': 33, 'right_low': 24, 'central': 21, '?': 1})\n",
            "irradiat: Counter({'no': 218, 'yes': 68})\n",
            "Class: Counter({'no-recurrence-events': 201, 'recurrence-events': 85})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All fields look to contain data that is catagorical in nature.**\n",
        "\n",
        "**Some contain data that appears erroneous:**\n",
        " \n",
        "*   **'tumor-size' and 'inv-nodes' appear to contain some data in a datetime format and some in string.**\n",
        "*   **'node-caps' and 'breast-quad' contain Question Marks.**\n",
        "\n",
        "**Need a way to address these erroneous data inputs.**\n",
        "\n"
      ],
      "metadata": {
        "id": "lALFUx2EEQF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look in more detail at the columns with datetime data.\n",
        "print(raw_data.iloc[:, 2].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IetVwnCr3XI",
        "outputId": "21645753-61ec-48ce-96dc-98e6dc430987"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['15-19' '15-19' '35-39' '35-39' '30-34' '25-29' '40-44'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '0-4' '40-44' '25-29' '15-19'\n",
            " '30-34' '25-29' '25-29' '20-24' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '15-19' '40-44' '20-24' '20-24' '40-44' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '15-19' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '30-34' '15-19' '30-34' '25-29' '25-29' '20-24' '30-34' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '45-49' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '35-39' '25-29' '20-24'\n",
            " '15-19' '30-34' datetime.datetime(2014, 10, 1, 0, 0) '35-39' '50-54'\n",
            " '40-44' '15-19' '30-34' '0-4' '40-44' '25-29' '25-29' '20-24' '35-39'\n",
            " '50-54' '0-4' '40-44' '30-34' '20-24' '30-34' '20-24' '15-19' '25-29'\n",
            " '15-19' '50-54' datetime.datetime(2014, 10, 1, 0, 0) '25-29' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '15-19' '25-29' '25-29' '30-34'\n",
            " '15-19' '25-29' '30-34' '15-19' '0-4' '35-39' '40-44' '25-29' '20-24'\n",
            " '30-34' '20-24' '30-34' '20-24' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '20-24' '45-49' '40-44' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " '35-39' '20-24' '15-19' '30-34' '20-24' '20-24' '30-34' '20-24' '25-29'\n",
            " '30-34' '20-24' '15-19' '30-34' '30-34' '40-44'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '30-34' datetime.datetime(2014, 10, 1, 0, 0) '35-39' '20-24' '30-34'\n",
            " '25-29' '15-19' '35-39' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " '30-34' '25-29' '15-19' '15-19' '30-34' '35-39' '30-34' '25-29' '30-34'\n",
            " '15-19' '0-4' '0-4' '50-54' '30-34' '20-24' '25-29' '30-34' '20-24'\n",
            " '15-19' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '40-44' '30-34' '50-54' '15-19'\n",
            " '40-44' '25-29' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '25-29' '25-29' '30-34' '50-54'\n",
            " '30-34' '20-24' '30-34' '25-29' '20-24' '20-24' '50-54' '20-24' '30-34'\n",
            " '25-29' '25-29' '40-44' '20-24' '20-24' '25-29' '25-29' '20-24' '40-44'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '30-34'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) '15-19' '30-34' '25-29'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) '25-29' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '50-54' '25-29' '20-24'\n",
            " '30-34' '30-34' '15-19' '20-24' datetime.datetime(2019, 9, 5, 0, 0)\n",
            " '30-34' '30-34' '25-29' '25-29' '40-44' '25-29' '30-34' '30-34' '25-29'\n",
            " '25-29' '40-44' '20-24' '25-29' '20-24' '40-44' '25-29' '25-29' '45-49'\n",
            " '20-24' '25-29' '20-24' '20-24' '35-39' '20-24' '30-34' '25-29' '30-34'\n",
            " '25-29' '20-24' '20-24' datetime.datetime(2014, 10, 1, 0, 0) '15-19'\n",
            " '25-29' '20-24' '40-44' '15-19' '30-34' '30-34' '40-44' '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '40-44' '30-34' '30-34' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '25-29' '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '0-4' '25-29' '25-29'\n",
            " '40-44' '25-29' '30-34' '20-24' '20-24' '25-29' '30-34' '20-24' '30-34'\n",
            " '0-4' '20-24' '35-39' '30-34' '20-24' '25-29' '35-39' '20-24' '20-24'\n",
            " '35-39' '35-39' '25-29' '35-39' '30-34' '20-24' '15-19' '30-34' '25-29'\n",
            " '30-34' '15-19' '40-44']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at output data\n",
        "raw_data['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HePUlhNvfWF",
        "outputId": "ff179b68-c32b-47ba-d860-7e6ed723d5bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no-recurrence-events    201\n",
              "recurrence-events        85\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only 2 possible outputs, thus needs converting to binary format for use in classifier models."
      ],
      "metadata": {
        "id": "bkV5bQKKwYHj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KMB3eKfC7goU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f54178-9501-4d28-c415-b55355ee0c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True outputs: 29.72 %\n"
          ]
        }
      ],
      "source": [
        "# Check output balance\n",
        "out = raw_data.iloc[:, -1].values\n",
        "no_rows = len(raw_data)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "code_rows = le.fit_transform(out)\n",
        "print(\"True outputs: {:.2f} %\".format(sum(code_rows)/len(raw_data)*100))\n",
        "pos = sum(code_rows)\n",
        "neg = len(raw_data)-sum(code_rows)\n",
        "del out, no_rows, le, code_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clear imbalance between output data. Some degree of bias/weighting/sampling will be required to ensure that results accurately predict outcomes for both True and False outcomes."
      ],
      "metadata": {
        "id": "mMo9-0hTwirc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f02MTYgB7goW"
      },
      "outputs": [],
      "source": [
        "# Explain your key findings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data set is made up of 9 independent variables all of which appear catagorical in nature. Although stored as an integer, 'deg-malig' can be viewed as  catagorical data as it can only contain 3 discrete values.**\n",
        "\n",
        "**The inclusion of datetime data entries in both the 'tumor-size' and 'inv-nodes' fields appears to be caused by a formatting entry within Excel. For example, '10-14' being input erroneously as 10/14 thus Excel has interpreted (and converted) it to the datetime field 01/10/2014. A function will need to be written within the model to convert these back to correct format.**\n",
        "\n",
        "**How to deal with '?' entries in fields that are otherwise boolean poses an interesting dilemma. If these are infact meant to signify that the presence is unknown because no diagnostic work has been conducted, then this woiuld signify a valid dat entry. If it is however just an incomplete data entry then there is a risk its inclusion could skew the model results. Without knowing which it seems wisest to remove this data from the dataset. Removal of the entire field could well deprive the model of important information, thus just removing these specific entries (rows) appears the most sensible option, particularly noting that there are relatively few occurences.**\n",
        "\n",
        "**Data set is imbalanced, with dependent variable outputs only True in 30% of instances. The model applied will require this imbalance to be taken into account so as not to sacrifice results predicting this smaller class (surely the aim of cancer diagnosis) so as to achieve a high accuracy figure.**\n",
        "\n",
        "**Output variable will need converting into binary output for use with a binary classification model.**"
      ],
      "metadata": {
        "id": "V7OWyLcOrgWJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzZj8I8G7goX"
      },
      "source": [
        "Create any data pre-processing that you will conduct on seen and unseen data.  Regardless of the model you use, this dataframe must contain only numeric features and have a strategy for any expected missing values. Any objects can that are needed to handle the test data that are dependent on the training data can be stored in the model class.  You are recommended to use sklearn Pipelines or similar functionality to ensure reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct date types in 'tumor-size' and 'inv-nodes' variables\n",
        "for i in range(0, len(raw_data)):\n",
        "    if type(raw_data['tumor-size'][i]) is not str:\n",
        "        if raw_data['tumor-size'][i].day == 1:\n",
        "            raw_data['tumor-size'][i] = str(raw_data['tumor-size'][i].month) +'-' + str(raw_data['tumor-size'][i].year-2000)\n",
        "        else:\n",
        "            raw_data['tumor-size'][i] = str(raw_data['tumor-size'][i].day) + '-' + str(raw_data['tumor-size'][i].month)\n",
        "    if type(raw_data['inv-nodes'][i]) is not str:\n",
        "        if raw_data['inv-nodes'][i].day == 1:\n",
        "            raw_data['inv-nodes'][i] = str(raw_data['inv-nodes'][i].month) + '-' + str(raw_data['inv-nodes'][i].year-2000)\n",
        "        else:\n",
        "            raw_data['inv-nodes'][i] = str(raw_data['inv-nodes'][i].day) + '-' + str(raw_data['inv-nodes'][i].month)        "
      ],
      "metadata": {
        "id": "GlZwiMllRpUB",
        "outputId": "1d2bc9da-51fe-4970-bb19-6c2fe246ea7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all rows containing ? data\n",
        "indx = raw_data[raw_data.isin(['?'])].stack(dropna=True).unstack().index\n",
        "print(f\"indx: {indx}\")\n",
        "raw_data = raw_data.drop(index=indx)"
      ],
      "metadata": {
        "id": "ThhbSU5gPBYA",
        "outputId": "67a0ed54-1ac7-4d66-b619-e7ac1e688ed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indx: Int64Index([20, 31, 50, 54, 71, 92, 149, 240, 264], dtype='int64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WIh9_0pp7goY"
      },
      "outputs": [],
      "source": [
        "# Split your data so that you can test the effectiveness of your model\n",
        "# Split the data into a Training set and a Test set\n",
        "dfs = np.split(raw_data, [len(raw_data.columns)-1], axis=1)\n",
        "X = dfs[0]\n",
        "y = dfs[1]\n",
        "\n",
        "# Handle categorical values and drop dummy variable\n",
        "# Remove non-categorical data\n",
        "dm = X.pop('deg-malig')\n",
        "# Encode the catagorical data (dummy variables)\n",
        "proc_X = pd.get_dummies(data=X, prefix_sep='_', drop_first=True)\n",
        "# Add back in non-categorical data\n",
        "proc_X.insert(0, 'deg-malig', dm)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(proc_X, y, test_size = 0.25, random_state = 42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate class weights\n",
        "weight_0 = (1 / neg) * ((pos + neg) / 2)\n",
        "weight_1 = (1 / pos) * ((pos + neg) / 2)\n",
        "class_weight = np.log([pos/neg])\n",
        "class_weight_dict = {0: weight_0, 1: weight_1}\n",
        "print(f\"Weight for 0: {weight_0}\")\n",
        "print(f\"Weight for 1: {weight_1}\")"
      ],
      "metadata": {
        "id": "CtCPaYUj8dcn",
        "outputId": "a010d722-d00a-4f89-b914-09002c251d40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight for 0: 0.7114427860696517\n",
            "Weight for 1: 1.6823529411764706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AbOQACY77goY"
      },
      "outputs": [],
      "source": [
        "# Populate preprocess_training_data and preprocess_test_data to preprocess data.\n",
        "# You must process test and train separately so your model does not accidently gain information that a model wouldnt have in reality and therefore get better predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Xsq2f8747goZ"
      },
      "outputs": [],
      "source": [
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "class Module4_Model:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.metrics = [\n",
        "            keras.metrics.TruePositives(name='tp'),\n",
        "            keras.metrics.FalsePositives(name='fp'),\n",
        "            keras.metrics.TrueNegatives(name='tn'),\n",
        "            keras.metrics.FalseNegatives(name='fn'),\n",
        "            keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "            keras.metrics.Recall(name='recall'),\n",
        "            keras.metrics.Precision(name='precision'),\n",
        "            keras.metrics.AUC(name='prc', curve='PR'),\n",
        "        ]\n",
        "        self.EPOCHS = 500\n",
        "        self.BATCH = 100\n",
        "        self.THR = 0.3\n",
        "        self.stop_crit = keras.callbacks.EarlyStopping(\n",
        "            monitor='val_prc',\n",
        "            verbose=1,\n",
        "            patience=100,\n",
        "            mode='max',\n",
        "            restore_best_weights=True)\n",
        "\n",
        "    def preprocess_training_data(self, training_df):\n",
        "        \"\"\"\n",
        "        This function should process the training data and store any features\n",
        "        required in the class\n",
        "        \"\"\"         \n",
        "        # Apply feature scaling\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "        sc = StandardScaler()\n",
        "        processed_df = sc.fit_transform(training_df)\n",
        "        return processed_df, sc\n",
        "\n",
        "    def preprocess_test_data(self, test_df):\n",
        "        \"\"\"\n",
        "        This function should process the test data and store any features\n",
        "        required in the class\n",
        "        \"\"\"\n",
        "        # Apply feature scaling\n",
        "        processed_df = self.scalar.transform(test_df)\n",
        "        return processed_df\n",
        "\n",
        "    def make_model(self,hp):\n",
        "        model = keras.Sequential()\n",
        "        output_bias = keras.initializers.Constant(class_weight)\n",
        "        # Tune the number of units in each layer\n",
        "        hp_units1 = hp.Int('units1',min_value=16,max_value=128,step=2)\n",
        "        hp_units2 = hp.Int('units2',min_value=16,max_value=64,step=2)\n",
        "        hp_units3 = hp.Int('units3',min_value=16,max_value=32,step=2)\n",
        "\n",
        "        model.add(Dense(hp_units1,\n",
        "                        activation=hp.Choice(\n",
        "                            name='dense_activation1',\n",
        "                            values=['tanh','relu','selu','leaky-relu'],\n",
        "                            default='selu'),\n",
        "                        input_shape=(x_train_processed.shape[-1],),\n",
        "                        kernel_initializer='lecun_normal'\n",
        "                        ))\n",
        "        #model.add(Dropout(0.5))\n",
        "        model.add(Dense(hp_units2,\n",
        "                        activation=hp.Choice(\n",
        "                            name='dense_activation2',\n",
        "                            values=['tanh','relu','selu','leaky-relu'],\n",
        "                            default='leaky-relu'),\n",
        "                        kernel_initializer='lecun_normal'\n",
        "                        ))\n",
        "        model.add(Dense(hp_units3,\n",
        "                        activation=hp.Choice(\n",
        "                            name='dense_activation3',\n",
        "                            values=['tanh','relu','selu','leaky-relu'],\n",
        "                            default='leaky-relu'),\n",
        "                        kernel_initializer='lecun_normal'\n",
        "                        ))\n",
        "        model.add(Dense(1,kernel_initializer='normal',activation='sigmoid',bias_initializer=output_bias))\n",
        "        hp_learning_rate = hp.Choice('learning_rate',values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adamax(learning_rate=hp_learning_rate),\n",
        "            loss=keras.losses.BinaryCrossentropy(),\n",
        "            metrics=self.metrics)\n",
        "        \n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "F3LiNNCb7goa"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "my_model = Module4_Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZQD7WPdN7god"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "x_train_processed, my_model.scalar = my_model.preprocess_training_data(X_train)\n",
        "x_val_processed = my_model.preprocess_test_data(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the output data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb = LabelEncoder()\n",
        "y_train = pd.DataFrame(lb.fit_transform(y_train))\n",
        "y_val = pd.DataFrame(lb.transform(y_val))\n",
        "y_test = pd.DataFrame(lb.transform(y_test))"
      ],
      "metadata": {
        "id": "xZNGF1UxWGU5",
        "outputId": "bd8f1cce-82e3-4f84-f738-9507008f58f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XnLHgaXS7goe"
      },
      "outputs": [],
      "source": [
        "# Create a model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "from keras.layers import LeakyReLU,ELU,PReLU,Dropout\n",
        "from keras.losses import MeanSquaredLogarithmicError\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "msle = MeanSquaredLogarithmicError()\n",
        "get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.3))})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilise HyperBand algorithm from keras tuner to construct model\n",
        "tuner = kt.Hyperband(\n",
        "    my_model.make_model,\n",
        "    objective=kt.Objective('val_prc', direction='max'),\n",
        "    max_epochs=50,\n",
        "    directory='keras_tuner_dir',\n",
        "    project_name='keras_tuner',\n",
        ")\n",
        "tuner.search(x_train_processed,y_train,epochs=10,validation_split=0.2)"
      ],
      "metadata": {
        "id": "p1Ph9bZMV5G6",
        "outputId": "c954da9f-50ee-4a58-c9da-93520202f8b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 07s]\n",
            "val_prc: 0.6047655940055847\n",
            "\n",
            "Best val_prc So Far: 0.7019385099411011\n",
            "Total elapsed time: 00h 06m 56s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rQwUj4lk7goe"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "x_test_processed = my_model.preprocess_test_data(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for h_param in [f\"units{i}\" for i in range(1,4)] + ['learning_rate'] + [f\"dense_activation{i}\" for i in range(1,4)]:\n",
        "    print(h_param, tuner.get_best_hyperparameters()[0].get(h_param))\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "HuWZxfcvYOI4",
        "outputId": "62afe1bc-c055-4682-fcbe-24ec7067482c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "units1 86\n",
            "units2 30\n",
            "units3 32\n",
            "learning_rate 0.001\n",
            "dense_activation1 leaky-relu\n",
            "dense_activation2 leaky-relu\n",
            "dense_activation3 leaky-relu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.best_model = tuner.get_best_models()[0]\n",
        "my_model.best_model.build(x_train_processed.shape)\n",
        "my_model.best_model.summary()"
      ],
      "metadata": {
        "id": "Lku4uguEY1ar",
        "outputId": "8826cda5-dce9-47c2-8e05-91be6e0fbe6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 86)                2752      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 30)                2610      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                992       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,387\n",
            "Trainable params: 6,387\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the best model (with class weights)\n",
        "my_model.best_model.fit(x_train_processed,\n",
        "                   y_train,\n",
        "                   batch_size=my_model.BATCH,\n",
        "                   epochs=my_model.EPOCHS,\n",
        "                   callbacks=[my_model.stop_crit],\n",
        "                   validation_data=(x_val_processed,y_val),\n",
        "                   class_weight=class_weight_dict)"
      ],
      "metadata": {
        "id": "DFAWtazI9LH4",
        "outputId": "d1dc052a-4a94-4539-accc-4d8ebd71ccd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.7315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6383 - val_loss: 0.6456 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4863\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6375 - val_loss: 0.6455 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4817\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6326 - val_loss: 0.6454 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4787\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.7308 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6309 - val_loss: 0.6454 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4823\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.7306 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6326 - val_loss: 0.6453 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4812\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.7304 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6341 - val_loss: 0.6452 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4812\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.7302 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6393 - val_loss: 0.6452 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4812\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.7299 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6428 - val_loss: 0.6451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4782\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.7297 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6378 - val_loss: 0.6450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4782\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.7295 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6349 - val_loss: 0.6450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4782\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.7292 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6374 - val_loss: 0.6449 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4837\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.7290 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6377 - val_loss: 0.6448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4837\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.7288 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6373 - val_loss: 0.6448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4858\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7285 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6397 - val_loss: 0.6447 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4858\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7283 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6407 - val_loss: 0.6446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4858\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7281 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6369 - val_loss: 0.6446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4854\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7278 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6324 - val_loss: 0.6445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4910\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7276 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6294 - val_loss: 0.6444 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4910\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7274 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6294 - val_loss: 0.6444 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4849\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7271 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6296 - val_loss: 0.6443 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4849\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7269 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6287 - val_loss: 0.6442 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4849\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7267 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6264 - val_loss: 0.6442 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4814\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7264 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6269 - val_loss: 0.6441 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4814\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7262 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6256 - val_loss: 0.6440 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4869\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7260 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6275 - val_loss: 0.6440 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4906\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7257 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6309 - val_loss: 0.6439 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4927\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7255 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6326 - val_loss: 0.6438 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4927\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.7253 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6332 - val_loss: 0.6438 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4927\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7250 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6331 - val_loss: 0.6437 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4862\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7248 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6303 - val_loss: 0.6437 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4853\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7246 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6303 - val_loss: 0.6436 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4853\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7243 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6286 - val_loss: 0.6435 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4876\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7241 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6294 - val_loss: 0.6435 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4817\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7239 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6252 - val_loss: 0.6434 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4817\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7236 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6271 - val_loss: 0.6433 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4817\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7234 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6249 - val_loss: 0.6433 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4832\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7231 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6272 - val_loss: 0.6432 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4900\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7229 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6269 - val_loss: 0.6431 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4931\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7227 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6236 - val_loss: 0.6431 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4910\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7224 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6233 - val_loss: 0.6430 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4910\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7222 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6238 - val_loss: 0.6430 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4876\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7220 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6235 - val_loss: 0.6429 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4876\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7217 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6253 - val_loss: 0.6428 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4907\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7215 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6259 - val_loss: 0.6428 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4885\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7212 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6261 - val_loss: 0.6427 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4909\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.7210 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6224 - val_loss: 0.6426 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4887\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7208 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6204 - val_loss: 0.6426 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4897\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7205 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6228 - val_loss: 0.6425 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4897\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7203 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6173 - val_loss: 0.6424 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4897\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7200 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6206 - val_loss: 0.6424 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4899\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7198 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6211 - val_loss: 0.6423 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4889\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7195 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6223 - val_loss: 0.6423 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4912\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7193 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6202 - val_loss: 0.6422 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4940\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7191 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6212 - val_loss: 0.6421 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4940\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7188 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6242 - val_loss: 0.6421 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4909\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7186 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6220 - val_loss: 0.6420 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4909\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7183 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6243 - val_loss: 0.6419 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4909\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7181 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6239 - val_loss: 0.6419 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4899\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7178 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6238 - val_loss: 0.6418 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4899\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7176 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6245 - val_loss: 0.6417 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4882\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7174 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6263 - val_loss: 0.6417 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4882\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.7171 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6205 - val_loss: 0.6416 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4863\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7169 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6229 - val_loss: 0.6415 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4863\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.7166 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6233 - val_loss: 0.6415 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4863\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.7164 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6233 - val_loss: 0.6414 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4863\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7161 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6222 - val_loss: 0.6413 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4863\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.7159 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6204 - val_loss: 0.6412 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4863\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7156 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6156 - val_loss: 0.6412 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4863\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7154 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6147 - val_loss: 0.6411 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4871\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7151 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6179 - val_loss: 0.6410 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4862\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7149 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6168 - val_loss: 0.6410 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4918\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7146 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6157 - val_loss: 0.6409 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4907\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.7144 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6156 - val_loss: 0.6408 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4930\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7141 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6111 - val_loss: 0.6408 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4930\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7139 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6115 - val_loss: 0.6407 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4930\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7136 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6080 - val_loss: 0.6406 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4952\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7134 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6181 - val_loss: 0.6406 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4952\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7131 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6185 - val_loss: 0.6405 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4952\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.7128 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6191 - val_loss: 0.6404 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4952\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7126 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6159 - val_loss: 0.6404 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4896\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6141 - val_loss: 0.6403 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4896\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7121 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6147 - val_loss: 0.6402 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4896\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7118 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6143 - val_loss: 0.6402 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4911\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.7116 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6176 - val_loss: 0.6401 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4911\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.7113 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6176 - val_loss: 0.6400 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4911\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7111 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6176 - val_loss: 0.6400 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4911\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7108 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6133 - val_loss: 0.6399 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4888\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7106 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6145 - val_loss: 0.6398 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4874\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7103 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6144 - val_loss: 0.6398 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4898\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7101 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6135 - val_loss: 0.6397 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4898\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7098 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6196 - val_loss: 0.6397 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4898\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7095 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6197 - val_loss: 0.6396 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4889\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7093 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6156 - val_loss: 0.6395 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4911\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6153 - val_loss: 0.6395 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4911\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7088 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6145 - val_loss: 0.6394 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4906\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7085 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6141 - val_loss: 0.6394 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4900\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7083 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6144 - val_loss: 0.6393 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4890\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7080 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6172 - val_loss: 0.6392 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4865\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7077 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6136 - val_loss: 0.6392 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4920\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7075 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6147 - val_loss: 0.6391 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4920\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.7072 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6145 - val_loss: 0.6390 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4911\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.7070 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6131 - val_loss: 0.6390 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4939\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.7067 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6152 - val_loss: 0.6389 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4881\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.7065 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6191 - val_loss: 0.6389 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4881\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7062 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6147 - val_loss: 0.6388 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4881\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7059 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6159 - val_loss: 0.6388 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4881\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7057 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6149 - val_loss: 0.6387 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4881\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.7054 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6146 - val_loss: 0.6386 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4881\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7052 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6131 - val_loss: 0.6386 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4917\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7049 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6136 - val_loss: 0.6385 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4917\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.7047 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6108 - val_loss: 0.6385 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4917\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7044 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6144 - val_loss: 0.6384 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4917\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.7042 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6149 - val_loss: 0.6383 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4918\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7039 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6179 - val_loss: 0.6383 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4941\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.7036 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6163 - val_loss: 0.6382 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4941\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7034 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6123 - val_loss: 0.6382 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4941\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7031 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6092 - val_loss: 0.6381 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4918\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7028 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6106 - val_loss: 0.6380 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4918\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7026 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6142 - val_loss: 0.6380 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4918\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7023 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6147 - val_loss: 0.6379 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4918\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.7021 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6162 - val_loss: 0.6379 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4918\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.7018 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6151 - val_loss: 0.6378 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4918\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.7015 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6129 - val_loss: 0.6377 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4892\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.7012 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6137 - val_loss: 0.6377 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4923\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7010 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6166 - val_loss: 0.6376 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4871\n",
            "Epoch 126/500\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6203 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 76.0000 - fn: 24.0000 - accuracy: 0.7600 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6046Restoring model weights from the end of the best epoch: 76.\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.7007 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 118.0000 - fn: 47.0000 - accuracy: 0.7152 - recall: 0.0000e+00 - precision: 0.0000e+00 - prc: 0.6135 - val_loss: 0.6376 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 15.0000 - val_accuracy: 0.6429 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_prc: 0.4853\n",
            "Epoch 126: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efbac42dc90>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualise the loss and accuracy for each epoch"
      ],
      "metadata": {
        "id": "G9DPmZDDXEnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(my_model.best_model.history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "84wnXBf0XDyz",
        "outputId": "82d2aaec-c231-400f-83e4-c74f137d93b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "#print(my_model.best_model.history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(my_model.best_model.history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c_bC8ZieW5fQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a7d6964a-a463-4d59-e33b-eb16d35d8311"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "kwOiqNee7goj"
      },
      "outputs": [],
      "source": [
        "# use your model to make a prediction on unseen data\n",
        "y_pred = my_model.best_model.predict(x_test_processed,batch_size=my_model.BATCH)\n",
        "#convert values\n",
        "y_pred = (y_pred>my_model.THR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VGgleoej7gok",
        "outputId": "b389d585-e51b-4a1d-a4c3-1b8d16ef3b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 62.86 %\n",
            "Weighted ROC AUC accuracy: 62.95 %\n",
            "Confusion matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Asssess the accuracy of your model and explain your key findings\n",
        "# Generate confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "score = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {:.2f} %\".format(score*100))\n",
        "print(\"Weighted ROC AUC accuracy: {:.2f} %\".format(roc_auc_score(y_test, y_pred, average='weighted')*100))\n",
        "print(\"Confusion matrix:\")\n",
        "disp = ConfusionMatrixDisplay(cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Apply k-fold Cross Validation\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# from numpy import ravel\n",
        "# accuracies = cross_val_score(estimator = classifier, X = x_train_processed, y = ravel(y_train.values), scoring = 'roc_auc_ovo', cv = 10)\n",
        "# print(\"K-fold cross validation results\")\n",
        "# print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "# print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model is approx 65-70% accurate at predicting whether cancer recurrence will occur.**\n",
        "\n",
        "**Crucially, the proportion of False Negatives is low (<15%). In cancer diagnosis these are the outcomes that we want to minimise. False Positives, whilst undesirable, will likely lead to further diagnostic testing before it is realised that cancer is not present.**"
      ],
      "metadata": {
        "id": "UMNN4P_E07L6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDU85k7J7gok"
      },
      "source": [
        "### Unit tests:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq2QRpri7gol"
      },
      "source": [
        "###Checking training and test data for null values. This will work for both pd dataframes and np arrays, and ensures no null values exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "oUeh38w_7gol"
      },
      "outputs": [],
      "source": [
        "def test_no_nulls(data):\n",
        "    \"\"\" Assert no null values within pd dataframe or np array \"\"\"\n",
        "    \n",
        "    # if data is numpy array, handle accordingly\n",
        "    if isinstance(data, (np.ndarray)):\n",
        "        assert not np.isnan(np.min(data))\n",
        "    \n",
        "    # if not np array, assume data is pandas dataframe\n",
        "    else:\n",
        "        assert data.isna().sum().sum() == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BV9Z1F3i7gom"
      },
      "outputs": [],
      "source": [
        "# run null data unit test on both training and test data\n",
        "test_no_nulls(x_train_processed)\n",
        "test_no_nulls(x_test_processed)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of KSVC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}