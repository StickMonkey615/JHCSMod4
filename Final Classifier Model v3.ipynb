{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StickMonkey615/JHCSMod4/blob/main/Final%20Classifier%20Model%20v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRn73TIW7gn9"
      },
      "source": [
        "# Module 4 Guidance\n",
        "\n",
        "This notebook is a template for module 4b and 4c, which will be tested in Google Colab, your code needs to run there.\n",
        "The structure has been provided to improve consistency and make it easier for markers to understand your code but still give students the flexibility to be creative.  You need to populate the required functions to solve this problem.  All dependencies should be documented in the next cell.\n",
        "\n",
        "You can:\n",
        "    add further cells or text blocks to extend or further explain your solution\n",
        "    add further functions\n",
        "\n",
        "Dont:\n",
        "    rename functions\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxOsuHxz7goC",
        "outputId": "0c72a009-27ab-4b18-f8be-49d31ed2b6ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 7.8 MB/s \n",
            "\u001b[?25h  Downloading imbalanced_learn-0.9.0-py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 42.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.8.1\n",
            "    Uninstalling imbalanced-learn-0.8.1:\n",
            "      Successfully uninstalled imbalanced-learn-0.8.1\n",
            "Successfully installed imbalanced-learn-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# Fixed dependencies - do not remove or change.\n",
        "import pytest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/gdrive/')\n",
        "# Import your dependencies\n",
        "!pip install --upgrade xlrd > 1.2.0\n",
        "!pip install imbalanced-learn\n",
        "!pip install --upgrade imbalanced-learn\n",
        "import xlrd\n",
        "import imblearn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1m_gmKQP7goE"
      },
      "outputs": [],
      "source": [
        "# Import data\n",
        "\n",
        "def import_local_data(file_path):\n",
        "    \"\"\"This function needs to import the data file into collab and return a pandas dataframe\n",
        "    \"\"\"\n",
        "    raw_df = pd.read_excel(file_path)\n",
        "    return raw_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cIljHljB7goF"
      },
      "outputs": [],
      "source": [
        "local_file_path = \"breast-cancer.xls\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LCu51H5Z7goF"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "raw_data = import_local_data(local_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9WDYKUP7goG"
      },
      "source": [
        "### Conduct exploratory data analysis and explain your key findings - Examine the data, explain its key features and what they look like.  Highlight any fields that are anomalous."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the different dataframe column headings\n",
        "print(raw_data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkjdfYHGiz7a",
        "outputId": "4a2584f0-8cc0-4aef-9531-11afff31a2e1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig',\n",
            "       'breast', 'breast-quad', 'irradiat', 'Class'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine data types for each column\n",
        "for i in range(0, len(raw_data.columns)):\n",
        "    print(type(raw_data.values[1][i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKqjAI-XigbI",
        "outputId": "273ecd37-0766-4833-9187-93c52066cfc0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'int'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Look at the range of values for each field\n",
        "from collections import Counter\n",
        "rng_vals=[]\n",
        "for i in range(0,len(raw_data.columns)):\n",
        "    rng_vals.append(Counter(raw_data.iloc[:,i].values))\n",
        "    print(f\"{raw_data.columns[i]}: {rng_vals[i]}\")\n",
        "del rng_vals, i"
      ],
      "metadata": {
        "id": "-lQUCdTe36Dp",
        "outputId": "6e9fa224-04c6-4283-a5a0-6fdec4d3647a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age: Counter({'50-59': 96, '40-49': 90, '60-69': 57, '30-39': 36, '70-79': 6, '20-29': 1})\n",
            "menopause: Counter({'premeno': 150, 'ge40': 129, 'lt40': 7})\n",
            "tumor-size: Counter({'30-34': 60, '25-29': 54, '20-24': 50, '15-19': 30, datetime.datetime(2014, 10, 1, 0, 0): 28, '40-44': 22, '35-39': 19, '0-4': 8, '50-54': 8, datetime.datetime(2019, 9, 5, 0, 0): 4, '45-49': 3})\n",
            "inv-nodes: Counter({'0-2': 213, datetime.datetime(2019, 5, 3, 0, 0): 36, datetime.datetime(2019, 8, 6, 0, 0): 17, datetime.datetime(2019, 11, 9, 0, 0): 10, '15-17': 6, datetime.datetime(2014, 12, 1, 0, 0): 3, '24-26': 1})\n",
            "node-caps: Counter({'no': 222, 'yes': 56, '?': 8})\n",
            "deg-malig: Counter({2: 130, 3: 85, 1: 71})\n",
            "breast: Counter({'left': 152, 'right': 134})\n",
            "breast-quad: Counter({'left_low': 110, 'left_up': 97, 'right_up': 33, 'right_low': 24, 'central': 21, '?': 1})\n",
            "irradiat: Counter({'no': 218, 'yes': 68})\n",
            "Class: Counter({'no-recurrence-events': 201, 'recurrence-events': 85})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All fields look to contain data that is catagorical in nature.**\n",
        "\n",
        "**Some contain data that appears erroneous:**\n",
        " \n",
        "*   **'tumor-size' and 'inv-nodes' appear to contain some data in a datetime format and some in string.**\n",
        "*   **'node-caps' and 'breast-quad' contain Question Marks.**\n",
        "\n",
        "**Need a way to address these erroneous data inputs.**\n",
        "\n"
      ],
      "metadata": {
        "id": "lALFUx2EEQF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look in more detail at the columns with datetime data.\n",
        "print(raw_data.iloc[:, 2].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IetVwnCr3XI",
        "outputId": "72765074-e7b7-4180-f6a1-6fb56613df0d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['15-19' '15-19' '35-39' '35-39' '30-34' '25-29' '40-44'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '0-4' '40-44' '25-29' '15-19'\n",
            " '30-34' '25-29' '25-29' '20-24' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '15-19' '40-44' '20-24' '20-24' '40-44' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '15-19' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '30-34' '15-19' '30-34' '25-29' '25-29' '20-24' '30-34' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '45-49' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '35-39' '25-29' '20-24'\n",
            " '15-19' '30-34' datetime.datetime(2014, 10, 1, 0, 0) '35-39' '50-54'\n",
            " '40-44' '15-19' '30-34' '0-4' '40-44' '25-29' '25-29' '20-24' '35-39'\n",
            " '50-54' '0-4' '40-44' '30-34' '20-24' '30-34' '20-24' '15-19' '25-29'\n",
            " '15-19' '50-54' datetime.datetime(2014, 10, 1, 0, 0) '25-29' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '15-19' '25-29' '25-29' '30-34'\n",
            " '15-19' '25-29' '30-34' '15-19' '0-4' '35-39' '40-44' '25-29' '20-24'\n",
            " '30-34' '20-24' '30-34' '20-24' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '20-24' '45-49' '40-44' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " '35-39' '20-24' '15-19' '30-34' '20-24' '20-24' '30-34' '20-24' '25-29'\n",
            " '30-34' '20-24' '15-19' '30-34' '30-34' '40-44'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) datetime.datetime(2014, 10, 1, 0, 0)\n",
            " '30-34' datetime.datetime(2014, 10, 1, 0, 0) '35-39' '20-24' '30-34'\n",
            " '25-29' '15-19' '35-39' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " '30-34' '25-29' '15-19' '15-19' '30-34' '35-39' '30-34' '25-29' '30-34'\n",
            " '15-19' '0-4' '0-4' '50-54' '30-34' '20-24' '25-29' '30-34' '20-24'\n",
            " '15-19' datetime.datetime(2014, 10, 1, 0, 0) '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '40-44' '30-34' '50-54' '15-19'\n",
            " '40-44' '25-29' datetime.datetime(2014, 10, 1, 0, 0)\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '25-29' '25-29' '30-34' '50-54'\n",
            " '30-34' '20-24' '30-34' '25-29' '20-24' '20-24' '50-54' '20-24' '30-34'\n",
            " '25-29' '25-29' '40-44' '20-24' '20-24' '25-29' '25-29' '20-24' '40-44'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '30-34'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) '15-19' '30-34' '25-29'\n",
            " datetime.datetime(2019, 9, 5, 0, 0) '25-29' '25-29'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '35-39' '50-54' '25-29' '20-24'\n",
            " '30-34' '30-34' '15-19' '20-24' datetime.datetime(2019, 9, 5, 0, 0)\n",
            " '30-34' '30-34' '25-29' '25-29' '40-44' '25-29' '30-34' '30-34' '25-29'\n",
            " '25-29' '40-44' '20-24' '25-29' '20-24' '40-44' '25-29' '25-29' '45-49'\n",
            " '20-24' '25-29' '20-24' '20-24' '35-39' '20-24' '30-34' '25-29' '30-34'\n",
            " '25-29' '20-24' '20-24' datetime.datetime(2014, 10, 1, 0, 0) '15-19'\n",
            " '25-29' '20-24' '40-44' '15-19' '30-34' '30-34' '40-44' '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '40-44' '30-34' '30-34' '15-19'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '20-24'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '25-29' '30-34'\n",
            " datetime.datetime(2014, 10, 1, 0, 0) '30-34' '0-4' '25-29' '25-29'\n",
            " '40-44' '25-29' '30-34' '20-24' '20-24' '25-29' '30-34' '20-24' '30-34'\n",
            " '0-4' '20-24' '35-39' '30-34' '20-24' '25-29' '35-39' '20-24' '20-24'\n",
            " '35-39' '35-39' '25-29' '35-39' '30-34' '20-24' '15-19' '30-34' '25-29'\n",
            " '30-34' '15-19' '40-44']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at output data\n",
        "#print(raw_data.iloc[:, -1].values)\n",
        "raw_data['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HePUlhNvfWF",
        "outputId": "b2933aa9-1747-4b22-e4a1-36e4bc7efe93"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no-recurrence-events    201\n",
              "recurrence-events        85\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only 2 possible outputs, thus needs converting to binary format for use in classifier models."
      ],
      "metadata": {
        "id": "bkV5bQKKwYHj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KMB3eKfC7goU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1133797d-a7ee-499b-b059-8319a691227f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True outputs: 29.72 %\n"
          ]
        }
      ],
      "source": [
        "# Check output balance\n",
        "out = raw_data.iloc[:, -1].values\n",
        "no_rows = len(raw_data)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "code_rows = le.fit_transform(out)\n",
        "print(\"True outputs: {:.2f} %\".format(sum(code_rows)/no_rows*100))\n",
        "del out, no_rows, le, code_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clear imbalance between output data. Some degree of bias/weighting/sampling will be required to ensure that results accurately predict outcomes for both True and False outcomes."
      ],
      "metadata": {
        "id": "mMo9-0hTwirc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f02MTYgB7goW"
      },
      "outputs": [],
      "source": [
        "# Explain your key findings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data set is made up of 9 independent variables all of which appear catagorical in nature. Although stored as an integer, 'deg-malig' can be viewed as  catagorical data as it can only contain 3 discrete values.**\n",
        "\n",
        "**The inclusion of datetime data entries in both the 'tumor-size' and 'inv-nodes' fields appears to be caused by a formatting entry within Excel. For example, '10-14' being input erroneously as 10/14 thus Excel has interpreted (and converted) it to the datetime field 01/10/2014. A function will need to be written within the model to convert these back to correct format.**\n",
        "\n",
        "**How to deal with '?' entries in fields that are otherwise boolean poses an interesting dilemma. If these are infact meant to signify that the presence is unknown because no diagnostic work has been conducted, then this woiuld signify a valid data entry. If it is however just an incomplete data entry then there is a risk its inclusion could skew the model results. Without knowing which it seems wisest to remove this data from the dataset. Removal of the entire field could well deprive the model of important information, thus just removing these specific entries (rows) appears the most sensible option, particularly noting that there are relatively few occurences.**\n",
        "\n",
        "**Data set is imbalanced, with dependent variable outputs only True in 30% of instances. The model applied will require this imbalance to be taken into account so as not to sacrifice results predicting this smaller class (surely the aim of cancer diagnosis) so as to achieve a high accuracy figure.**\n",
        "\n",
        "**Output variable will need converting into binary output for use with a binary classification model.**"
      ],
      "metadata": {
        "id": "V7OWyLcOrgWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OK28_iB2wDzX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzZj8I8G7goX"
      },
      "source": [
        "Create any data pre-processing that you will conduct on seen and unseen data.  Regardless of the model you use, this dataframe must contain only numeric features and have a strategy for any expected missing values. Any objects can that are needed to handle the test data that are dependent on the training data can be stored in the model class.  You are recommended to use sklearn Pipelines or similar functionality to ensure reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Xsq2f8747goZ"
      },
      "outputs": [],
      "source": [
        "class Module4_Model:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "\n",
        "    def process_dataframe(self, unproc_data):\n",
        "        \"\"\"\n",
        "        Function to remove any erroneous data and then process all data into a\n",
        "        Pandas Dataframe with all data converted into catagorical date (i.e. \n",
        "        encoded) and dummy variables dropped.\n",
        "        \"\"\"\n",
        "        # Deal with ? entries (remove them)\n",
        "        indx = unproc_data[unproc_data.isin(['?'])].stack(dropna=True).unstack().index\n",
        "        print(f\"indx: {indx}\")\n",
        "        unproc_data = unproc_data.drop(index=indx)\n",
        "\n",
        "        # Remove non-categorical data\n",
        "        dm = unproc_data.pop('deg-malig')\n",
        "\n",
        "        # Encode the catagorical data (dummy variables)\n",
        "        proc_data = pd.get_dummies(data=unproc_data, prefix_sep='_', drop_first=True)\n",
        "    \n",
        "        # Add back in non-categorical data\n",
        "        proc_data.insert(0, 'deg-malig', dm)\n",
        "    \n",
        "        return proc_data\n",
        "    \n",
        "    def reformat_dates(self, data):\n",
        "        \"\"\" \n",
        "        Function to reformat datetime data entries in 'tumor-size' and \n",
        "        'inv-nodes' fields back into the string format expected.\n",
        "        \"\"\"\n",
        "        # Correct date types in 'tumor-size' and 'inv-nodes' variables\n",
        "        for i in range(0, len(data)):\n",
        "            if type(data['tumor-size'][i]) is not str:\n",
        "                if data['tumor-size'][i].day == 1:\n",
        "                    data['tumor-size'][i] = str(data['tumor-size'][i].month) +'-' + str(data['tumor-size'][i].year-2000)\n",
        "                else:\n",
        "                    data['tumor-size'][i] = str(data['tumor-size'][i].day) + '-' + str(data['tumor-size'][i].month)\n",
        "            if type(data['inv-nodes'][i]) is not str:\n",
        "                if data['inv-nodes'][i].day == 1:\n",
        "                    data['inv-nodes'][i] = str(data['inv-nodes'][i].month) + '-' + str(data['inv-nodes'][i].year-2000)\n",
        "                else:\n",
        "                    data['inv-nodes'][i] = str(data['inv-nodes'][i].day) + '-' + str(data['inv-nodes'][i].month)\n",
        "        \n",
        "        return data\n",
        "\n",
        "    def preprocess_training_data(self, training_df):\n",
        "        \"\"\"\n",
        "        This function should process the training data and store any features\n",
        "        required in the class\n",
        "        \"\"\"\n",
        "        # Apply feature scaling\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "        sc = StandardScaler()\n",
        "        processed_df = sc.fit_transform(training_df)\n",
        "        return processed_df\n",
        "\n",
        "    def preprocess_test_data(self, test_df):\n",
        "        \"\"\"\n",
        "        This function should process the test data and store any features\n",
        "        required in the class\n",
        "        \"\"\"\n",
        "        # Apply feature scaling\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "        sc = StandardScaler()\n",
        "        processed_df = sc.fit_transform(test_df)\n",
        "        return processed_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "F3LiNNCb7goa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d539c15e-9688-44b3-e102-9257a329c5b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indx: Int64Index([20, 31, 50, 54, 71, 92, 149, 240, 264], dtype='int64')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ],
      "source": [
        "# Dont change\n",
        "my_model = Module4_Model()\n",
        "# reformat date fields into string\n",
        "raw_data_date = my_model.reformat_dates(raw_data)\n",
        "\n",
        "# clean up data and create dataframe of only numerical (catagorical) data\n",
        "clean_data = my_model.process_dataframe(raw_data_date)\n",
        "del raw_data_date, raw_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WIh9_0pp7goY"
      },
      "outputs": [],
      "source": [
        "# Split your data so that you can test the effectiveness of your model\n",
        "# Split the data into a Training set and a Test set\n",
        "dfs = np.split(clean_data, [len(clean_data.columns)-1], axis=1)\n",
        "X = dfs[0]\n",
        "y = dfs[1]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size = 0.25,\n",
        "                                                    random_state = 42)\n",
        "del dfs, X, y, clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZQD7WPdN7god"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "x_train_processed = my_model.preprocess_training_data(X_train)\n",
        "del X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AbOQACY77goY"
      },
      "outputs": [],
      "source": [
        "# Populate preprocess_training_data and preprocess_test_data to preprocess data.\n",
        "# You must process test and train separately so your model does not accidently\n",
        "# gain information that a model wouldnt have in reality and therefore get better predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rQwUj4lk7goe"
      },
      "outputs": [],
      "source": [
        "# Dont change\n",
        "x_test_processed = my_model.preprocess_test_data(X_test)\n",
        "del X_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply dimensionality reduction\n",
        "from sklearn.decomposition import KernelPCA\n",
        "kpca = KernelPCA(n_components = 8, kernel = 'rbf')\n",
        "x_train_processed = kpca.fit_transform(x_train_processed)\n",
        "x_test_processed = kpca.transform(x_test_processed)"
      ],
      "metadata": {
        "id": "7o9n5XqHozgi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XnLHgaXS7goe"
      },
      "outputs": [],
      "source": [
        "# Create models for evaluation\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from imblearn.ensemble import EasyEnsembleClassifier, BalancedRandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score,log_loss,recall_score,balanced_accuracy_score\n",
        "from sklearn.metrics import precision_score,f1_score,confusion_matrix, fbeta_score\n",
        "from imblearn.metrics import sensitivity_score, specificity_score, geometric_mean_score\n",
        "\n",
        "models = ['ADA',\n",
        "          'GBC',\n",
        "          'EEC',\n",
        "          'BRF',\n",
        "          'RFC',\n",
        "          'KNN',\n",
        "          'SVC',\n",
        "          'lReg']\n",
        "\n",
        "classifiers = [AdaBoostClassifier(random_state=42),\n",
        "               GradientBoostingClassifier(random_state=42),\n",
        "               EasyEnsembleClassifier(base_estimator=RandomForestClassifier(random_state=42,\n",
        "                                                                            n_estimators=60)),\n",
        "               BalancedRandomForestClassifier(random_state=42),\n",
        "               RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "               KNeighborsClassifier(n_jobs=-1),\n",
        "               SVC(random_state=42, probability=True),\n",
        "               LogisticRegression(solver='newton-cg', multi_class='multinomial')]\n",
        "\n",
        "# n_estimators range limited for EEC and KNN to reduce processing time. Initially\n",
        "# ranges from 10 to 100 (incl.) were run before smaller ranges were selected.\n",
        "params = {models[0]:{'learning_rate':[0.01,0.1,1,10],\n",
        "                     'n_estimators':np.array(range(10,110,10)),\n",
        "                     'algorithm':['SAMME','SAMME.R']},\n",
        "          models[1]:{'learning_rate':[0.01,0.1,1,10],\n",
        "                     'n_estimators':np.array(range(10,110,10)),\n",
        "                     'max_depth':np.array(range(1,11,1))},\n",
        "          models[2]:{'n_estimators':np.array(range(10,60,10)),\n",
        "                     'base_estimator__n_estimators':np.array(range(40,100,10)),\n",
        "                     'base_estimator__criterion':['gini','entropy'],\n",
        "                     'base_estimator__class_weight':['balanced','balanced_subsample']},\n",
        "          models[3]:{'n_estimators':np.array(range(10,110,10)),\n",
        "                     'criterion':['gini','entropy'],\n",
        "                     'class_weight':['balanced','balanced_subsample']},\n",
        "          models[4]:{'n_estimators':np.array(range(10,110,10)),\n",
        "                     'criterion':['gini','entropy'],\n",
        "                     'class_weight':['balanced','balanced_subsample']},\n",
        "          models[5]:{'n_neighbors':np.array(range(10,60,10)),\n",
        "                     'weights':['uniform','distance'],\n",
        "                     'algorithm':['auto','ball_tree'],\n",
        "                     'metric':['chebyshev','minkowski']},\n",
        "          models[6]:{'C':[1,10,60,100,600,1000],\n",
        "                     'tol':[0.005],\n",
        "                     'kernel':['linear','poly','rbf','sigmoid'],\n",
        "                     'class_weight':['balanced']},\n",
        "          models[7]:{'C':[1,10,60,100,600,1000],\n",
        "                     'class_weight':['balanced'],\n",
        "                     'solver':['newton-cg','lbfgs','sag','saga'],\n",
        "                     'tol':[0.0001]}}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a scoring metric to determine which classifier is the most appropriate to use. As false negative results are those that, in a medical context, have the most significantly negative outcomes then this scoring metric will be used to assess minimisation against false negatives."
      ],
      "metadata": {
        "id": "6yFtvk5v5FVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom scoring metric to be used to decide between different\n",
        "# classifiers after grid search.\n",
        "from sklearn.metrics import make_scorer\n",
        "import math\n",
        "def my_scorer(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    score = tn/(tn+fn) #measure between false negative and true negatives\n",
        "    if math.isnan(score):\n",
        "        score = 0.01\n",
        "    return score\n",
        "\n",
        "cust_score = make_scorer(my_scorer,greater_is_better=True)"
      ],
      "metadata": {
        "id": "A-O1nwgnD7ei"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conduct halving grid search across all models\n",
        "y_tested=0\n",
        "test_scores=[]\n",
        "for name, estimator in zip(models,classifiers):\n",
        "    print(name)\n",
        "    clf = HalvingGridSearchCV(estimator=estimator,\n",
        "                            param_grid=params[name],\n",
        "                            factor=2,\n",
        "                            scoring='balanced_accuracy',\n",
        "                            cv=5,\n",
        "                            n_jobs=-1,\n",
        "                            verbose=0)\n",
        "    clf.fit(x_train_processed, np.ravel(y_train.values))\n",
        "    estimates = clf.predict_proba(x_test_processed)\n",
        "    y_tested+=estimates\n",
        "    acc = accuracy_score(y_test, clf.predict(x_test_processed))\n",
        "    rec = recall_score(y_test, clf.predict(x_test_processed))\n",
        "    pre = precision_score(y_test, clf.predict(x_test_processed))\n",
        "    f1s = f1_score(y_test, clf.predict(x_test_processed), average='macro')\n",
        "    cm = confusion_matrix(y_test, clf.predict(x_test_processed))\n",
        "    sel_score = my_scorer(y_test, clf.predict(x_test_processed))    \n",
        "    test_scores.append((name,acc,clf.best_score_,f1s,rec,pre,cm,clf.best_params_,sel_score))\n",
        "    \n",
        "submission = pd.DataFrame(test_scores, columns=['Classifier',\n",
        "                                                'Accuracy',\n",
        "                                                'Trg balanced accuracy score',\n",
        "                                                'F-score test',\n",
        "                                                'Recall',\n",
        "                                                'Precision',\n",
        "                                                'Confusion matrix',\n",
        "                                                'Best params',\n",
        "                                                'Selector'])\n",
        "submission.to_csv(f\"Results.csv\")\n",
        "del acc,clf,estimates,y_tested,rec,pre,f1s,cm,sel_score,test_scores,name,estimator"
      ],
      "metadata": {
        "id": "woCp5wuzhqXH",
        "outputId": "ee395c0e-e284-402e-eae7-4ddad562bcc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ADA\n",
            "Best params: {'algorithm': 'SAMME', 'learning_rate': 1, 'n_estimators': 10}\n",
            "Best score: 0.538551038333647\n",
            "Accuracy: 72.8571%\n",
            "Recall: 26.3158%\n",
            "Precision: 50.0000%\n",
            "F-measure: 58.6828%\n",
            "[[46  5]\n",
            " [14  5]]\n",
            "GBC\n",
            "Best params: {'learning_rate': 1, 'max_depth': 6, 'n_estimators': 20}\n",
            "Best score: 0.6164318652362131\n",
            "Accuracy: 65.7143%\n",
            "Recall: 26.3158%\n",
            "Precision: 33.3333%\n",
            "F-measure: 53.3851%\n",
            "[[41 10]\n",
            " [14  5]]\n",
            "EEC\n",
            "Best params: {'base_estimator__class_weight': 'balanced', 'base_estimator__criterion': 'entropy', 'base_estimator__n_estimators': 40, 'n_estimators': 10}\n",
            "Best score: 0.5819894598155468\n",
            "Accuracy: 57.1429%\n",
            "Recall: 68.4211%\n",
            "Precision: 35.1351%\n",
            "F-measure: 55.3571%\n",
            "[[27 24]\n",
            " [ 6 13]]\n",
            "BRF\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "40 fits failed out of a total of 200.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "40 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/ensemble/_forest.py\", line 566, in fit\n",
            "    for i, (s, t) in enumerate(zip(samplers, trees))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1043, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 779, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/ensemble/_forest.py\", line 57, in _local_parallel_build_trees\n",
            "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/base.py\", line 80, in fit_resample\n",
            "    self.sampling_strategy, y, self._sampling_type\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/utils/_validation.py\", line 501, in check_sampling_strategy\n",
            "    f\"The target 'y' needs to have more than 1 class. \"\n",
            "ValueError: The target 'y' needs to have more than 1 class. Got 1 class instead\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.64095238 0.5397619\n",
            " 0.63166667 0.56738095 0.56738095 0.58761905 0.5647619  0.59333333\n",
            " 0.5647619  0.5647619  0.6302381  0.58738095 0.59595238 0.6552381\n",
            " 0.6302381  0.59952381 0.64952381 0.6352381  0.56595238 0.54595238]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.89873737 0.8854798\n",
            " 0.91607744 0.90374579 0.91199495 0.91738215 0.91321549 0.90698653\n",
            " 0.91153199 0.90698653 0.89258021 0.88880471 0.91069024 0.89132997\n",
            " 0.90782828 0.90867003 0.91321549 0.90698653 0.89040404 0.89541246]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.64095238 0.5397619\n",
            " 0.63166667 0.56738095 0.56738095 0.58761905 0.5647619  0.59333333\n",
            " 0.5647619  0.5647619  0.6302381  0.58738095 0.59595238 0.6552381\n",
            " 0.6302381  0.59952381 0.64952381 0.6352381  0.56595238 0.54595238\n",
            " 0.50198135 0.56107226 0.50198135 0.56054779 0.56928904 0.5284965\n",
            " 0.51107226 0.58607226 0.54440559 0.51182984]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.89873737 0.8854798\n",
            " 0.91607744 0.90374579 0.91199495 0.91738215 0.91321549 0.90698653\n",
            " 0.91153199 0.90698653 0.89258021 0.88880471 0.91069024 0.89132997\n",
            " 0.90782828 0.90867003 0.91321549 0.90698653 0.89040404 0.89541246\n",
            " 0.92960988 0.92519677 0.92069963 0.93446656 0.91579025 0.92760446\n",
            " 0.93198143 0.92736849 0.92060081 0.92468353]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.64095238 0.5397619\n",
            " 0.63166667 0.56738095 0.56738095 0.58761905 0.5647619  0.59333333\n",
            " 0.5647619  0.5647619  0.6302381  0.58738095 0.59595238 0.6552381\n",
            " 0.6302381  0.59952381 0.64952381 0.6352381  0.56595238 0.54595238\n",
            " 0.50198135 0.56107226 0.50198135 0.56054779 0.56928904 0.5284965\n",
            " 0.51107226 0.58607226 0.54440559 0.51182984 0.57834431 0.5955405\n",
            " 0.58967187 0.59130686 0.62009034]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.89873737 0.8854798\n",
            " 0.91607744 0.90374579 0.91199495 0.91738215 0.91321549 0.90698653\n",
            " 0.91153199 0.90698653 0.89258021 0.88880471 0.91069024 0.89132997\n",
            " 0.90782828 0.90867003 0.91321549 0.90698653 0.89040404 0.89541246\n",
            " 0.92960988 0.92519677 0.92069963 0.93446656 0.91579025 0.92760446\n",
            " 0.93198143 0.92736849 0.92060081 0.92468353 0.90013453 0.89153902\n",
            " 0.89818421 0.90685838 0.90575372]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params: {'class_weight': 'balanced', 'criterion': 'entropy', 'n_estimators': 90}\n",
            "Best score: 0.6200903444381705\n",
            "Accuracy: 58.5714%\n",
            "Recall: 84.2105%\n",
            "Precision: 38.0952%\n",
            "F-measure: 57.8751%\n",
            "[[25 26]\n",
            " [ 3 16]]\n",
            "RFC\n",
            "Best params: {'class_weight': 'balanced', 'criterion': 'entropy', 'n_estimators': 70}\n",
            "Best score: 0.553471359558316\n",
            "Accuracy: 65.7143%\n",
            "Recall: 26.3158%\n",
            "Precision: 33.3333%\n",
            "F-measure: 53.3851%\n",
            "[[41 10]\n",
            " [14  5]]\n",
            "KNN\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.5        0.41666667        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.51666667 0.56666667\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.5        0.41666667        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.51666667 0.56666667        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [0.51702381 1.                nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.50702381 1.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.51702381 1.                nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.50702381 1.                nan        nan        nan        nan\n",
            "        nan        nan        nan        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.5        0.41666667        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.51666667 0.56666667\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.5        0.41666667        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.51666667 0.56666667        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.58333333 0.53809524 0.6        0.58333333\n",
            "        nan        nan        nan        nan 0.56666667 0.56666667\n",
            " 0.6        0.58333333        nan        nan        nan        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [0.51702381 1.                nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.50702381 1.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.51702381 1.                nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.50702381 1.                nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.48663968 1.         0.5        1.\n",
            "        nan        nan        nan        nan 0.49635628 0.98888889\n",
            " 0.5        0.98888889        nan        nan        nan        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.5        0.41666667        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.51666667 0.56666667\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.5        0.41666667        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.51666667 0.56666667        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.58333333 0.53809524 0.6        0.58333333\n",
            "        nan        nan        nan        nan 0.56666667 0.56666667\n",
            " 0.6        0.58333333        nan        nan        nan        nan\n",
            " 0.5        0.51166667 0.5        0.51166667 0.5        0.5\n",
            " 0.51166667 0.51166667 0.5        0.51166667]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [0.51702381 1.                nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.50702381 1.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.51702381 1.                nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.50702381 1.                nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.48663968 1.         0.5        1.\n",
            "        nan        nan        nan        nan 0.49635628 0.98888889\n",
            " 0.5        0.98888889        nan        nan        nan        nan\n",
            " 0.5        1.         0.5        1.         0.5        0.5\n",
            " 0.97947368 1.         0.5        1.        ]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.5        0.41666667        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.51666667 0.56666667\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.5        0.41666667        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.51666667 0.56666667        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.58333333 0.53809524 0.6        0.58333333\n",
            "        nan        nan        nan        nan 0.56666667 0.56666667\n",
            " 0.6        0.58333333        nan        nan        nan        nan\n",
            " 0.5        0.51166667 0.5        0.51166667 0.5        0.5\n",
            " 0.51166667 0.51166667 0.5        0.51166667 0.51458874 0.52411255\n",
            " 0.49549784 0.52411255 0.49549784]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [0.51702381 1.                nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.50702381 1.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.51702381 1.                nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.50702381 1.                nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.48663968 1.         0.5        1.\n",
            "        nan        nan        nan        nan 0.49635628 0.98888889\n",
            " 0.5        0.98888889        nan        nan        nan        nan\n",
            " 0.5        1.         0.5        1.         0.5        0.5\n",
            " 0.97947368 1.         0.5        1.         1.         1.\n",
            " 1.         1.         1.        ]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params: {'algorithm': 'auto', 'metric': 'chebyshev', 'n_neighbors': 50, 'weights': 'distance'}\n",
            "Best score: 0.5241125541125541\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 72.8571%\n",
            "Recall: 0.0000%\n",
            "Precision: 0.0000%\n",
            "F-measure: 42.1488%\n",
            "[[51  0]\n",
            " [19  0]]\n",
            "SVC\n",
            "Best params: {'C': 1, 'class_weight': 'balanced', 'kernel': 'poly', 'tol': 0.005}\n",
            "Best score: 0.6077214379823076\n",
            "Accuracy: 42.8571%\n",
            "Recall: 84.2105%\n",
            "Precision: 30.1887%\n",
            "F-measure: 42.8105%\n",
            "[[14 37]\n",
            " [ 3 16]]\n",
            "lReg\n",
            "Best params: {'C': 600, 'class_weight': 'balanced', 'solver': 'saga', 'tol': 0.0001}\n",
            "Best score: 0.6360336282075412\n",
            "Accuracy: 68.5714%\n",
            "Recall: 89.4737%\n",
            "Precision: 45.9459%\n",
            "F-measure: 67.2619%\n",
            "[[31 20]\n",
            " [ 2 17]]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_f5dad728-22b1-49b4-805c-e6188f4bdf86\", \"Results_0.csv\", 1989)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ADA\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.208      0.208      0.208      0.208      0.208      0.208\n",
            " 0.208      0.208      0.208      0.208             nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan 0.81666667 0.81666667 0.81666667 0.81666667 0.88333333\n",
            " 0.88333333 0.88333333 0.88333333 0.88333333 0.88333333 0.88333333\n",
            " 0.81666667 0.83333333 0.86666667 0.93333333 0.93333333 0.93333333\n",
            " 0.93333333 0.93333333 0.93333333 0.93333333 0.78333333 0.78333333\n",
            " 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333\n",
            " 0.78333333 0.78333333]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.208      0.208      0.208      0.208      0.208      0.208\n",
            " 0.208      0.208      0.208      0.208             nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan 0.81666667 0.81666667 0.81666667 0.81666667 0.88333333\n",
            " 0.88333333 0.88333333 0.88333333 0.88333333 0.88333333 0.88333333\n",
            " 0.81666667 0.83333333 0.86666667 0.93333333 0.93333333 0.93333333\n",
            " 0.93333333 0.93333333 0.93333333 0.93333333 0.78333333 0.78333333\n",
            " 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333\n",
            " 0.78333333 0.78333333 0.85238095        nan        nan        nan\n",
            "        nan        nan 0.84928571        nan        nan 0.86428571\n",
            " 0.83928571 0.88452381 0.88571429 0.87428571 0.85714286 0.84761905\n",
            " 0.90285714 0.90285714 0.90285714        nan 0.89285714 0.89285714\n",
            " 0.8547619         nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.86428571 0.86428571\n",
            " 0.86428571 0.86428571 0.86428571 0.83928571 0.89285714 0.84928571]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.208      0.208      0.208      0.208      0.208      0.208\n",
            " 0.208      0.208      0.208      0.208             nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan 0.81666667 0.81666667 0.81666667 0.81666667 0.88333333\n",
            " 0.88333333 0.88333333 0.88333333 0.88333333 0.88333333 0.88333333\n",
            " 0.81666667 0.83333333 0.86666667 0.93333333 0.93333333 0.93333333\n",
            " 0.93333333 0.93333333 0.93333333 0.93333333 0.78333333 0.78333333\n",
            " 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333\n",
            " 0.78333333 0.78333333 0.85238095        nan        nan        nan\n",
            "        nan        nan 0.84928571        nan        nan 0.86428571\n",
            " 0.83928571 0.88452381 0.88571429 0.87428571 0.85714286 0.84761905\n",
            " 0.90285714 0.90285714 0.90285714        nan 0.89285714 0.89285714\n",
            " 0.8547619         nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.86428571 0.86428571\n",
            " 0.86428571 0.86428571 0.86428571 0.83928571 0.89285714 0.84928571\n",
            " 0.73441558 0.73060606 0.74774892 0.72666667 0.755      0.755\n",
            " 0.78833333 0.72060606 0.755      0.73333333 0.73333333 0.73333333\n",
            " 0.72512821 0.755      0.75884615 0.755      0.755      0.755\n",
            " 0.72666667 0.74393939]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.208      0.208      0.208      0.208      0.208      0.208\n",
            " 0.208      0.208      0.208      0.208             nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan 0.81666667 0.81666667 0.81666667 0.81666667 0.88333333\n",
            " 0.88333333 0.88333333 0.88333333 0.88333333 0.88333333 0.88333333\n",
            " 0.81666667 0.83333333 0.86666667 0.93333333 0.93333333 0.93333333\n",
            " 0.93333333 0.93333333 0.93333333 0.93333333 0.78333333 0.78333333\n",
            " 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333 0.78333333\n",
            " 0.78333333 0.78333333 0.85238095        nan        nan        nan\n",
            "        nan        nan 0.84928571        nan        nan 0.86428571\n",
            " 0.83928571 0.88452381 0.88571429 0.87428571 0.85714286 0.84761905\n",
            " 0.90285714 0.90285714 0.90285714        nan 0.89285714 0.89285714\n",
            " 0.8547619         nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.86428571 0.86428571\n",
            " 0.86428571 0.86428571 0.86428571 0.83928571 0.89285714 0.84928571\n",
            " 0.73441558 0.73060606 0.74774892 0.72666667 0.755      0.755\n",
            " 0.78833333 0.72060606 0.755      0.73333333 0.73333333 0.73333333\n",
            " 0.72512821 0.755      0.75884615 0.755      0.755      0.755\n",
            " 0.72666667 0.74393939 0.72456167 0.72028959 0.72028959 0.70040323\n",
            " 0.70040323 0.70040323 0.72028959 0.70040323 0.72028959 0.72908724]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params: {'algorithm': 'SAMME.R', 'learning_rate': 0.01, 'n_estimators': 10}\n",
            "Best score: 0.7290872434017596\n",
            "Accuracy: 72.8571%\n",
            "Recall: 0.0000%\n",
            "Precision: 0.0000%\n",
            "F-measure: 42.1488%\n",
            "[[51  0]\n",
            " [19  0]]\n",
            "GBC\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.71666667 0.71666667 0.71666667 0.71666667 0.71666667\n",
            " 0.71666667 0.71666667 0.71666667 0.71666667        nan 0.71666667\n",
            " 0.71666667 0.71666667 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333        nan 0.71666667 0.71666667 0.76666667\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            "        nan 0.71666667 0.71666667 0.76666667 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333        nan 0.71666667\n",
            " 0.71666667 0.76666667 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333        nan 0.71666667 0.71666667 0.76666667\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            "        nan 0.71666667 0.71666667 0.76666667 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333        nan 0.71666667\n",
            " 0.71666667 0.76666667 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333        nan 0.71666667 0.71666667 0.76666667\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            "        nan 0.71666667 0.71666667 0.76666667 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.71666667 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.51866667 0.51866667 0.51866667 0.51866667 0.51866667 0.51866667\n",
            " 0.51866667 0.51866667 0.51866667 0.51866667 0.53533333 0.53533333\n",
            " 0.53533333 0.53533333 0.53533333 0.53533333 0.53533333 0.53533333\n",
            " 0.53533333 0.53533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.71666667 0.71666667 0.71666667 0.71666667 0.71666667\n",
            " 0.71666667 0.71666667 0.71666667 0.71666667        nan 0.71666667\n",
            " 0.71666667 0.71666667 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333        nan 0.71666667 0.71666667 0.76666667\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            "        nan 0.71666667 0.71666667 0.76666667 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333        nan 0.71666667\n",
            " 0.71666667 0.76666667 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333        nan 0.71666667 0.71666667 0.76666667\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            "        nan 0.71666667 0.71666667 0.76666667 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333        nan 0.71666667\n",
            " 0.71666667 0.76666667 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333        nan 0.71666667 0.71666667 0.76666667\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            "        nan 0.71666667 0.71666667 0.76666667 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.71666667 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.51866667 0.51866667 0.51866667 0.51866667 0.51866667 0.51866667\n",
            " 0.51866667 0.51866667 0.51866667 0.51866667 0.53533333 0.53533333\n",
            " 0.53533333 0.53533333 0.53533333 0.53533333 0.53533333 0.53533333\n",
            " 0.53533333 0.53533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.88095238\n",
            " 0.84761905 0.84761905 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.88095238 0.83428571 0.84571429 0.83428571\n",
            " 0.82857143 0.82857143 0.82857143 0.82857143 0.82857143 0.82857143\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.81428571\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.82857143\n",
            " 0.84761905 0.84761905 0.82857143 0.85238095 0.85238095 0.83428571\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.81428571\n",
            " 0.82857143 0.82857143 0.82857143 0.82857143 0.82857143 0.82857143\n",
            " 0.82857143 0.82857143 0.82857143 0.82857143 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.81428571\n",
            " 0.85238095 0.85238095 0.85238095 0.82857143 0.82857143 0.81428571\n",
            " 0.82857143 0.82857143 0.82857143 0.81428571 0.81428571 0.81428571\n",
            " 0.85238095 0.81428571 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.81428571 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.81428571 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.81428571 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.84571429 0.84571429 0.84571429 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.84571429 0.84571429\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.84571429\n",
            " 0.83428571 0.83428571 0.83428571 0.82857143 0.82857143 0.81904762\n",
            " 0.84761905 0.8047619  0.85238095 0.8047619  0.8047619  0.7747619\n",
            " 0.8247619  0.8047619  0.8047619  0.7547619  0.8047619  0.84571429\n",
            " 0.8047619  0.85238095 0.84571429 0.85238095 0.85238095 0.85238095\n",
            " 0.84571429 0.84571429 0.84571429 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.84571429 0.84571429\n",
            " 0.84571429 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.84571429 0.84571429 0.84571429 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.84571429\n",
            " 0.84571429 0.84571429        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.71666667 0.71666667 0.71666667 0.71666667 0.71666667\n",
            " 0.71666667 0.71666667 0.71666667 0.71666667        nan 0.71666667\n",
            " 0.71666667 0.71666667 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333        nan 0.71666667 0.71666667 0.76666667\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            "        nan 0.71666667 0.71666667 0.76666667 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333        nan 0.71666667\n",
            " 0.71666667 0.76666667 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333        nan 0.71666667 0.71666667 0.76666667\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            "        nan 0.71666667 0.71666667 0.76666667 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333        nan 0.71666667\n",
            " 0.71666667 0.76666667 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333        nan 0.71666667 0.71666667 0.76666667\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            "        nan 0.71666667 0.71666667 0.76666667 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.71666667 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.51866667 0.51866667 0.51866667 0.51866667 0.51866667 0.51866667\n",
            " 0.51866667 0.51866667 0.51866667 0.51866667 0.53533333 0.53533333\n",
            " 0.53533333 0.53533333 0.53533333 0.53533333 0.53533333 0.53533333\n",
            " 0.53533333 0.53533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.88095238\n",
            " 0.84761905 0.84761905 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.88095238 0.83428571 0.84571429 0.83428571\n",
            " 0.82857143 0.82857143 0.82857143 0.82857143 0.82857143 0.82857143\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.81428571\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.82857143\n",
            " 0.84761905 0.84761905 0.82857143 0.85238095 0.85238095 0.83428571\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.81428571\n",
            " 0.82857143 0.82857143 0.82857143 0.82857143 0.82857143 0.82857143\n",
            " 0.82857143 0.82857143 0.82857143 0.82857143 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.81428571\n",
            " 0.85238095 0.85238095 0.85238095 0.82857143 0.82857143 0.81428571\n",
            " 0.82857143 0.82857143 0.82857143 0.81428571 0.81428571 0.81428571\n",
            " 0.85238095 0.81428571 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.81428571 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.81428571 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.81428571 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.84571429 0.84571429 0.84571429 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.84571429 0.84571429\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.84571429\n",
            " 0.83428571 0.83428571 0.83428571 0.82857143 0.82857143 0.81904762\n",
            " 0.84761905 0.8047619  0.85238095 0.8047619  0.8047619  0.7747619\n",
            " 0.8247619  0.8047619  0.8047619  0.7547619  0.8047619  0.84571429\n",
            " 0.8047619  0.85238095 0.84571429 0.85238095 0.85238095 0.85238095\n",
            " 0.84571429 0.84571429 0.84571429 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.84571429 0.84571429\n",
            " 0.84571429 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.84571429 0.84571429 0.84571429 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.84571429\n",
            " 0.84571429 0.84571429        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.753663   0.77032967 0.70491841 0.70363636 0.70363636 0.71904762\n",
            " 0.69672439 0.73133977 0.70315795 0.68857143 0.70238095 0.70238095\n",
            " 0.6868254  0.6868254  0.69672439 0.72588523 0.678663   0.71318681\n",
            " 0.7168254  0.71318681 0.66238095 0.66238095 0.66238095 0.66238095\n",
            " 0.74434343 0.74434343 0.66238095 0.74434343 0.72823954 0.72823954\n",
            " 0.71318681 0.74434343 0.64571429 0.6552381  0.7479798  0.66926407\n",
            " 0.66238095 0.66238095 0.68550061 0.68550061 0.68550061 0.68550061\n",
            " 0.68550061 0.66994505 0.66238095 0.68285714 0.70050061 0.70050061\n",
            " 0.70050061 0.70050061 0.66238095 0.66238095 0.68285714 0.66926407\n",
            " 0.7219697  0.6625974  0.70604396 0.71318681 0.71318681 0.68857143\n",
            " 0.71318681 0.71318681 0.71318681 0.74032967 0.74434343 0.71961538\n",
            " 0.67460317 0.66926407 0.68005772 0.68450216 0.68450216 0.68450216\n",
            " 0.67460317 0.71934343 0.7110101  0.7110101  0.71934343 0.67460317\n",
            " 0.68450216 0.66238095 0.66238095 0.68450216 0.67460317 0.68005772\n",
            " 0.68005772 0.68450216 0.6552381  0.69015873 0.67857143 0.66071429\n",
            " 0.6725     0.6725     0.6725     0.6725     0.6725     0.6725\n",
            " 0.6725     0.6725     0.6725     0.6725    ]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.71666667 0.71666667 0.71666667 0.71666667 0.71666667\n",
            " 0.71666667 0.71666667 0.71666667 0.71666667        nan 0.71666667\n",
            " 0.71666667 0.71666667 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333        nan 0.71666667 0.71666667 0.76666667\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            "        nan 0.71666667 0.71666667 0.76666667 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333        nan 0.71666667\n",
            " 0.71666667 0.76666667 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333        nan 0.71666667 0.71666667 0.76666667\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            "        nan 0.71666667 0.71666667 0.76666667 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333        nan 0.71666667\n",
            " 0.71666667 0.76666667 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333        nan 0.71666667 0.71666667 0.76666667\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            "        nan 0.71666667 0.71666667 0.76666667 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.71666667 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
            " 0.51866667 0.51866667 0.51866667 0.51866667 0.51866667 0.51866667\n",
            " 0.51866667 0.51866667 0.51866667 0.51866667 0.53533333 0.53533333\n",
            " 0.53533333 0.53533333 0.53533333 0.53533333 0.53533333 0.53533333\n",
            " 0.53533333 0.53533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333 0.63533333\n",
            " 0.63533333 0.63533333 0.63533333 0.63533333 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.88095238\n",
            " 0.84761905 0.84761905 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.88095238 0.83428571 0.84571429 0.83428571\n",
            " 0.82857143 0.82857143 0.82857143 0.82857143 0.82857143 0.82857143\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.81428571\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.82857143\n",
            " 0.84761905 0.84761905 0.82857143 0.85238095 0.85238095 0.83428571\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.81428571\n",
            " 0.82857143 0.82857143 0.82857143 0.82857143 0.82857143 0.82857143\n",
            " 0.82857143 0.82857143 0.82857143 0.82857143 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.81428571\n",
            " 0.85238095 0.85238095 0.85238095 0.82857143 0.82857143 0.81428571\n",
            " 0.82857143 0.82857143 0.82857143 0.81428571 0.81428571 0.81428571\n",
            " 0.85238095 0.81428571 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.81428571 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.81428571 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.81428571 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.84571429 0.84571429 0.84571429 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.84571429 0.84571429\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.84571429\n",
            " 0.83428571 0.83428571 0.83428571 0.82857143 0.82857143 0.81904762\n",
            " 0.84761905 0.8047619  0.85238095 0.8047619  0.8047619  0.7747619\n",
            " 0.8247619  0.8047619  0.8047619  0.7547619  0.8047619  0.84571429\n",
            " 0.8047619  0.85238095 0.84571429 0.85238095 0.85238095 0.85238095\n",
            " 0.84571429 0.84571429 0.84571429 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.84571429 0.84571429\n",
            " 0.84571429 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095\n",
            " 0.84571429 0.84571429 0.84571429 0.85238095 0.85238095 0.85238095\n",
            " 0.85238095 0.85238095 0.85238095 0.85238095 0.85238095 0.84571429\n",
            " 0.84571429 0.84571429        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.753663   0.77032967 0.70491841 0.70363636 0.70363636 0.71904762\n",
            " 0.69672439 0.73133977 0.70315795 0.68857143 0.70238095 0.70238095\n",
            " 0.6868254  0.6868254  0.69672439 0.72588523 0.678663   0.71318681\n",
            " 0.7168254  0.71318681 0.66238095 0.66238095 0.66238095 0.66238095\n",
            " 0.74434343 0.74434343 0.66238095 0.74434343 0.72823954 0.72823954\n",
            " 0.71318681 0.74434343 0.64571429 0.6552381  0.7479798  0.66926407\n",
            " 0.66238095 0.66238095 0.68550061 0.68550061 0.68550061 0.68550061\n",
            " 0.68550061 0.66994505 0.66238095 0.68285714 0.70050061 0.70050061\n",
            " 0.70050061 0.70050061 0.66238095 0.66238095 0.68285714 0.66926407\n",
            " 0.7219697  0.6625974  0.70604396 0.71318681 0.71318681 0.68857143\n",
            " 0.71318681 0.71318681 0.71318681 0.74032967 0.74434343 0.71961538\n",
            " 0.67460317 0.66926407 0.68005772 0.68450216 0.68450216 0.68450216\n",
            " 0.67460317 0.71934343 0.7110101  0.7110101  0.71934343 0.67460317\n",
            " 0.68450216 0.66238095 0.66238095 0.68450216 0.67460317 0.68005772\n",
            " 0.68005772 0.68450216 0.6552381  0.69015873 0.67857143 0.66071429\n",
            " 0.6725     0.6725     0.6725     0.6725     0.6725     0.6725\n",
            " 0.6725     0.6725     0.6725     0.6725     0.68488356 0.69423077\n",
            " 0.69456229 0.69195722 0.69195722 0.69569597 0.69698679 0.70939194\n",
            " 0.70194298 0.68893122 0.69916641 0.69403821 0.69403821 0.69404762\n",
            " 0.6846993  0.68881652 0.6856646  0.69857087 0.69173722 0.7005881\n",
            " 0.70357143 0.68729509 0.69197338 0.71190476 0.6952674  0.70805861\n",
            " 0.7026455  0.69525641 0.71136853 0.70239194 0.69881766 0.68400768\n",
            " 0.69319573 0.69038606 0.69771939 0.69829797 0.71686036 0.70829193\n",
            " 0.71354924 0.71062526 0.70049417 0.7027329  0.70074372 0.70302292\n",
            " 0.69373166 0.70302292 0.6961932  0.70302292 0.68121849 0.68308184]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 20}\n",
            "Best score: 0.7168603634690591\n",
            "Accuracy: 71.4286%\n",
            "Recall: 15.7895%\n",
            "Precision: 42.8571%\n",
            "F-measure: 52.7665%\n",
            "[[47  4]\n",
            " [16  3]]\n",
            "EEC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602   nan 0.702\n",
            " 0.602 0.602 0.602   nan 0.602 0.602 0.602 0.602   nan 0.602 0.602 0.602\n",
            " 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602\n",
            " 0.602 0.602 0.602 0.602 0.602 0.602   nan 0.602 0.602 0.602 0.604 0.602\n",
            " 0.602 0.602   nan 0.602 0.602 0.602 0.602 0.602 0.602 0.702 0.602 0.602\n",
            " 0.604 0.602 0.602 0.602 0.602   nan 0.602 0.604 0.602 0.602 0.604 0.602\n",
            " 0.604 0.602 0.602 0.602 0.602 0.702 0.602 0.602 0.602 0.602 0.702 0.602\n",
            " 0.602 0.602 0.602 0.602 0.602 0.602   nan 0.602   nan 0.602 0.602 0.602\n",
            " 0.602 0.602 0.602 0.602 0.702 0.602 0.602 0.602 0.602 0.702 0.602 0.602\n",
            " 0.602 0.602 0.602   nan 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602   nan 0.702\n",
            " 0.602 0.602 0.602   nan 0.602 0.602 0.602 0.602   nan 0.602 0.602 0.602\n",
            " 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602\n",
            " 0.602 0.602 0.602 0.602 0.602 0.602   nan 0.602 0.602 0.602 0.604 0.602\n",
            " 0.602 0.602   nan 0.602 0.602 0.602 0.602 0.602 0.602 0.702 0.602 0.602\n",
            " 0.604 0.602 0.602 0.602 0.602   nan 0.602 0.604 0.602 0.602 0.604 0.602\n",
            " 0.604 0.602 0.602 0.602 0.602 0.702 0.602 0.602 0.602 0.602 0.702 0.602\n",
            " 0.602 0.602 0.602 0.602 0.602 0.602   nan 0.602   nan 0.602 0.602 0.602\n",
            " 0.602 0.602 0.602 0.602 0.702 0.602 0.602 0.602 0.602 0.702 0.602 0.602\n",
            " 0.602 0.602 0.602   nan 0.602 0.602 0.602 0.602 0.602 0.602 0.602 0.602\n",
            " 0.6   0.6   0.6   0.6   0.62  0.6   0.6   0.6   0.6   0.6   0.6   0.6\n",
            " 0.6   0.62  0.55  0.62  0.62  0.62  0.6   0.6   0.6   0.62  0.6   0.62\n",
            " 0.62  0.62  0.58  0.6   0.62  0.5   0.6   0.6   0.6   0.6   0.62  0.6\n",
            " 0.6   0.6   0.5   0.6   0.5   0.58  0.5   0.6   0.6   0.6   0.6   0.6\n",
            " 0.6   0.62  0.55  0.62  0.6   0.6   0.58  0.5   0.6   0.62  0.6   0.6  ]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.602      0.602      0.602      0.602      0.602      0.602\n",
            " 0.602      0.602      0.602      0.602             nan 0.702\n",
            " 0.602      0.602      0.602             nan 0.602      0.602\n",
            " 0.602      0.602             nan 0.602      0.602      0.602\n",
            " 0.602      0.602      0.602      0.602      0.602      0.602\n",
            " 0.602      0.602      0.602      0.602      0.602      0.602\n",
            " 0.602      0.602      0.602      0.602      0.602      0.602\n",
            "        nan 0.602      0.602      0.602      0.604      0.602\n",
            " 0.602      0.602             nan 0.602      0.602      0.602\n",
            " 0.602      0.602      0.602      0.702      0.602      0.602\n",
            " 0.604      0.602      0.602      0.602      0.602             nan\n",
            " 0.602      0.604      0.602      0.602      0.604      0.602\n",
            " 0.604      0.602      0.602      0.602      0.602      0.702\n",
            " 0.602      0.602      0.602      0.602      0.702      0.602\n",
            " 0.602      0.602      0.602      0.602      0.602      0.602\n",
            "        nan 0.602             nan 0.602      0.602      0.602\n",
            " 0.602      0.602      0.602      0.602      0.702      0.602\n",
            " 0.602      0.602      0.602      0.702      0.602      0.602\n",
            " 0.602      0.602      0.602             nan 0.602      0.602\n",
            " 0.602      0.602      0.602      0.602      0.602      0.602\n",
            " 0.6        0.6        0.6        0.6        0.62       0.6\n",
            " 0.6        0.6        0.6        0.6        0.6        0.6\n",
            " 0.6        0.62       0.55       0.62       0.62       0.62\n",
            " 0.6        0.6        0.6        0.62       0.6        0.62\n",
            " 0.62       0.62       0.58       0.6        0.62       0.5\n",
            " 0.6        0.6        0.6        0.6        0.62       0.6\n",
            " 0.6        0.6        0.5        0.6        0.5        0.58\n",
            " 0.5        0.6        0.6        0.6        0.6        0.6\n",
            " 0.6        0.62       0.55       0.62       0.6        0.6\n",
            " 0.58       0.5        0.6        0.62       0.6        0.6\n",
            " 0.75386724 0.7610101  0.76111111 0.75555556 0.75555556 0.75555556\n",
            " 0.7484127  0.75386724 0.75555556 0.7610101  0.75386724 0.75386724\n",
            " 0.74545455 0.77767677 0.78253968 0.77767677 0.75555556 0.73831169\n",
            " 0.7484127  0.74545455 0.78243867 0.75555556 0.75555556 0.7484127\n",
            " 0.75555556 0.75555556 0.7484127  0.7610101  0.77388889 0.77767677]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.602      0.602      0.602      0.602      0.602      0.602\n",
            " 0.602      0.602      0.602      0.602             nan 0.702\n",
            " 0.602      0.602      0.602             nan 0.602      0.602\n",
            " 0.602      0.602             nan 0.602      0.602      0.602\n",
            " 0.602      0.602      0.602      0.602      0.602      0.602\n",
            " 0.602      0.602      0.602      0.602      0.602      0.602\n",
            " 0.602      0.602      0.602      0.602      0.602      0.602\n",
            "        nan 0.602      0.602      0.602      0.604      0.602\n",
            " 0.602      0.602             nan 0.602      0.602      0.602\n",
            " 0.602      0.602      0.602      0.702      0.602      0.602\n",
            " 0.604      0.602      0.602      0.602      0.602             nan\n",
            " 0.602      0.604      0.602      0.602      0.604      0.602\n",
            " 0.604      0.602      0.602      0.602      0.602      0.702\n",
            " 0.602      0.602      0.602      0.602      0.702      0.602\n",
            " 0.602      0.602      0.602      0.602      0.602      0.602\n",
            "        nan 0.602             nan 0.602      0.602      0.602\n",
            " 0.602      0.602      0.602      0.602      0.702      0.602\n",
            " 0.602      0.602      0.602      0.702      0.602      0.602\n",
            " 0.602      0.602      0.602             nan 0.602      0.602\n",
            " 0.602      0.602      0.602      0.602      0.602      0.602\n",
            " 0.6        0.6        0.6        0.6        0.62       0.6\n",
            " 0.6        0.6        0.6        0.6        0.6        0.6\n",
            " 0.6        0.62       0.55       0.62       0.62       0.62\n",
            " 0.6        0.6        0.6        0.62       0.6        0.62\n",
            " 0.62       0.62       0.58       0.6        0.62       0.5\n",
            " 0.6        0.6        0.6        0.6        0.62       0.6\n",
            " 0.6        0.6        0.5        0.6        0.5        0.58\n",
            " 0.5        0.6        0.6        0.6        0.6        0.6\n",
            " 0.6        0.62       0.55       0.62       0.6        0.6\n",
            " 0.58       0.5        0.6        0.62       0.6        0.6\n",
            " 0.75386724 0.7610101  0.76111111 0.75555556 0.75555556 0.75555556\n",
            " 0.7484127  0.75386724 0.75555556 0.7610101  0.75386724 0.75386724\n",
            " 0.74545455 0.77767677 0.78253968 0.77767677 0.75555556 0.73831169\n",
            " 0.7484127  0.74545455 0.78243867 0.75555556 0.75555556 0.7484127\n",
            " 0.75555556 0.75555556 0.7484127  0.7610101  0.77388889 0.77767677\n",
            " 0.72       0.74752568 0.72446115 0.73128655 0.7172549  0.74969925\n",
            " 0.73992063 0.73135191 0.73616394 0.74768244 0.7628602  0.72994326\n",
            " 0.71988796 0.70972335 0.75569202]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'base_estimator__class_weight': 'balanced', 'base_estimator__criterion': 'entropy', 'base_estimator__n_estimators': 50, 'n_estimators': 10}\n",
            "Best score: 0.7628602048106692\n",
            "Accuracy: 58.5714%\n",
            "Recall: 84.2105%\n",
            "Precision: 38.0952%\n",
            "F-measure: 57.8751%\n",
            "[[25 26]\n",
            " [ 3 16]]\n",
            "BRF\n",
            "Best params: {'class_weight': 'balanced', 'criterion': 'entropy', 'n_estimators': 80}\n",
            "Best score: 0.8119281045751634\n",
            "Accuracy: 60.0000%\n",
            "Recall: 84.2105%\n",
            "Precision: 39.0244%\n",
            "F-measure: 59.1667%\n",
            "[[26 25]\n",
            " [ 3 16]]\n",
            "RFC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.59452381 0.60833333\n",
            " 0.61833333 0.64452381 0.65119048 0.62380952 0.62785714 0.62761905\n",
            " 0.61452381 0.59452381 0.64166667 0.585      0.585      0.605\n",
            " 0.61047619 0.59047619 0.59452381 0.60785714 0.60119048 0.60119048]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.59452381 0.60833333\n",
            " 0.61833333 0.64452381 0.65119048 0.62380952 0.62785714 0.62761905\n",
            " 0.61452381 0.59452381 0.64166667 0.585      0.585      0.605\n",
            " 0.61047619 0.59047619 0.59452381 0.60785714 0.60119048 0.60119048\n",
            " 0.75333333 0.70867799 0.73739594 0.75238095 0.72640693 0.73095238\n",
            " 0.74194139 0.67584416 0.75989011 0.71761905]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.59452381 0.60833333\n",
            " 0.61833333 0.64452381 0.65119048 0.62380952 0.62785714 0.62761905\n",
            " 0.61452381 0.59452381 0.64166667 0.585      0.585      0.605\n",
            " 0.61047619 0.59047619 0.59452381 0.60785714 0.60119048 0.60119048\n",
            " 0.75333333 0.70867799 0.73739594 0.75238095 0.72640693 0.73095238\n",
            " 0.74194139 0.67584416 0.75989011 0.71761905 0.74280431 0.74063867\n",
            " 0.72767196 0.7227791  0.73148148]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'class_weight': 'balanced', 'criterion': 'gini', 'n_estimators': 90}\n",
            "Best score: 0.7428043068043069\n",
            "Accuracy: 68.5714%\n",
            "Recall: 31.5789%\n",
            "Precision: 40.0000%\n",
            "F-measure: 57.2697%\n",
            "[[42  9]\n",
            " [13  6]]\n",
            "KNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [0.7297619 1.              nan       nan       nan       nan       nan\n",
            "       nan       nan       nan 0.725     1.              nan       nan\n",
            "       nan       nan       nan       nan       nan       nan 0.7297619\n",
            " 1.              nan       nan       nan       nan       nan       nan\n",
            "       nan       nan 0.725     1.              nan       nan       nan\n",
            "       nan       nan       nan       nan       nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan 0.825\n",
            "        nan 0.825             nan        nan        nan        nan\n",
            "        nan        nan        nan 0.825             nan 0.81166667\n",
            "        nan        nan        nan        nan        nan        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [0.7297619  1.                nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.725      1.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.7297619  1.                nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.725      1.                nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan 1.\n",
            " 0.68716563 1.         0.69012097 1.                nan        nan\n",
            "        nan        nan 0.75799119 1.         0.71231249 0.984\n",
            " 0.69012097 0.984             nan        nan        nan        nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan 0.825\n",
            "        nan 0.825             nan        nan        nan        nan\n",
            "        nan        nan        nan 0.825             nan 0.81166667\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.76416667 0.76666667 0.76666667 0.75801282 0.76666667 0.77083333\n",
            " 0.77083333 0.76130952 0.80372294 0.76416667]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [0.7297619  1.                nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.725      1.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.7297619  1.                nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.725      1.                nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan 1.\n",
            " 0.68716563 1.         0.69012097 1.                nan        nan\n",
            "        nan        nan 0.75799119 1.         0.71231249 0.984\n",
            " 0.69012097 0.984             nan        nan        nan        nan\n",
            " 1.         0.69176587 0.69176587 1.         0.69176587 1.\n",
            " 0.71587935 0.7356384  0.7389119  1.        ]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan 0.825\n",
            "        nan 0.825             nan        nan        nan        nan\n",
            "        nan        nan        nan 0.825             nan 0.81166667\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.76416667 0.76666667 0.76666667 0.75801282 0.76666667 0.77083333\n",
            " 0.77083333 0.76130952 0.80372294 0.76416667 0.69282258 0.68926307\n",
            " 0.71569892 0.69583333 0.71585415]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [0.7297619  1.                nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.725      1.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.7297619  1.                nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.725      1.                nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan 1.\n",
            " 0.68716563 1.         0.69012097 1.                nan        nan\n",
            "        nan        nan 0.75799119 1.         0.71231249 0.984\n",
            " 0.69012097 0.984             nan        nan        nan        nan\n",
            " 1.         0.69176587 0.69176587 1.         0.69176587 1.\n",
            " 0.71587935 0.7356384  0.7389119  1.         0.70954724 0.71311409\n",
            " 1.         0.71928763 0.75487279]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'algorithm': 'auto', 'metric': 'minkowski', 'n_neighbors': 10, 'weights': 'uniform'}\n",
            "Best score: 0.7158541462657146\n",
            "Accuracy: 72.8571%\n",
            "Recall: 15.7895%\n",
            "Precision: 50.0000%\n",
            "F-measure: 53.7391%\n",
            "[[48  3]\n",
            " [16  3]]\n",
            "SVC\n",
            "Best params: {'C': 1, 'class_weight': 'balanced', 'kernel': 'sigmoid', 'tol': 0.005}\n",
            "Best score: 0.7966666666666666\n",
            "Accuracy: 68.5714%\n",
            "Recall: 84.2105%\n",
            "Precision: 45.7143%\n",
            "F-measure: 66.8389%\n",
            "[[32 19]\n",
            " [ 3 16]]\n",
            "lReg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "24 fits failed out of a total of 120.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "24 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1558, in fit\n",
            "    % classes_[0]\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.74619048 0.71333333 0.71333333 0.69333333 0.73       0.69333333\n",
            " 0.69333333 0.72       0.72       0.72       0.8        0.76333333]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.89137255 0.92136223 0.92136223 0.92998968 0.91601307 0.92998968\n",
            " 0.92998968 0.89636223 0.8873065  0.89636223 0.91756405 0.91365325]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.74619048 0.71333333 0.71333333 0.69333333 0.73       0.69333333\n",
            " 0.69333333 0.72       0.72       0.72       0.8        0.76333333\n",
            " 0.66759019 0.63425685 0.64489011 0.72658009 0.67338384 0.69393939]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.89137255 0.92136223 0.92136223 0.92998968 0.91601307 0.92998968\n",
            " 0.92998968 0.89636223 0.8873065  0.89636223 0.91756405 0.91365325\n",
            " 0.85519698 0.84036322 0.85747967 0.84224765 0.82815625 0.89133678]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'C': 1000, 'class_weight': 'balanced', 'solver': 'saga', 'tol': 0.0001}\n",
            "Best score: 0.7892002734107998\n",
            "Accuracy: 68.5714%\n",
            "Recall: 89.4737%\n",
            "Precision: 45.9459%\n",
            "F-measure: 67.2619%\n",
            "[[31 20]\n",
            " [ 2 17]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.74619048 0.71333333 0.71333333 0.69333333 0.73       0.69333333\n",
            " 0.69333333 0.72       0.72       0.72       0.8        0.76333333\n",
            " 0.66759019 0.63425685 0.64489011 0.72658009 0.67338384 0.69393939\n",
            " 0.78920027 0.78862471 0.74052931]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.89137255 0.92136223 0.92136223 0.92998968 0.91601307 0.92998968\n",
            " 0.92998968 0.89636223 0.8873065  0.89636223 0.91756405 0.91365325\n",
            " 0.85519698 0.84036322 0.85747967 0.84224765 0.82815625 0.89133678\n",
            " 0.83682867 0.81555097 0.78437996]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ac5547e8-c583-4dd0-98fe-8728317daabf\", \"Results_1.csv\", 1963)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EqEGqaAA7goi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "197fbbb7-1852-405f-8edd-1a680a544032"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1000, class_weight='balanced', multi_class='multinomial',\n",
              "                   solver='saga')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Select the highest performing classifier\n",
        "indx = submission['Selector'].idxmax()\n",
        "my_model.classifier = classifiers[indx].set_params(**submission['Best params'][indx])\n",
        "\n",
        "# Train your model\n",
        "my_model.classifier.fit(x_train_processed, np.ravel(y_train.values))\n",
        "del submission,indx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kwOiqNee7goj"
      },
      "outputs": [],
      "source": [
        "# use your model to make a prediction on unseen data\n",
        "y_pred = my_model.classifier.predict(x_test_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VGgleoej7gok",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "e44f0df1-b9f5-41dd-9f02-5e3d58bf115c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 68.57 %\n",
            "Weighted ROC AUC accuracy: 75.13 %\n",
            "Confusion matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False negatives: 2.86 %\n",
            "F-score (macro): 67.26 %\n",
            "K-fold cross validation results\n",
            "Accuracy: 65.44 %\n",
            "Standard Deviation: 10.86 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "# Asssess the accuracy of your model and explain your key findings\n",
        "# Generate confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, roc_auc_score, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_pred, labels=my_model.classifier.classes_)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracy_score(y_test, y_pred)*100))\n",
        "print(\"Weighted ROC AUC accuracy: {:.2f} %\".format(roc_auc_score(y_test, y_pred, average='weighted')*100))\n",
        "print(\"Confusion matrix:\")\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=my_model.classifier.classes_)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "print(\"False negatives: {:.2f} %\".format(cm[1,0]/sum(sum(cm))*100))\n",
        "print(\"F-score (macro): {:.2f} %\".format(f1_score(y_test,y_pred,average='macro')*100))\n",
        "\n",
        "# Apply k-fold Cross Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator=my_model.classifier,\n",
        "                             X=x_train_processed,\n",
        "                             y=np.ravel(y_train.values),\n",
        "                             scoring='roc_auc_ovo',\n",
        "                             cv=10)\n",
        "print(\"K-fold cross validation results\")\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
        "del cm, accuracies, disp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model has an accuracy of around 65% (non-deterministic nature means this is slightly variable) when predicting whether cancer recurrence will occur.**\n",
        "\n",
        "**Crucially, the proportion of False Negatives is very low (<5%). In cancer diagnosis these are the outcomes that we want to minimise. False Positives, whilst undesirable, will likely lead to further diagnostic testing before it is realised that cancer is not present.**"
      ],
      "metadata": {
        "id": "UMNN4P_E07L6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDU85k7J7gok"
      },
      "source": [
        "### Unit tests:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "TGd264IsrMob"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq2QRpri7gol"
      },
      "source": [
        "###Checking training and test data for null values. This will work for both pd dataframes and np arrays, and ensures no null values exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oUeh38w_7gol"
      },
      "outputs": [],
      "source": [
        "def test_no_nulls(data):\n",
        "    \"\"\" Assert no null values within pd dataframe or np array \"\"\"\n",
        "    \n",
        "    # if data is numpy array, handle accordingly\n",
        "    if isinstance(data, (np.ndarray)):\n",
        "        assert not np.isnan(np.min(data))\n",
        "    \n",
        "    # if not np array, assume data is pandas dataframe\n",
        "    else:\n",
        "        assert data.isna().sum().sum() == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BV9Z1F3i7gom"
      },
      "outputs": [],
      "source": [
        "# run null data unit test on both training and test data\n",
        "test_no_nulls(x_train_processed)\n",
        "test_no_nulls(x_test_processed)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of KSVC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}